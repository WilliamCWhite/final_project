{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b2c49450-78d6-481f-9fad-cd46d193e35a",
   "metadata": {},
   "source": [
    "# Importing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1a1049ec-c615-4850-b927-be6d944f15fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('Students.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "38a1556d-34a2-4fc3-882b-6e31a1a09361",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Student_Name                                      College_Name       Stream  \\\n",
      "0        Aarav       Indian Institute of Information Technology   Engineering   \n",
      "1       Vivaan   Government Ram Bhajan Rai NES College, Jashpur      Commerce   \n",
      "2       Aditya     Dolphin PG Institute of BioMedical & Natural       Science   \n",
      "3       Vihaan  Shaheed Rajguru College of Applied Sciences for          Arts   \n",
      "4        Arjun                   Roorkee College of Engineering       Science   \n",
      "\n",
      "   Year_of_Study AI_Tools_Used  Daily_Usage_Hours  \\\n",
      "0              4        Gemini                0.9   \n",
      "1              2       ChatGPT                3.4   \n",
      "2              2       Copilot                3.6   \n",
      "3              2       Copilot                2.9   \n",
      "4              1        Gemini                0.9   \n",
      "\n",
      "                       Use_Cases  Trust_in_AI_Tools  Impact_on_Grades  \\\n",
      "0       Assignments, Coding Help                  2                 2   \n",
      "1            Learning new topics                  3                -3   \n",
      "2         MCQ Practice, Projects                  5                 0   \n",
      "3                Content Writing                  5                 2   \n",
      "4  Doubt Solving, Resume Writing                  1                 3   \n",
      "\n",
      "  Do_Professors_Allow_Use Preferred_AI_Tool  Awareness_Level  \\\n",
      "0                      No           Copilot                9   \n",
      "1                     Yes             Other                6   \n",
      "2                      No            Gemini                1   \n",
      "3                     Yes            Gemini                5   \n",
      "4                     Yes             Other                8   \n",
      "\n",
      "  Willing_to_Pay_for_Access          State Device_Used Internet_Access  \n",
      "0                       Yes  Uttar pradesh      Mobile            Poor  \n",
      "1                        No   Chhattisgarh      Laptop            Poor  \n",
      "2                        No    Uttarakhand      Tablet            Poor  \n",
      "3                        No      Delhi ncr      Laptop            High  \n",
      "4                       Yes    Uttarakhand      Laptop          Medium  \n",
      "(3614, 16)\n"
     ]
    }
   ],
   "source": [
    "print(df.head())\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0482ea04-790e-471b-976a-ba36bc0eecee",
   "metadata": {},
   "source": [
    "# Correlation Coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0c37f63a-e694-4318-8c5c-87df883be2a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year_of_Study</th>\n",
       "      <th>Daily_Usage_Hours</th>\n",
       "      <th>Trust_in_AI_Tools</th>\n",
       "      <th>Impact_on_Grades</th>\n",
       "      <th>Awareness_Level</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Year_of_Study</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.007906</td>\n",
       "      <td>0.000744</td>\n",
       "      <td>-0.005867</td>\n",
       "      <td>-0.012708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Daily_Usage_Hours</th>\n",
       "      <td>0.007906</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.012369</td>\n",
       "      <td>0.057222</td>\n",
       "      <td>0.005981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Trust_in_AI_Tools</th>\n",
       "      <td>0.000744</td>\n",
       "      <td>-0.012369</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.047310</td>\n",
       "      <td>0.039466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Impact_on_Grades</th>\n",
       "      <td>-0.005867</td>\n",
       "      <td>0.057222</td>\n",
       "      <td>-0.047310</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.015721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Awareness_Level</th>\n",
       "      <td>-0.012708</td>\n",
       "      <td>0.005981</td>\n",
       "      <td>0.039466</td>\n",
       "      <td>-0.015721</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Year_of_Study  Daily_Usage_Hours  Trust_in_AI_Tools  \\\n",
       "Year_of_Study           1.000000           0.007906           0.000744   \n",
       "Daily_Usage_Hours       0.007906           1.000000          -0.012369   \n",
       "Trust_in_AI_Tools       0.000744          -0.012369           1.000000   \n",
       "Impact_on_Grades       -0.005867           0.057222          -0.047310   \n",
       "Awareness_Level        -0.012708           0.005981           0.039466   \n",
       "\n",
       "                   Impact_on_Grades  Awareness_Level  \n",
       "Year_of_Study             -0.005867        -0.012708  \n",
       "Daily_Usage_Hours          0.057222         0.005981  \n",
       "Trust_in_AI_Tools         -0.047310         0.039466  \n",
       "Impact_on_Grades           1.000000        -0.015721  \n",
       "Awareness_Level           -0.015721         1.000000  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corr_df = df.corr(numeric_only=True)\n",
    "corr_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "037cf9c4-e686-4fa9-bc6a-d338ddb44621",
   "metadata": {},
   "source": [
    "The numeric variables don't appear to show any significant linear relationship at all. However, there are a lot of non_numeric variables to test this relationship. Since many of the variables are categorical or multi-select, we have to process the data a lot to figure out correlations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "406057b5-6628-4c78-8262-c15094ef1686",
   "metadata": {},
   "source": [
    "Notes:\n",
    "- Use correlation ratio for categorical to numeric\n",
    "- Use cramers v for categorical to categorical"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28637c23-8954-44d2-8c3e-7abe3822077c",
   "metadata": {},
   "source": [
    "## Converting Binary and Multi-Select Columns to 0 or 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "336f3db7-2dad-446f-9e57-e593e0c34bf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert yes/no columns to 0/1 to allow for correlation calculations\n",
    "binary_columns = [\"Do_Professors_Allow_Use\", \"Willing_to_Pay_for_Access\"]\n",
    "df[binary_columns] = df[binary_columns].replace({\n",
    "    'Yes': 1, 'No': 0,\n",
    "})\n",
    "\n",
    "# convert multi-select columns (Ai_tools_used, use_cases) to multiple binary columns\n",
    "multi_col_1 = 'Use_Cases'\n",
    "df = df.join(df[multi_col_1].str.get_dummies(sep=', ').add_prefix(f'Use_'))\n",
    "\n",
    "multi_col_2 = 'AI_Tools_Used'\n",
    "df = df.join(df[multi_col_2].str.get_dummies(sep=', ').add_prefix(f'AI_Tool_'))\n",
    "\n",
    "df = df.drop(columns=[multi_col_1, multi_col_2])\n",
    "other_cols_to_drop = ['Student_Name', 'College_Name', 'State']\n",
    "df = df.drop(columns=other_cols_to_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e8cefaad-93b3-4602-a911-876213d06b39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year_of_Study</th>\n",
       "      <th>Daily_Usage_Hours</th>\n",
       "      <th>Trust_in_AI_Tools</th>\n",
       "      <th>Impact_on_Grades</th>\n",
       "      <th>Do_Professors_Allow_Use</th>\n",
       "      <th>Awareness_Level</th>\n",
       "      <th>Willing_to_Pay_for_Access</th>\n",
       "      <th>Use_Assignments</th>\n",
       "      <th>Use_Coding Help</th>\n",
       "      <th>Use_Content Writing</th>\n",
       "      <th>...</th>\n",
       "      <th>Use_Project Work</th>\n",
       "      <th>Use_Projects</th>\n",
       "      <th>Use_Resume Writing</th>\n",
       "      <th>AI_Tool_Bard</th>\n",
       "      <th>AI_Tool_ChatGPT</th>\n",
       "      <th>AI_Tool_Claude</th>\n",
       "      <th>AI_Tool_Copilot</th>\n",
       "      <th>AI_Tool_Gemini</th>\n",
       "      <th>AI_Tool_Midjourney</th>\n",
       "      <th>AI_Tool_Other</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Year_of_Study</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.007906</td>\n",
       "      <td>0.000744</td>\n",
       "      <td>-0.005867</td>\n",
       "      <td>0.053934</td>\n",
       "      <td>-0.012708</td>\n",
       "      <td>0.016681</td>\n",
       "      <td>-0.008744</td>\n",
       "      <td>-0.013586</td>\n",
       "      <td>0.045134</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.008500</td>\n",
       "      <td>-0.051430</td>\n",
       "      <td>0.024716</td>\n",
       "      <td>0.034448</td>\n",
       "      <td>-0.043521</td>\n",
       "      <td>0.030750</td>\n",
       "      <td>-0.008550</td>\n",
       "      <td>0.002923</td>\n",
       "      <td>-0.063732</td>\n",
       "      <td>0.007173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Daily_Usage_Hours</th>\n",
       "      <td>0.007906</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.012369</td>\n",
       "      <td>0.057222</td>\n",
       "      <td>0.022814</td>\n",
       "      <td>0.005981</td>\n",
       "      <td>0.029144</td>\n",
       "      <td>0.007313</td>\n",
       "      <td>0.016174</td>\n",
       "      <td>-0.005589</td>\n",
       "      <td>...</td>\n",
       "      <td>0.038416</td>\n",
       "      <td>-0.084594</td>\n",
       "      <td>0.050600</td>\n",
       "      <td>0.027914</td>\n",
       "      <td>-0.044830</td>\n",
       "      <td>0.020512</td>\n",
       "      <td>-0.091600</td>\n",
       "      <td>0.017539</td>\n",
       "      <td>0.009136</td>\n",
       "      <td>0.031434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Trust_in_AI_Tools</th>\n",
       "      <td>0.000744</td>\n",
       "      <td>-0.012369</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.047310</td>\n",
       "      <td>-0.023196</td>\n",
       "      <td>0.039466</td>\n",
       "      <td>0.003888</td>\n",
       "      <td>-0.052935</td>\n",
       "      <td>-0.045146</td>\n",
       "      <td>0.052210</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.004208</td>\n",
       "      <td>0.016648</td>\n",
       "      <td>0.047427</td>\n",
       "      <td>0.012985</td>\n",
       "      <td>0.042708</td>\n",
       "      <td>-0.013583</td>\n",
       "      <td>0.083427</td>\n",
       "      <td>-0.061107</td>\n",
       "      <td>-0.046083</td>\n",
       "      <td>-0.001726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Impact_on_Grades</th>\n",
       "      <td>-0.005867</td>\n",
       "      <td>0.057222</td>\n",
       "      <td>-0.047310</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.067598</td>\n",
       "      <td>-0.015721</td>\n",
       "      <td>0.010042</td>\n",
       "      <td>0.026643</td>\n",
       "      <td>0.028122</td>\n",
       "      <td>0.013472</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009948</td>\n",
       "      <td>0.002235</td>\n",
       "      <td>-0.012425</td>\n",
       "      <td>-0.034130</td>\n",
       "      <td>0.035791</td>\n",
       "      <td>-0.033301</td>\n",
       "      <td>-0.022007</td>\n",
       "      <td>0.011087</td>\n",
       "      <td>-0.027012</td>\n",
       "      <td>-0.001976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Do_Professors_Allow_Use</th>\n",
       "      <td>0.053934</td>\n",
       "      <td>0.022814</td>\n",
       "      <td>-0.023196</td>\n",
       "      <td>0.067598</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.045744</td>\n",
       "      <td>0.002119</td>\n",
       "      <td>0.023058</td>\n",
       "      <td>0.022695</td>\n",
       "      <td>-0.019090</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.019314</td>\n",
       "      <td>0.036682</td>\n",
       "      <td>-0.042712</td>\n",
       "      <td>-0.006088</td>\n",
       "      <td>0.031920</td>\n",
       "      <td>0.003230</td>\n",
       "      <td>0.016994</td>\n",
       "      <td>-0.004202</td>\n",
       "      <td>-0.042689</td>\n",
       "      <td>-0.023350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Awareness_Level</th>\n",
       "      <td>-0.012708</td>\n",
       "      <td>0.005981</td>\n",
       "      <td>0.039466</td>\n",
       "      <td>-0.015721</td>\n",
       "      <td>-0.045744</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.005995</td>\n",
       "      <td>-0.008286</td>\n",
       "      <td>-0.011941</td>\n",
       "      <td>-0.001199</td>\n",
       "      <td>...</td>\n",
       "      <td>0.024574</td>\n",
       "      <td>0.014521</td>\n",
       "      <td>-0.033978</td>\n",
       "      <td>-0.026047</td>\n",
       "      <td>0.057712</td>\n",
       "      <td>-0.000741</td>\n",
       "      <td>-0.012254</td>\n",
       "      <td>0.005765</td>\n",
       "      <td>-0.000422</td>\n",
       "      <td>-0.016379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Willing_to_Pay_for_Access</th>\n",
       "      <td>0.016681</td>\n",
       "      <td>0.029144</td>\n",
       "      <td>0.003888</td>\n",
       "      <td>0.010042</td>\n",
       "      <td>0.002119</td>\n",
       "      <td>-0.005995</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.018665</td>\n",
       "      <td>-0.025934</td>\n",
       "      <td>0.021783</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.011918</td>\n",
       "      <td>-0.017242</td>\n",
       "      <td>0.019389</td>\n",
       "      <td>0.029503</td>\n",
       "      <td>0.005837</td>\n",
       "      <td>-0.016449</td>\n",
       "      <td>0.011975</td>\n",
       "      <td>-0.010145</td>\n",
       "      <td>-0.018396</td>\n",
       "      <td>-0.008739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Use_Assignments</th>\n",
       "      <td>-0.008744</td>\n",
       "      <td>0.007313</td>\n",
       "      <td>-0.052935</td>\n",
       "      <td>0.026643</td>\n",
       "      <td>0.023058</td>\n",
       "      <td>-0.008286</td>\n",
       "      <td>-0.018665</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.690256</td>\n",
       "      <td>-0.155300</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.012498</td>\n",
       "      <td>-0.197691</td>\n",
       "      <td>-0.159424</td>\n",
       "      <td>0.022876</td>\n",
       "      <td>-0.108475</td>\n",
       "      <td>0.005017</td>\n",
       "      <td>-0.073581</td>\n",
       "      <td>0.079761</td>\n",
       "      <td>0.081219</td>\n",
       "      <td>0.011021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Use_Coding Help</th>\n",
       "      <td>-0.013586</td>\n",
       "      <td>0.016174</td>\n",
       "      <td>-0.045146</td>\n",
       "      <td>0.028122</td>\n",
       "      <td>0.022695</td>\n",
       "      <td>-0.011941</td>\n",
       "      <td>-0.025934</td>\n",
       "      <td>0.690256</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.186427</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.023726</td>\n",
       "      <td>-0.200517</td>\n",
       "      <td>-0.141745</td>\n",
       "      <td>-0.010168</td>\n",
       "      <td>-0.098457</td>\n",
       "      <td>0.018355</td>\n",
       "      <td>-0.063553</td>\n",
       "      <td>0.057411</td>\n",
       "      <td>0.076659</td>\n",
       "      <td>0.014847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Use_Content Writing</th>\n",
       "      <td>0.045134</td>\n",
       "      <td>-0.005589</td>\n",
       "      <td>0.052210</td>\n",
       "      <td>0.013472</td>\n",
       "      <td>-0.019090</td>\n",
       "      <td>-0.001199</td>\n",
       "      <td>0.021783</td>\n",
       "      <td>-0.155300</td>\n",
       "      <td>-0.186427</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000444</td>\n",
       "      <td>-0.172854</td>\n",
       "      <td>-0.125874</td>\n",
       "      <td>0.029125</td>\n",
       "      <td>-0.053024</td>\n",
       "      <td>0.019293</td>\n",
       "      <td>0.015761</td>\n",
       "      <td>-0.001071</td>\n",
       "      <td>-0.016636</td>\n",
       "      <td>0.028943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Use_Doubt Solving</th>\n",
       "      <td>0.018541</td>\n",
       "      <td>0.062526</td>\n",
       "      <td>0.027868</td>\n",
       "      <td>-0.019937</td>\n",
       "      <td>-0.034946</td>\n",
       "      <td>-0.022962</td>\n",
       "      <td>0.006831</td>\n",
       "      <td>-0.168704</td>\n",
       "      <td>-0.165545</td>\n",
       "      <td>-0.144669</td>\n",
       "      <td>...</td>\n",
       "      <td>0.013624</td>\n",
       "      <td>-0.179020</td>\n",
       "      <td>0.601919</td>\n",
       "      <td>0.048395</td>\n",
       "      <td>-0.055495</td>\n",
       "      <td>0.016450</td>\n",
       "      <td>-0.011218</td>\n",
       "      <td>-0.097819</td>\n",
       "      <td>-0.065743</td>\n",
       "      <td>0.053646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Use_Exam Prep</th>\n",
       "      <td>0.023226</td>\n",
       "      <td>0.016621</td>\n",
       "      <td>-0.019512</td>\n",
       "      <td>-0.011126</td>\n",
       "      <td>0.029095</td>\n",
       "      <td>-0.015637</td>\n",
       "      <td>-0.005025</td>\n",
       "      <td>-0.193071</td>\n",
       "      <td>-0.195832</td>\n",
       "      <td>-0.168814</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.098215</td>\n",
       "      <td>-0.145998</td>\n",
       "      <td>-0.171332</td>\n",
       "      <td>-0.078850</td>\n",
       "      <td>0.139825</td>\n",
       "      <td>-0.084153</td>\n",
       "      <td>0.057372</td>\n",
       "      <td>0.043204</td>\n",
       "      <td>0.001937</td>\n",
       "      <td>-0.083114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Use_Exam Preparation</th>\n",
       "      <td>-0.001655</td>\n",
       "      <td>0.052071</td>\n",
       "      <td>-0.012320</td>\n",
       "      <td>-0.009996</td>\n",
       "      <td>0.015470</td>\n",
       "      <td>-0.015791</td>\n",
       "      <td>0.019811</td>\n",
       "      <td>-0.041201</td>\n",
       "      <td>-0.040716</td>\n",
       "      <td>-0.018259</td>\n",
       "      <td>...</td>\n",
       "      <td>0.104822</td>\n",
       "      <td>-0.094076</td>\n",
       "      <td>0.011248</td>\n",
       "      <td>0.099691</td>\n",
       "      <td>-0.131418</td>\n",
       "      <td>0.121649</td>\n",
       "      <td>-0.104313</td>\n",
       "      <td>-0.108061</td>\n",
       "      <td>-0.082297</td>\n",
       "      <td>0.152997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Use_Learning new topics</th>\n",
       "      <td>-0.006668</td>\n",
       "      <td>-0.030620</td>\n",
       "      <td>-0.023284</td>\n",
       "      <td>0.020483</td>\n",
       "      <td>-0.038885</td>\n",
       "      <td>0.027542</td>\n",
       "      <td>0.008448</td>\n",
       "      <td>-0.175185</td>\n",
       "      <td>-0.149621</td>\n",
       "      <td>-0.138156</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.005022</td>\n",
       "      <td>-0.171474</td>\n",
       "      <td>-0.135747</td>\n",
       "      <td>0.037992</td>\n",
       "      <td>0.010690</td>\n",
       "      <td>0.013695</td>\n",
       "      <td>-0.010850</td>\n",
       "      <td>-0.043758</td>\n",
       "      <td>0.007434</td>\n",
       "      <td>0.005519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Use_MCQ Practice</th>\n",
       "      <td>-0.040144</td>\n",
       "      <td>-0.034028</td>\n",
       "      <td>-0.009831</td>\n",
       "      <td>-0.009879</td>\n",
       "      <td>0.039598</td>\n",
       "      <td>-0.004877</td>\n",
       "      <td>-0.012988</td>\n",
       "      <td>-0.177690</td>\n",
       "      <td>-0.192156</td>\n",
       "      <td>-0.126966</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.008222</td>\n",
       "      <td>0.794501</td>\n",
       "      <td>-0.155392</td>\n",
       "      <td>0.017879</td>\n",
       "      <td>0.039579</td>\n",
       "      <td>0.014102</td>\n",
       "      <td>0.006726</td>\n",
       "      <td>-0.004026</td>\n",
       "      <td>-0.039478</td>\n",
       "      <td>-0.013321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Use_Notes</th>\n",
       "      <td>0.023226</td>\n",
       "      <td>0.016621</td>\n",
       "      <td>-0.019512</td>\n",
       "      <td>-0.011126</td>\n",
       "      <td>0.029095</td>\n",
       "      <td>-0.015637</td>\n",
       "      <td>-0.005025</td>\n",
       "      <td>-0.193071</td>\n",
       "      <td>-0.195832</td>\n",
       "      <td>-0.168814</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.098215</td>\n",
       "      <td>-0.145998</td>\n",
       "      <td>-0.171332</td>\n",
       "      <td>-0.078850</td>\n",
       "      <td>0.139825</td>\n",
       "      <td>-0.084153</td>\n",
       "      <td>0.057372</td>\n",
       "      <td>0.043204</td>\n",
       "      <td>0.001937</td>\n",
       "      <td>-0.083114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Use_Project Work</th>\n",
       "      <td>-0.008500</td>\n",
       "      <td>0.038416</td>\n",
       "      <td>-0.004208</td>\n",
       "      <td>-0.009948</td>\n",
       "      <td>-0.019314</td>\n",
       "      <td>0.024574</td>\n",
       "      <td>-0.011918</td>\n",
       "      <td>-0.012498</td>\n",
       "      <td>-0.023726</td>\n",
       "      <td>-0.000444</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.100565</td>\n",
       "      <td>-0.000290</td>\n",
       "      <td>0.115981</td>\n",
       "      <td>-0.125369</td>\n",
       "      <td>0.145321</td>\n",
       "      <td>-0.140541</td>\n",
       "      <td>-0.119423</td>\n",
       "      <td>-0.087974</td>\n",
       "      <td>0.180798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Use_Projects</th>\n",
       "      <td>-0.051430</td>\n",
       "      <td>-0.084594</td>\n",
       "      <td>0.016648</td>\n",
       "      <td>0.002235</td>\n",
       "      <td>0.036682</td>\n",
       "      <td>0.014521</td>\n",
       "      <td>-0.017242</td>\n",
       "      <td>-0.197691</td>\n",
       "      <td>-0.200517</td>\n",
       "      <td>-0.172854</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.100565</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.175431</td>\n",
       "      <td>-0.080736</td>\n",
       "      <td>0.132091</td>\n",
       "      <td>-0.086166</td>\n",
       "      <td>0.096429</td>\n",
       "      <td>0.075496</td>\n",
       "      <td>0.015589</td>\n",
       "      <td>-0.085103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Use_Resume Writing</th>\n",
       "      <td>0.024716</td>\n",
       "      <td>0.050600</td>\n",
       "      <td>0.047427</td>\n",
       "      <td>-0.012425</td>\n",
       "      <td>-0.042712</td>\n",
       "      <td>-0.033978</td>\n",
       "      <td>0.019389</td>\n",
       "      <td>-0.159424</td>\n",
       "      <td>-0.141745</td>\n",
       "      <td>-0.125874</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000290</td>\n",
       "      <td>-0.175431</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.041238</td>\n",
       "      <td>-0.060618</td>\n",
       "      <td>0.051283</td>\n",
       "      <td>-0.005691</td>\n",
       "      <td>-0.089791</td>\n",
       "      <td>-0.061395</td>\n",
       "      <td>0.029736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AI_Tool_Bard</th>\n",
       "      <td>0.034448</td>\n",
       "      <td>0.027914</td>\n",
       "      <td>0.012985</td>\n",
       "      <td>-0.034130</td>\n",
       "      <td>-0.006088</td>\n",
       "      <td>-0.026047</td>\n",
       "      <td>0.029503</td>\n",
       "      <td>0.022876</td>\n",
       "      <td>-0.010168</td>\n",
       "      <td>0.029125</td>\n",
       "      <td>...</td>\n",
       "      <td>0.115981</td>\n",
       "      <td>-0.080736</td>\n",
       "      <td>0.041238</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.181673</td>\n",
       "      <td>-0.046536</td>\n",
       "      <td>-0.177504</td>\n",
       "      <td>-0.166922</td>\n",
       "      <td>-0.070628</td>\n",
       "      <td>-0.045962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AI_Tool_ChatGPT</th>\n",
       "      <td>-0.043521</td>\n",
       "      <td>-0.044830</td>\n",
       "      <td>0.042708</td>\n",
       "      <td>0.035791</td>\n",
       "      <td>0.031920</td>\n",
       "      <td>0.057712</td>\n",
       "      <td>0.005837</td>\n",
       "      <td>-0.108475</td>\n",
       "      <td>-0.098457</td>\n",
       "      <td>-0.053024</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.125369</td>\n",
       "      <td>0.132091</td>\n",
       "      <td>-0.060618</td>\n",
       "      <td>-0.181673</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.193891</td>\n",
       "      <td>0.314641</td>\n",
       "      <td>-0.207406</td>\n",
       "      <td>-0.294266</td>\n",
       "      <td>-0.191498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AI_Tool_Claude</th>\n",
       "      <td>0.030750</td>\n",
       "      <td>0.020512</td>\n",
       "      <td>-0.013583</td>\n",
       "      <td>-0.033301</td>\n",
       "      <td>0.003230</td>\n",
       "      <td>-0.000741</td>\n",
       "      <td>-0.016449</td>\n",
       "      <td>0.005017</td>\n",
       "      <td>0.018355</td>\n",
       "      <td>0.019293</td>\n",
       "      <td>...</td>\n",
       "      <td>0.145321</td>\n",
       "      <td>-0.086166</td>\n",
       "      <td>0.051283</td>\n",
       "      <td>-0.046536</td>\n",
       "      <td>-0.193891</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.189442</td>\n",
       "      <td>-0.178148</td>\n",
       "      <td>-0.075378</td>\n",
       "      <td>-0.049053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AI_Tool_Copilot</th>\n",
       "      <td>-0.008550</td>\n",
       "      <td>-0.091600</td>\n",
       "      <td>0.083427</td>\n",
       "      <td>-0.022007</td>\n",
       "      <td>0.016994</td>\n",
       "      <td>-0.012254</td>\n",
       "      <td>0.011975</td>\n",
       "      <td>-0.073581</td>\n",
       "      <td>-0.063553</td>\n",
       "      <td>0.015761</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.140541</td>\n",
       "      <td>0.096429</td>\n",
       "      <td>-0.005691</td>\n",
       "      <td>-0.177504</td>\n",
       "      <td>0.314641</td>\n",
       "      <td>-0.189442</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.189751</td>\n",
       "      <td>-0.287515</td>\n",
       "      <td>-0.187105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AI_Tool_Gemini</th>\n",
       "      <td>0.002923</td>\n",
       "      <td>0.017539</td>\n",
       "      <td>-0.061107</td>\n",
       "      <td>0.011087</td>\n",
       "      <td>-0.004202</td>\n",
       "      <td>0.005765</td>\n",
       "      <td>-0.010145</td>\n",
       "      <td>0.079761</td>\n",
       "      <td>0.057411</td>\n",
       "      <td>-0.001071</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.119423</td>\n",
       "      <td>0.075496</td>\n",
       "      <td>-0.089791</td>\n",
       "      <td>-0.166922</td>\n",
       "      <td>-0.207406</td>\n",
       "      <td>-0.178148</td>\n",
       "      <td>-0.189751</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.423119</td>\n",
       "      <td>-0.175950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AI_Tool_Midjourney</th>\n",
       "      <td>-0.063732</td>\n",
       "      <td>0.009136</td>\n",
       "      <td>-0.046083</td>\n",
       "      <td>-0.027012</td>\n",
       "      <td>-0.042689</td>\n",
       "      <td>-0.000422</td>\n",
       "      <td>-0.018396</td>\n",
       "      <td>0.081219</td>\n",
       "      <td>0.076659</td>\n",
       "      <td>-0.016636</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.087974</td>\n",
       "      <td>0.015589</td>\n",
       "      <td>-0.061395</td>\n",
       "      <td>-0.070628</td>\n",
       "      <td>-0.294266</td>\n",
       "      <td>-0.075378</td>\n",
       "      <td>-0.287515</td>\n",
       "      <td>0.423119</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.074448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AI_Tool_Other</th>\n",
       "      <td>0.007173</td>\n",
       "      <td>0.031434</td>\n",
       "      <td>-0.001726</td>\n",
       "      <td>-0.001976</td>\n",
       "      <td>-0.023350</td>\n",
       "      <td>-0.016379</td>\n",
       "      <td>-0.008739</td>\n",
       "      <td>0.011021</td>\n",
       "      <td>0.014847</td>\n",
       "      <td>0.028943</td>\n",
       "      <td>...</td>\n",
       "      <td>0.180798</td>\n",
       "      <td>-0.085103</td>\n",
       "      <td>0.029736</td>\n",
       "      <td>-0.045962</td>\n",
       "      <td>-0.191498</td>\n",
       "      <td>-0.049053</td>\n",
       "      <td>-0.187105</td>\n",
       "      <td>-0.175950</td>\n",
       "      <td>-0.074448</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>26 rows Ã— 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                           Year_of_Study  Daily_Usage_Hours  \\\n",
       "Year_of_Study                   1.000000           0.007906   \n",
       "Daily_Usage_Hours               0.007906           1.000000   \n",
       "Trust_in_AI_Tools               0.000744          -0.012369   \n",
       "Impact_on_Grades               -0.005867           0.057222   \n",
       "Do_Professors_Allow_Use         0.053934           0.022814   \n",
       "Awareness_Level                -0.012708           0.005981   \n",
       "Willing_to_Pay_for_Access       0.016681           0.029144   \n",
       "Use_Assignments                -0.008744           0.007313   \n",
       "Use_Coding Help                -0.013586           0.016174   \n",
       "Use_Content Writing             0.045134          -0.005589   \n",
       "Use_Doubt Solving               0.018541           0.062526   \n",
       "Use_Exam Prep                   0.023226           0.016621   \n",
       "Use_Exam Preparation           -0.001655           0.052071   \n",
       "Use_Learning new topics        -0.006668          -0.030620   \n",
       "Use_MCQ Practice               -0.040144          -0.034028   \n",
       "Use_Notes                       0.023226           0.016621   \n",
       "Use_Project Work               -0.008500           0.038416   \n",
       "Use_Projects                   -0.051430          -0.084594   \n",
       "Use_Resume Writing              0.024716           0.050600   \n",
       "AI_Tool_Bard                    0.034448           0.027914   \n",
       "AI_Tool_ChatGPT                -0.043521          -0.044830   \n",
       "AI_Tool_Claude                  0.030750           0.020512   \n",
       "AI_Tool_Copilot                -0.008550          -0.091600   \n",
       "AI_Tool_Gemini                  0.002923           0.017539   \n",
       "AI_Tool_Midjourney             -0.063732           0.009136   \n",
       "AI_Tool_Other                   0.007173           0.031434   \n",
       "\n",
       "                           Trust_in_AI_Tools  Impact_on_Grades  \\\n",
       "Year_of_Study                       0.000744         -0.005867   \n",
       "Daily_Usage_Hours                  -0.012369          0.057222   \n",
       "Trust_in_AI_Tools                   1.000000         -0.047310   \n",
       "Impact_on_Grades                   -0.047310          1.000000   \n",
       "Do_Professors_Allow_Use            -0.023196          0.067598   \n",
       "Awareness_Level                     0.039466         -0.015721   \n",
       "Willing_to_Pay_for_Access           0.003888          0.010042   \n",
       "Use_Assignments                    -0.052935          0.026643   \n",
       "Use_Coding Help                    -0.045146          0.028122   \n",
       "Use_Content Writing                 0.052210          0.013472   \n",
       "Use_Doubt Solving                   0.027868         -0.019937   \n",
       "Use_Exam Prep                      -0.019512         -0.011126   \n",
       "Use_Exam Preparation               -0.012320         -0.009996   \n",
       "Use_Learning new topics            -0.023284          0.020483   \n",
       "Use_MCQ Practice                   -0.009831         -0.009879   \n",
       "Use_Notes                          -0.019512         -0.011126   \n",
       "Use_Project Work                   -0.004208         -0.009948   \n",
       "Use_Projects                        0.016648          0.002235   \n",
       "Use_Resume Writing                  0.047427         -0.012425   \n",
       "AI_Tool_Bard                        0.012985         -0.034130   \n",
       "AI_Tool_ChatGPT                     0.042708          0.035791   \n",
       "AI_Tool_Claude                     -0.013583         -0.033301   \n",
       "AI_Tool_Copilot                     0.083427         -0.022007   \n",
       "AI_Tool_Gemini                     -0.061107          0.011087   \n",
       "AI_Tool_Midjourney                 -0.046083         -0.027012   \n",
       "AI_Tool_Other                      -0.001726         -0.001976   \n",
       "\n",
       "                           Do_Professors_Allow_Use  Awareness_Level  \\\n",
       "Year_of_Study                             0.053934        -0.012708   \n",
       "Daily_Usage_Hours                         0.022814         0.005981   \n",
       "Trust_in_AI_Tools                        -0.023196         0.039466   \n",
       "Impact_on_Grades                          0.067598        -0.015721   \n",
       "Do_Professors_Allow_Use                   1.000000        -0.045744   \n",
       "Awareness_Level                          -0.045744         1.000000   \n",
       "Willing_to_Pay_for_Access                 0.002119        -0.005995   \n",
       "Use_Assignments                           0.023058        -0.008286   \n",
       "Use_Coding Help                           0.022695        -0.011941   \n",
       "Use_Content Writing                      -0.019090        -0.001199   \n",
       "Use_Doubt Solving                        -0.034946        -0.022962   \n",
       "Use_Exam Prep                             0.029095        -0.015637   \n",
       "Use_Exam Preparation                      0.015470        -0.015791   \n",
       "Use_Learning new topics                  -0.038885         0.027542   \n",
       "Use_MCQ Practice                          0.039598        -0.004877   \n",
       "Use_Notes                                 0.029095        -0.015637   \n",
       "Use_Project Work                         -0.019314         0.024574   \n",
       "Use_Projects                              0.036682         0.014521   \n",
       "Use_Resume Writing                       -0.042712        -0.033978   \n",
       "AI_Tool_Bard                             -0.006088        -0.026047   \n",
       "AI_Tool_ChatGPT                           0.031920         0.057712   \n",
       "AI_Tool_Claude                            0.003230        -0.000741   \n",
       "AI_Tool_Copilot                           0.016994        -0.012254   \n",
       "AI_Tool_Gemini                           -0.004202         0.005765   \n",
       "AI_Tool_Midjourney                       -0.042689        -0.000422   \n",
       "AI_Tool_Other                            -0.023350        -0.016379   \n",
       "\n",
       "                           Willing_to_Pay_for_Access  Use_Assignments  \\\n",
       "Year_of_Study                               0.016681        -0.008744   \n",
       "Daily_Usage_Hours                           0.029144         0.007313   \n",
       "Trust_in_AI_Tools                           0.003888        -0.052935   \n",
       "Impact_on_Grades                            0.010042         0.026643   \n",
       "Do_Professors_Allow_Use                     0.002119         0.023058   \n",
       "Awareness_Level                            -0.005995        -0.008286   \n",
       "Willing_to_Pay_for_Access                   1.000000        -0.018665   \n",
       "Use_Assignments                            -0.018665         1.000000   \n",
       "Use_Coding Help                            -0.025934         0.690256   \n",
       "Use_Content Writing                         0.021783        -0.155300   \n",
       "Use_Doubt Solving                           0.006831        -0.168704   \n",
       "Use_Exam Prep                              -0.005025        -0.193071   \n",
       "Use_Exam Preparation                        0.019811        -0.041201   \n",
       "Use_Learning new topics                     0.008448        -0.175185   \n",
       "Use_MCQ Practice                           -0.012988        -0.177690   \n",
       "Use_Notes                                  -0.005025        -0.193071   \n",
       "Use_Project Work                           -0.011918        -0.012498   \n",
       "Use_Projects                               -0.017242        -0.197691   \n",
       "Use_Resume Writing                          0.019389        -0.159424   \n",
       "AI_Tool_Bard                                0.029503         0.022876   \n",
       "AI_Tool_ChatGPT                             0.005837        -0.108475   \n",
       "AI_Tool_Claude                             -0.016449         0.005017   \n",
       "AI_Tool_Copilot                             0.011975        -0.073581   \n",
       "AI_Tool_Gemini                             -0.010145         0.079761   \n",
       "AI_Tool_Midjourney                         -0.018396         0.081219   \n",
       "AI_Tool_Other                              -0.008739         0.011021   \n",
       "\n",
       "                           Use_Coding Help  Use_Content Writing  ...  \\\n",
       "Year_of_Study                    -0.013586             0.045134  ...   \n",
       "Daily_Usage_Hours                 0.016174            -0.005589  ...   \n",
       "Trust_in_AI_Tools                -0.045146             0.052210  ...   \n",
       "Impact_on_Grades                  0.028122             0.013472  ...   \n",
       "Do_Professors_Allow_Use           0.022695            -0.019090  ...   \n",
       "Awareness_Level                  -0.011941            -0.001199  ...   \n",
       "Willing_to_Pay_for_Access        -0.025934             0.021783  ...   \n",
       "Use_Assignments                   0.690256            -0.155300  ...   \n",
       "Use_Coding Help                   1.000000            -0.186427  ...   \n",
       "Use_Content Writing              -0.186427             1.000000  ...   \n",
       "Use_Doubt Solving                -0.165545            -0.144669  ...   \n",
       "Use_Exam Prep                    -0.195832            -0.168814  ...   \n",
       "Use_Exam Preparation             -0.040716            -0.018259  ...   \n",
       "Use_Learning new topics          -0.149621            -0.138156  ...   \n",
       "Use_MCQ Practice                 -0.192156            -0.126966  ...   \n",
       "Use_Notes                        -0.195832            -0.168814  ...   \n",
       "Use_Project Work                 -0.023726            -0.000444  ...   \n",
       "Use_Projects                     -0.200517            -0.172854  ...   \n",
       "Use_Resume Writing               -0.141745            -0.125874  ...   \n",
       "AI_Tool_Bard                     -0.010168             0.029125  ...   \n",
       "AI_Tool_ChatGPT                  -0.098457            -0.053024  ...   \n",
       "AI_Tool_Claude                    0.018355             0.019293  ...   \n",
       "AI_Tool_Copilot                  -0.063553             0.015761  ...   \n",
       "AI_Tool_Gemini                    0.057411            -0.001071  ...   \n",
       "AI_Tool_Midjourney                0.076659            -0.016636  ...   \n",
       "AI_Tool_Other                     0.014847             0.028943  ...   \n",
       "\n",
       "                           Use_Project Work  Use_Projects  Use_Resume Writing  \\\n",
       "Year_of_Study                     -0.008500     -0.051430            0.024716   \n",
       "Daily_Usage_Hours                  0.038416     -0.084594            0.050600   \n",
       "Trust_in_AI_Tools                 -0.004208      0.016648            0.047427   \n",
       "Impact_on_Grades                  -0.009948      0.002235           -0.012425   \n",
       "Do_Professors_Allow_Use           -0.019314      0.036682           -0.042712   \n",
       "Awareness_Level                    0.024574      0.014521           -0.033978   \n",
       "Willing_to_Pay_for_Access         -0.011918     -0.017242            0.019389   \n",
       "Use_Assignments                   -0.012498     -0.197691           -0.159424   \n",
       "Use_Coding Help                   -0.023726     -0.200517           -0.141745   \n",
       "Use_Content Writing               -0.000444     -0.172854           -0.125874   \n",
       "Use_Doubt Solving                  0.013624     -0.179020            0.601919   \n",
       "Use_Exam Prep                     -0.098215     -0.145998           -0.171332   \n",
       "Use_Exam Preparation               0.104822     -0.094076            0.011248   \n",
       "Use_Learning new topics           -0.005022     -0.171474           -0.135747   \n",
       "Use_MCQ Practice                  -0.008222      0.794501           -0.155392   \n",
       "Use_Notes                         -0.098215     -0.145998           -0.171332   \n",
       "Use_Project Work                   1.000000     -0.100565           -0.000290   \n",
       "Use_Projects                      -0.100565      1.000000           -0.175431   \n",
       "Use_Resume Writing                -0.000290     -0.175431            1.000000   \n",
       "AI_Tool_Bard                       0.115981     -0.080736            0.041238   \n",
       "AI_Tool_ChatGPT                   -0.125369      0.132091           -0.060618   \n",
       "AI_Tool_Claude                     0.145321     -0.086166            0.051283   \n",
       "AI_Tool_Copilot                   -0.140541      0.096429           -0.005691   \n",
       "AI_Tool_Gemini                    -0.119423      0.075496           -0.089791   \n",
       "AI_Tool_Midjourney                -0.087974      0.015589           -0.061395   \n",
       "AI_Tool_Other                      0.180798     -0.085103            0.029736   \n",
       "\n",
       "                           AI_Tool_Bard  AI_Tool_ChatGPT  AI_Tool_Claude  \\\n",
       "Year_of_Study                  0.034448        -0.043521        0.030750   \n",
       "Daily_Usage_Hours              0.027914        -0.044830        0.020512   \n",
       "Trust_in_AI_Tools              0.012985         0.042708       -0.013583   \n",
       "Impact_on_Grades              -0.034130         0.035791       -0.033301   \n",
       "Do_Professors_Allow_Use       -0.006088         0.031920        0.003230   \n",
       "Awareness_Level               -0.026047         0.057712       -0.000741   \n",
       "Willing_to_Pay_for_Access      0.029503         0.005837       -0.016449   \n",
       "Use_Assignments                0.022876        -0.108475        0.005017   \n",
       "Use_Coding Help               -0.010168        -0.098457        0.018355   \n",
       "Use_Content Writing            0.029125        -0.053024        0.019293   \n",
       "Use_Doubt Solving              0.048395        -0.055495        0.016450   \n",
       "Use_Exam Prep                 -0.078850         0.139825       -0.084153   \n",
       "Use_Exam Preparation           0.099691        -0.131418        0.121649   \n",
       "Use_Learning new topics        0.037992         0.010690        0.013695   \n",
       "Use_MCQ Practice               0.017879         0.039579        0.014102   \n",
       "Use_Notes                     -0.078850         0.139825       -0.084153   \n",
       "Use_Project Work               0.115981        -0.125369        0.145321   \n",
       "Use_Projects                  -0.080736         0.132091       -0.086166   \n",
       "Use_Resume Writing             0.041238        -0.060618        0.051283   \n",
       "AI_Tool_Bard                   1.000000        -0.181673       -0.046536   \n",
       "AI_Tool_ChatGPT               -0.181673         1.000000       -0.193891   \n",
       "AI_Tool_Claude                -0.046536        -0.193891        1.000000   \n",
       "AI_Tool_Copilot               -0.177504         0.314641       -0.189442   \n",
       "AI_Tool_Gemini                -0.166922        -0.207406       -0.178148   \n",
       "AI_Tool_Midjourney            -0.070628        -0.294266       -0.075378   \n",
       "AI_Tool_Other                 -0.045962        -0.191498       -0.049053   \n",
       "\n",
       "                           AI_Tool_Copilot  AI_Tool_Gemini  \\\n",
       "Year_of_Study                    -0.008550        0.002923   \n",
       "Daily_Usage_Hours                -0.091600        0.017539   \n",
       "Trust_in_AI_Tools                 0.083427       -0.061107   \n",
       "Impact_on_Grades                 -0.022007        0.011087   \n",
       "Do_Professors_Allow_Use           0.016994       -0.004202   \n",
       "Awareness_Level                  -0.012254        0.005765   \n",
       "Willing_to_Pay_for_Access         0.011975       -0.010145   \n",
       "Use_Assignments                  -0.073581        0.079761   \n",
       "Use_Coding Help                  -0.063553        0.057411   \n",
       "Use_Content Writing               0.015761       -0.001071   \n",
       "Use_Doubt Solving                -0.011218       -0.097819   \n",
       "Use_Exam Prep                     0.057372        0.043204   \n",
       "Use_Exam Preparation             -0.104313       -0.108061   \n",
       "Use_Learning new topics          -0.010850       -0.043758   \n",
       "Use_MCQ Practice                  0.006726       -0.004026   \n",
       "Use_Notes                         0.057372        0.043204   \n",
       "Use_Project Work                 -0.140541       -0.119423   \n",
       "Use_Projects                      0.096429        0.075496   \n",
       "Use_Resume Writing               -0.005691       -0.089791   \n",
       "AI_Tool_Bard                     -0.177504       -0.166922   \n",
       "AI_Tool_ChatGPT                   0.314641       -0.207406   \n",
       "AI_Tool_Claude                   -0.189442       -0.178148   \n",
       "AI_Tool_Copilot                   1.000000       -0.189751   \n",
       "AI_Tool_Gemini                   -0.189751        1.000000   \n",
       "AI_Tool_Midjourney               -0.287515        0.423119   \n",
       "AI_Tool_Other                    -0.187105       -0.175950   \n",
       "\n",
       "                           AI_Tool_Midjourney  AI_Tool_Other  \n",
       "Year_of_Study                       -0.063732       0.007173  \n",
       "Daily_Usage_Hours                    0.009136       0.031434  \n",
       "Trust_in_AI_Tools                   -0.046083      -0.001726  \n",
       "Impact_on_Grades                    -0.027012      -0.001976  \n",
       "Do_Professors_Allow_Use             -0.042689      -0.023350  \n",
       "Awareness_Level                     -0.000422      -0.016379  \n",
       "Willing_to_Pay_for_Access           -0.018396      -0.008739  \n",
       "Use_Assignments                      0.081219       0.011021  \n",
       "Use_Coding Help                      0.076659       0.014847  \n",
       "Use_Content Writing                 -0.016636       0.028943  \n",
       "Use_Doubt Solving                   -0.065743       0.053646  \n",
       "Use_Exam Prep                        0.001937      -0.083114  \n",
       "Use_Exam Preparation                -0.082297       0.152997  \n",
       "Use_Learning new topics              0.007434       0.005519  \n",
       "Use_MCQ Practice                    -0.039478      -0.013321  \n",
       "Use_Notes                            0.001937      -0.083114  \n",
       "Use_Project Work                    -0.087974       0.180798  \n",
       "Use_Projects                         0.015589      -0.085103  \n",
       "Use_Resume Writing                  -0.061395       0.029736  \n",
       "AI_Tool_Bard                        -0.070628      -0.045962  \n",
       "AI_Tool_ChatGPT                     -0.294266      -0.191498  \n",
       "AI_Tool_Claude                      -0.075378      -0.049053  \n",
       "AI_Tool_Copilot                     -0.287515      -0.187105  \n",
       "AI_Tool_Gemini                       0.423119      -0.175950  \n",
       "AI_Tool_Midjourney                   1.000000      -0.074448  \n",
       "AI_Tool_Other                       -0.074448       1.000000  \n",
       "\n",
       "[26 rows x 26 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corr_df = df.corr(numeric_only=True)\n",
    "corr_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34ab1065-8354-4552-98ce-9dcd79e91d1b",
   "metadata": {},
   "source": [
    "There still doesn't appear to be any significant linear correlations between these newly numeric variables and the previously existing numeric variables. I'm going to try and consolidate these categories to see if this changes anything."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0ee85b14-b941-47cd-a7c4-9819eb6e8751",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Stream', 'Year_of_Study', 'Daily_Usage_Hours', 'Trust_in_AI_Tools', 'Impact_on_Grades', 'Do_Professors_Allow_Use', 'Preferred_AI_Tool', 'Awareness_Level', 'Willing_to_Pay_for_Access', 'Device_Used', 'Internet_Access', 'Use_Assignments', 'Use_Coding Help', 'Use_Content Writing', 'Use_Doubt Solving', 'Use_Exam Prep', 'Use_Exam Preparation', 'Use_Learning new topics', 'Use_MCQ Practice', 'Use_Notes', 'Use_Project Work', 'Use_Projects', 'Use_Resume Writing', 'AI_Tool_Bard', 'AI_Tool_ChatGPT', 'AI_Tool_Claude', 'AI_Tool_Copilot', 'AI_Tool_Gemini', 'AI_Tool_Midjourney', 'AI_Tool_Other']\n",
      "['Stream', 'Year_of_Study', 'Daily_Usage_Hours', 'Trust_in_AI_Tools', 'Impact_on_Grades', 'Do_Professors_Allow_Use', 'Preferred_AI_Tool', 'Awareness_Level', 'Willing_to_Pay_for_Access', 'Device_Used', 'Internet_Access', 'Use_Studying', 'Use_Work', 'Use_Learning', 'AI_Tool_Chatbot', 'AI_Tool_Coding', 'AI_Tool_Misc']\n"
     ]
    }
   ],
   "source": [
    "# consolidated df\n",
    "cdf = df.copy()\n",
    "\n",
    "print(list(cdf.columns))\n",
    "\n",
    "# Combine similar use cases to concentrate the data\n",
    "to_combine_1 = ['Use_Exam Prep', 'Use_Exam Preparation', 'Use_MCQ Practice']\n",
    "cdf['Use_Studying'] = (cdf[to_combine_1].sum(axis=1) > 0).astype(int)\n",
    "\n",
    "to_combine_2 = ['Use_Project Work', 'Use_Projects', 'Use_Assignments', 'Use_Content Writing', 'Use_Coding Help']\n",
    "cdf['Use_Work'] = (cdf[to_combine_2].sum(axis=1) > 0).astype(int)\n",
    "\n",
    "to_combine_3 = ['Use_Coding Help', 'Use_Doubt Solving', 'Use_Learning new topics', 'Use_Notes']\n",
    "cdf['Use_Learning'] = (cdf[to_combine_3].sum(axis=1) > 0).astype(int)\n",
    "\n",
    "to_combine_4 = ['AI_Tool_Bard', 'AI_Tool_ChatGPT', 'AI_Tool_Gemini']\n",
    "cdf['AI_Tool_Chatbot'] = (cdf[to_combine_4].sum(axis=1) > 0).astype(int)\n",
    "\n",
    "to_combine_5 = ['AI_Tool_Copilot', 'AI_Tool_Claude']\n",
    "cdf['AI_Tool_Coding'] = (cdf[to_combine_5].sum(axis=1) > 0).astype(int)\n",
    "\n",
    "to_combine_6 = ['AI_Tool_Midjourney', 'AI_Tool_Other']\n",
    "cdf['AI_Tool_Misc'] = (cdf[to_combine_6].sum(axis=1) > 0).astype(int)\n",
    "\n",
    "# Drop Irrelevant Columns\n",
    "to_drop = to_combine_1 + to_combine_2 + to_combine_3 + to_combine_4 + to_combine_5 + to_combine_6 + ['Use_Resume Writing']\n",
    "cdf = cdf.drop(columns=to_drop)\n",
    "\n",
    "print(list(cdf.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9f50202b-676f-4893-bcf3-e3a752af00ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year_of_Study</th>\n",
       "      <th>Daily_Usage_Hours</th>\n",
       "      <th>Trust_in_AI_Tools</th>\n",
       "      <th>Impact_on_Grades</th>\n",
       "      <th>Do_Professors_Allow_Use</th>\n",
       "      <th>Awareness_Level</th>\n",
       "      <th>Willing_to_Pay_for_Access</th>\n",
       "      <th>Use_Studying</th>\n",
       "      <th>Use_Work</th>\n",
       "      <th>Use_Learning</th>\n",
       "      <th>AI_Tool_Chatbot</th>\n",
       "      <th>AI_Tool_Coding</th>\n",
       "      <th>AI_Tool_Misc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Year_of_Study</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.007906</td>\n",
       "      <td>0.000744</td>\n",
       "      <td>-0.005867</td>\n",
       "      <td>0.053934</td>\n",
       "      <td>-0.012708</td>\n",
       "      <td>0.016681</td>\n",
       "      <td>-0.017881</td>\n",
       "      <td>-0.008679</td>\n",
       "      <td>0.007309</td>\n",
       "      <td>-0.034670</td>\n",
       "      <td>0.004629</td>\n",
       "      <td>-0.050111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Daily_Usage_Hours</th>\n",
       "      <td>0.007906</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.012369</td>\n",
       "      <td>0.057222</td>\n",
       "      <td>0.022814</td>\n",
       "      <td>0.005981</td>\n",
       "      <td>0.029144</td>\n",
       "      <td>-0.000620</td>\n",
       "      <td>-0.039890</td>\n",
       "      <td>0.038225</td>\n",
       "      <td>0.007840</td>\n",
       "      <td>-0.081875</td>\n",
       "      <td>0.026329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Trust_in_AI_Tools</th>\n",
       "      <td>0.000744</td>\n",
       "      <td>-0.012369</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.047310</td>\n",
       "      <td>-0.023196</td>\n",
       "      <td>0.039466</td>\n",
       "      <td>0.003888</td>\n",
       "      <td>-0.029835</td>\n",
       "      <td>0.013527</td>\n",
       "      <td>-0.055883</td>\n",
       "      <td>-0.029831</td>\n",
       "      <td>0.076739</td>\n",
       "      <td>-0.040311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Impact_on_Grades</th>\n",
       "      <td>-0.005867</td>\n",
       "      <td>0.057222</td>\n",
       "      <td>-0.047310</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.067598</td>\n",
       "      <td>-0.015721</td>\n",
       "      <td>0.010042</td>\n",
       "      <td>-0.021206</td>\n",
       "      <td>0.028122</td>\n",
       "      <td>0.000313</td>\n",
       "      <td>0.040438</td>\n",
       "      <td>-0.035940</td>\n",
       "      <td>-0.024198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Do_Professors_Allow_Use</th>\n",
       "      <td>0.053934</td>\n",
       "      <td>0.022814</td>\n",
       "      <td>-0.023196</td>\n",
       "      <td>0.067598</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.045744</td>\n",
       "      <td>0.002119</td>\n",
       "      <td>0.053772</td>\n",
       "      <td>0.024540</td>\n",
       "      <td>-0.011792</td>\n",
       "      <td>0.005492</td>\n",
       "      <td>0.018184</td>\n",
       "      <td>-0.050171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Awareness_Level</th>\n",
       "      <td>-0.012708</td>\n",
       "      <td>0.005981</td>\n",
       "      <td>0.039466</td>\n",
       "      <td>-0.015721</td>\n",
       "      <td>-0.045744</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.005995</td>\n",
       "      <td>-0.026344</td>\n",
       "      <td>0.000827</td>\n",
       "      <td>-0.013487</td>\n",
       "      <td>0.036802</td>\n",
       "      <td>-0.012436</td>\n",
       "      <td>-0.010020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Willing_to_Pay_for_Access</th>\n",
       "      <td>0.016681</td>\n",
       "      <td>0.029144</td>\n",
       "      <td>0.003888</td>\n",
       "      <td>0.010042</td>\n",
       "      <td>0.002119</td>\n",
       "      <td>-0.005995</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.005234</td>\n",
       "      <td>-0.015896</td>\n",
       "      <td>-0.008580</td>\n",
       "      <td>0.001876</td>\n",
       "      <td>0.004844</td>\n",
       "      <td>-0.020840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Use_Studying</th>\n",
       "      <td>-0.017881</td>\n",
       "      <td>-0.000620</td>\n",
       "      <td>-0.029835</td>\n",
       "      <td>-0.021206</td>\n",
       "      <td>0.053772</td>\n",
       "      <td>-0.026344</td>\n",
       "      <td>-0.005234</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.066364</td>\n",
       "      <td>-0.256647</td>\n",
       "      <td>0.026495</td>\n",
       "      <td>0.002957</td>\n",
       "      <td>-0.050616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Use_Work</th>\n",
       "      <td>-0.008679</td>\n",
       "      <td>-0.039890</td>\n",
       "      <td>0.013527</td>\n",
       "      <td>0.028122</td>\n",
       "      <td>0.024540</td>\n",
       "      <td>0.000827</td>\n",
       "      <td>-0.015896</td>\n",
       "      <td>-0.066364</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.489041</td>\n",
       "      <td>-0.053318</td>\n",
       "      <td>-0.037621</td>\n",
       "      <td>0.043721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Use_Learning</th>\n",
       "      <td>0.007309</td>\n",
       "      <td>0.038225</td>\n",
       "      <td>-0.055883</td>\n",
       "      <td>0.000313</td>\n",
       "      <td>-0.011792</td>\n",
       "      <td>-0.013487</td>\n",
       "      <td>-0.008580</td>\n",
       "      <td>-0.256647</td>\n",
       "      <td>-0.489041</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.032500</td>\n",
       "      <td>-0.020645</td>\n",
       "      <td>0.021152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AI_Tool_Chatbot</th>\n",
       "      <td>-0.034670</td>\n",
       "      <td>0.007840</td>\n",
       "      <td>-0.029831</td>\n",
       "      <td>0.040438</td>\n",
       "      <td>0.005492</td>\n",
       "      <td>0.036802</td>\n",
       "      <td>0.001876</td>\n",
       "      <td>0.026495</td>\n",
       "      <td>-0.053318</td>\n",
       "      <td>0.032500</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.413535</td>\n",
       "      <td>-0.052759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AI_Tool_Coding</th>\n",
       "      <td>0.004629</td>\n",
       "      <td>-0.081875</td>\n",
       "      <td>0.076739</td>\n",
       "      <td>-0.035940</td>\n",
       "      <td>0.018184</td>\n",
       "      <td>-0.012436</td>\n",
       "      <td>0.004844</td>\n",
       "      <td>0.002957</td>\n",
       "      <td>-0.037621</td>\n",
       "      <td>-0.020645</td>\n",
       "      <td>-0.413535</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.391304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AI_Tool_Misc</th>\n",
       "      <td>-0.050111</td>\n",
       "      <td>0.026329</td>\n",
       "      <td>-0.040311</td>\n",
       "      <td>-0.024198</td>\n",
       "      <td>-0.050171</td>\n",
       "      <td>-0.010020</td>\n",
       "      <td>-0.020840</td>\n",
       "      <td>-0.050616</td>\n",
       "      <td>0.043721</td>\n",
       "      <td>0.021152</td>\n",
       "      <td>-0.052759</td>\n",
       "      <td>-0.391304</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           Year_of_Study  Daily_Usage_Hours  \\\n",
       "Year_of_Study                   1.000000           0.007906   \n",
       "Daily_Usage_Hours               0.007906           1.000000   \n",
       "Trust_in_AI_Tools               0.000744          -0.012369   \n",
       "Impact_on_Grades               -0.005867           0.057222   \n",
       "Do_Professors_Allow_Use         0.053934           0.022814   \n",
       "Awareness_Level                -0.012708           0.005981   \n",
       "Willing_to_Pay_for_Access       0.016681           0.029144   \n",
       "Use_Studying                   -0.017881          -0.000620   \n",
       "Use_Work                       -0.008679          -0.039890   \n",
       "Use_Learning                    0.007309           0.038225   \n",
       "AI_Tool_Chatbot                -0.034670           0.007840   \n",
       "AI_Tool_Coding                  0.004629          -0.081875   \n",
       "AI_Tool_Misc                   -0.050111           0.026329   \n",
       "\n",
       "                           Trust_in_AI_Tools  Impact_on_Grades  \\\n",
       "Year_of_Study                       0.000744         -0.005867   \n",
       "Daily_Usage_Hours                  -0.012369          0.057222   \n",
       "Trust_in_AI_Tools                   1.000000         -0.047310   \n",
       "Impact_on_Grades                   -0.047310          1.000000   \n",
       "Do_Professors_Allow_Use            -0.023196          0.067598   \n",
       "Awareness_Level                     0.039466         -0.015721   \n",
       "Willing_to_Pay_for_Access           0.003888          0.010042   \n",
       "Use_Studying                       -0.029835         -0.021206   \n",
       "Use_Work                            0.013527          0.028122   \n",
       "Use_Learning                       -0.055883          0.000313   \n",
       "AI_Tool_Chatbot                    -0.029831          0.040438   \n",
       "AI_Tool_Coding                      0.076739         -0.035940   \n",
       "AI_Tool_Misc                       -0.040311         -0.024198   \n",
       "\n",
       "                           Do_Professors_Allow_Use  Awareness_Level  \\\n",
       "Year_of_Study                             0.053934        -0.012708   \n",
       "Daily_Usage_Hours                         0.022814         0.005981   \n",
       "Trust_in_AI_Tools                        -0.023196         0.039466   \n",
       "Impact_on_Grades                          0.067598        -0.015721   \n",
       "Do_Professors_Allow_Use                   1.000000        -0.045744   \n",
       "Awareness_Level                          -0.045744         1.000000   \n",
       "Willing_to_Pay_for_Access                 0.002119        -0.005995   \n",
       "Use_Studying                              0.053772        -0.026344   \n",
       "Use_Work                                  0.024540         0.000827   \n",
       "Use_Learning                             -0.011792        -0.013487   \n",
       "AI_Tool_Chatbot                           0.005492         0.036802   \n",
       "AI_Tool_Coding                            0.018184        -0.012436   \n",
       "AI_Tool_Misc                             -0.050171        -0.010020   \n",
       "\n",
       "                           Willing_to_Pay_for_Access  Use_Studying  Use_Work  \\\n",
       "Year_of_Study                               0.016681     -0.017881 -0.008679   \n",
       "Daily_Usage_Hours                           0.029144     -0.000620 -0.039890   \n",
       "Trust_in_AI_Tools                           0.003888     -0.029835  0.013527   \n",
       "Impact_on_Grades                            0.010042     -0.021206  0.028122   \n",
       "Do_Professors_Allow_Use                     0.002119      0.053772  0.024540   \n",
       "Awareness_Level                            -0.005995     -0.026344  0.000827   \n",
       "Willing_to_Pay_for_Access                   1.000000     -0.005234 -0.015896   \n",
       "Use_Studying                               -0.005234      1.000000 -0.066364   \n",
       "Use_Work                                   -0.015896     -0.066364  1.000000   \n",
       "Use_Learning                               -0.008580     -0.256647 -0.489041   \n",
       "AI_Tool_Chatbot                             0.001876      0.026495 -0.053318   \n",
       "AI_Tool_Coding                              0.004844      0.002957 -0.037621   \n",
       "AI_Tool_Misc                               -0.020840     -0.050616  0.043721   \n",
       "\n",
       "                           Use_Learning  AI_Tool_Chatbot  AI_Tool_Coding  \\\n",
       "Year_of_Study                  0.007309        -0.034670        0.004629   \n",
       "Daily_Usage_Hours              0.038225         0.007840       -0.081875   \n",
       "Trust_in_AI_Tools             -0.055883        -0.029831        0.076739   \n",
       "Impact_on_Grades               0.000313         0.040438       -0.035940   \n",
       "Do_Professors_Allow_Use       -0.011792         0.005492        0.018184   \n",
       "Awareness_Level               -0.013487         0.036802       -0.012436   \n",
       "Willing_to_Pay_for_Access     -0.008580         0.001876        0.004844   \n",
       "Use_Studying                  -0.256647         0.026495        0.002957   \n",
       "Use_Work                      -0.489041        -0.053318       -0.037621   \n",
       "Use_Learning                   1.000000         0.032500       -0.020645   \n",
       "AI_Tool_Chatbot                0.032500         1.000000       -0.413535   \n",
       "AI_Tool_Coding                -0.020645        -0.413535        1.000000   \n",
       "AI_Tool_Misc                   0.021152        -0.052759       -0.391304   \n",
       "\n",
       "                           AI_Tool_Misc  \n",
       "Year_of_Study                 -0.050111  \n",
       "Daily_Usage_Hours              0.026329  \n",
       "Trust_in_AI_Tools             -0.040311  \n",
       "Impact_on_Grades              -0.024198  \n",
       "Do_Professors_Allow_Use       -0.050171  \n",
       "Awareness_Level               -0.010020  \n",
       "Willing_to_Pay_for_Access     -0.020840  \n",
       "Use_Studying                  -0.050616  \n",
       "Use_Work                       0.043721  \n",
       "Use_Learning                   0.021152  \n",
       "AI_Tool_Chatbot               -0.052759  \n",
       "AI_Tool_Coding                -0.391304  \n",
       "AI_Tool_Misc                   1.000000  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corr_df = cdf.corr(numeric_only=True)\n",
    "corr_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e21addf-9005-46cb-901e-c87202a87ee0",
   "metadata": {},
   "source": [
    "Once again there is no evidence of substantial linear relationships between the variables, especially between the use cases and the impacct on grades, which has me concerned about whether I'll be able to determine anything from this data. However, it also presents the intriguing possibility that machine learning models might be able to figure out something about the data that more generic statistical methods can't determine.\n",
    "Additionally, there are other single-select categorical variables (Stream (major), Preferred AI Tool, Device Used, Internet Access) to still process that might have some relevant takeaways. I will be separately testing my consolidated dataframe and my normal data frame to see if my choices of consolidation are helpful at all."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77b54ca0-aa22-4b76-8b4d-6632022fd180",
   "metadata": {},
   "source": [
    "## Processing Single-Select Categorical Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "895755b7-d719-4e5a-95ac-deb05aaf8786",
   "metadata": {},
   "outputs": [],
   "source": [
    "# I need a function to calculate the correlation ratio between a categorical and numeric variable\n",
    "# I found this library which can calculate the 'eta-square', which is a correlation ratio used for categorical and numeric comparison\n",
    "import numpy as np\n",
    "def correlation_ratio(categories, values):\n",
    "\n",
    "    # Unique groups\n",
    "    groups = np.unique(categories)\n",
    "\n",
    "    # Means\n",
    "    group_means = []\n",
    "    group_sizes = []\n",
    "\n",
    "    for g in groups:\n",
    "        vals = values[categories == g]\n",
    "        group_means.append(vals.mean())\n",
    "        group_sizes.append(len(vals))\n",
    "\n",
    "    grand_mean = values.mean()\n",
    "\n",
    "    # Between-group variance\n",
    "    ss_between = np.sum([\n",
    "        group_sizes[i] * (group_means[i] - grand_mean)**2\n",
    "        for i in range(len(groups))\n",
    "    ])\n",
    "\n",
    "    # Total variance\n",
    "    ss_total = np.sum((values - grand_mean)**2)\n",
    "\n",
    "    return np.sqrt(ss_between / ss_total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a2fd1c28-bc0d-44c9-8c59-64207a84ac15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year_of_Study</th>\n",
       "      <th>Daily_Usage_Hours</th>\n",
       "      <th>Trust_in_AI_Tools</th>\n",
       "      <th>Impact_on_Grades</th>\n",
       "      <th>Do_Professors_Allow_Use</th>\n",
       "      <th>Awareness_Level</th>\n",
       "      <th>Willing_to_Pay_for_Access</th>\n",
       "      <th>Use_Assignments</th>\n",
       "      <th>Use_Coding Help</th>\n",
       "      <th>Use_Content Writing</th>\n",
       "      <th>...</th>\n",
       "      <th>Use_Project Work</th>\n",
       "      <th>Use_Projects</th>\n",
       "      <th>Use_Resume Writing</th>\n",
       "      <th>AI_Tool_Bard</th>\n",
       "      <th>AI_Tool_ChatGPT</th>\n",
       "      <th>AI_Tool_Claude</th>\n",
       "      <th>AI_Tool_Copilot</th>\n",
       "      <th>AI_Tool_Gemini</th>\n",
       "      <th>AI_Tool_Midjourney</th>\n",
       "      <th>AI_Tool_Other</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.097351</td>\n",
       "      <td>0.138912</td>\n",
       "      <td>0.044403</td>\n",
       "      <td>0.071123</td>\n",
       "      <td>0.052085</td>\n",
       "      <td>0.103040</td>\n",
       "      <td>0.067345</td>\n",
       "      <td>0.094649</td>\n",
       "      <td>0.096420</td>\n",
       "      <td>0.117349</td>\n",
       "      <td>...</td>\n",
       "      <td>0.060620</td>\n",
       "      <td>0.117728</td>\n",
       "      <td>0.139187</td>\n",
       "      <td>0.080308</td>\n",
       "      <td>0.150288</td>\n",
       "      <td>0.080294</td>\n",
       "      <td>0.114345</td>\n",
       "      <td>0.088983</td>\n",
       "      <td>0.078867</td>\n",
       "      <td>0.036461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.056047</td>\n",
       "      <td>0.090722</td>\n",
       "      <td>0.046742</td>\n",
       "      <td>0.057018</td>\n",
       "      <td>0.091542</td>\n",
       "      <td>0.040309</td>\n",
       "      <td>0.032495</td>\n",
       "      <td>0.072894</td>\n",
       "      <td>0.082092</td>\n",
       "      <td>0.098029</td>\n",
       "      <td>...</td>\n",
       "      <td>0.249672</td>\n",
       "      <td>0.122749</td>\n",
       "      <td>0.068337</td>\n",
       "      <td>0.191104</td>\n",
       "      <td>0.162062</td>\n",
       "      <td>0.180937</td>\n",
       "      <td>0.187892</td>\n",
       "      <td>0.145142</td>\n",
       "      <td>0.114370</td>\n",
       "      <td>0.195415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.034806</td>\n",
       "      <td>0.029133</td>\n",
       "      <td>0.054088</td>\n",
       "      <td>0.013351</td>\n",
       "      <td>0.027254</td>\n",
       "      <td>0.046158</td>\n",
       "      <td>0.005385</td>\n",
       "      <td>0.062395</td>\n",
       "      <td>0.055560</td>\n",
       "      <td>0.007400</td>\n",
       "      <td>...</td>\n",
       "      <td>0.023893</td>\n",
       "      <td>0.055585</td>\n",
       "      <td>0.030483</td>\n",
       "      <td>0.008462</td>\n",
       "      <td>0.022104</td>\n",
       "      <td>0.016947</td>\n",
       "      <td>0.030372</td>\n",
       "      <td>0.040130</td>\n",
       "      <td>0.036924</td>\n",
       "      <td>0.034783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.032487</td>\n",
       "      <td>0.027332</td>\n",
       "      <td>0.008118</td>\n",
       "      <td>0.002514</td>\n",
       "      <td>0.010475</td>\n",
       "      <td>0.005411</td>\n",
       "      <td>0.010546</td>\n",
       "      <td>0.019296</td>\n",
       "      <td>0.028877</td>\n",
       "      <td>0.034596</td>\n",
       "      <td>...</td>\n",
       "      <td>0.019928</td>\n",
       "      <td>0.019362</td>\n",
       "      <td>0.022976</td>\n",
       "      <td>0.042424</td>\n",
       "      <td>0.015000</td>\n",
       "      <td>0.013480</td>\n",
       "      <td>0.025715</td>\n",
       "      <td>0.006552</td>\n",
       "      <td>0.005083</td>\n",
       "      <td>0.017216</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4 rows Ã— 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Year_of_Study  Daily_Usage_Hours  Trust_in_AI_Tools  Impact_on_Grades  \\\n",
       "0       0.097351           0.138912           0.044403          0.071123   \n",
       "1       0.056047           0.090722           0.046742          0.057018   \n",
       "2       0.034806           0.029133           0.054088          0.013351   \n",
       "3       0.032487           0.027332           0.008118          0.002514   \n",
       "\n",
       "   Do_Professors_Allow_Use  Awareness_Level  Willing_to_Pay_for_Access  \\\n",
       "0                 0.052085         0.103040                   0.067345   \n",
       "1                 0.091542         0.040309                   0.032495   \n",
       "2                 0.027254         0.046158                   0.005385   \n",
       "3                 0.010475         0.005411                   0.010546   \n",
       "\n",
       "   Use_Assignments  Use_Coding Help  Use_Content Writing  ...  \\\n",
       "0         0.094649         0.096420             0.117349  ...   \n",
       "1         0.072894         0.082092             0.098029  ...   \n",
       "2         0.062395         0.055560             0.007400  ...   \n",
       "3         0.019296         0.028877             0.034596  ...   \n",
       "\n",
       "   Use_Project Work  Use_Projects  Use_Resume Writing  AI_Tool_Bard  \\\n",
       "0          0.060620      0.117728            0.139187      0.080308   \n",
       "1          0.249672      0.122749            0.068337      0.191104   \n",
       "2          0.023893      0.055585            0.030483      0.008462   \n",
       "3          0.019928      0.019362            0.022976      0.042424   \n",
       "\n",
       "   AI_Tool_ChatGPT  AI_Tool_Claude  AI_Tool_Copilot  AI_Tool_Gemini  \\\n",
       "0         0.150288        0.080294         0.114345        0.088983   \n",
       "1         0.162062        0.180937         0.187892        0.145142   \n",
       "2         0.022104        0.016947         0.030372        0.040130   \n",
       "3         0.015000        0.013480         0.025715        0.006552   \n",
       "\n",
       "   AI_Tool_Midjourney  AI_Tool_Other  \n",
       "0            0.078867       0.036461  \n",
       "1            0.114370       0.195415  \n",
       "2            0.036924       0.034783  \n",
       "3            0.005083       0.017216  \n",
       "\n",
       "[4 rows x 26 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numeric_cols = df.select_dtypes(include=[np.number]).columns\n",
    "categoric_cols = ['Stream', 'Preferred_AI_Tool', 'Device_Used', 'Internet_Access']\n",
    "\n",
    "cat_corr_arr = np.zeros((len(categoric_cols), len(numeric_cols)))\n",
    "\n",
    "for index1, cat in enumerate(categoric_cols):\n",
    "    for index2, num in enumerate(numeric_cols):\n",
    "        eta = correlation_ratio(np.array(df[cat]), np.array(df[num]))\n",
    "        cat_corr_arr[index1][index2] = eta\n",
    "\n",
    "cat_corr_df = pd.DataFrame(cat_corr_arr, columns=numeric_cols)\n",
    "cat_corr_df\n",
    "# Note that 0 is Stream, 1 is Preferred AI Tool, 2 is Device Used, 3 is Internet Access"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "caa96ef4-00f0-439d-9220-ca9a55b0176c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year_of_Study</th>\n",
       "      <th>Daily_Usage_Hours</th>\n",
       "      <th>Trust_in_AI_Tools</th>\n",
       "      <th>Impact_on_Grades</th>\n",
       "      <th>Do_Professors_Allow_Use</th>\n",
       "      <th>Awareness_Level</th>\n",
       "      <th>Willing_to_Pay_for_Access</th>\n",
       "      <th>Use_Studying</th>\n",
       "      <th>Use_Work</th>\n",
       "      <th>Use_Learning</th>\n",
       "      <th>AI_Tool_Chatbot</th>\n",
       "      <th>AI_Tool_Coding</th>\n",
       "      <th>AI_Tool_Misc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.097351</td>\n",
       "      <td>0.138912</td>\n",
       "      <td>0.044403</td>\n",
       "      <td>0.071123</td>\n",
       "      <td>0.052085</td>\n",
       "      <td>0.103040</td>\n",
       "      <td>0.067345</td>\n",
       "      <td>0.105693</td>\n",
       "      <td>0.045772</td>\n",
       "      <td>0.066796</td>\n",
       "      <td>0.104661</td>\n",
       "      <td>0.105475</td>\n",
       "      <td>0.079186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.056047</td>\n",
       "      <td>0.090722</td>\n",
       "      <td>0.046742</td>\n",
       "      <td>0.057018</td>\n",
       "      <td>0.091542</td>\n",
       "      <td>0.040309</td>\n",
       "      <td>0.032495</td>\n",
       "      <td>0.051573</td>\n",
       "      <td>0.096196</td>\n",
       "      <td>0.084593</td>\n",
       "      <td>0.164060</td>\n",
       "      <td>0.117877</td>\n",
       "      <td>0.062914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.034806</td>\n",
       "      <td>0.029133</td>\n",
       "      <td>0.054088</td>\n",
       "      <td>0.013351</td>\n",
       "      <td>0.027254</td>\n",
       "      <td>0.046158</td>\n",
       "      <td>0.005385</td>\n",
       "      <td>0.075284</td>\n",
       "      <td>0.023943</td>\n",
       "      <td>0.048122</td>\n",
       "      <td>0.033352</td>\n",
       "      <td>0.022856</td>\n",
       "      <td>0.038979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.032487</td>\n",
       "      <td>0.027332</td>\n",
       "      <td>0.008118</td>\n",
       "      <td>0.002514</td>\n",
       "      <td>0.010475</td>\n",
       "      <td>0.005411</td>\n",
       "      <td>0.010546</td>\n",
       "      <td>0.024865</td>\n",
       "      <td>0.009668</td>\n",
       "      <td>0.042592</td>\n",
       "      <td>0.006522</td>\n",
       "      <td>0.019759</td>\n",
       "      <td>0.005825</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Year_of_Study  Daily_Usage_Hours  Trust_in_AI_Tools  Impact_on_Grades  \\\n",
       "0       0.097351           0.138912           0.044403          0.071123   \n",
       "1       0.056047           0.090722           0.046742          0.057018   \n",
       "2       0.034806           0.029133           0.054088          0.013351   \n",
       "3       0.032487           0.027332           0.008118          0.002514   \n",
       "\n",
       "   Do_Professors_Allow_Use  Awareness_Level  Willing_to_Pay_for_Access  \\\n",
       "0                 0.052085         0.103040                   0.067345   \n",
       "1                 0.091542         0.040309                   0.032495   \n",
       "2                 0.027254         0.046158                   0.005385   \n",
       "3                 0.010475         0.005411                   0.010546   \n",
       "\n",
       "   Use_Studying  Use_Work  Use_Learning  AI_Tool_Chatbot  AI_Tool_Coding  \\\n",
       "0      0.105693  0.045772      0.066796         0.104661        0.105475   \n",
       "1      0.051573  0.096196      0.084593         0.164060        0.117877   \n",
       "2      0.075284  0.023943      0.048122         0.033352        0.022856   \n",
       "3      0.024865  0.009668      0.042592         0.006522        0.019759   \n",
       "\n",
       "   AI_Tool_Misc  \n",
       "0      0.079186  \n",
       "1      0.062914  \n",
       "2      0.038979  \n",
       "3      0.005825  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numeric_cols = cdf.select_dtypes(include=[np.number]).columns\n",
    "categoric_cols = ['Stream', 'Preferred_AI_Tool', 'Device_Used', 'Internet_Access']\n",
    "\n",
    "cat_corr_arr = np.zeros((len(categoric_cols), len(numeric_cols)))\n",
    "\n",
    "for index1, cat in enumerate(categoric_cols):\n",
    "    for index2, num in enumerate(numeric_cols):\n",
    "        eta = correlation_ratio(cdf[cat], cdf[num])\n",
    "        cat_corr_arr[index1][index2] = eta\n",
    "\n",
    "cat_corr_cdf = pd.DataFrame(cat_corr_arr, columns=numeric_cols)\n",
    "cat_corr_cdf\n",
    "# Note that 0 is Stream, 1 is Preferred AI Tool, 2 is Device Used, 3 is Internet Access"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b2dedee-0de3-4d84-853c-7945310fe8e3",
   "metadata": {},
   "source": [
    "This is a table of correlation coefficients that show how much of the variation in a numeric variable is predicted by the variation in categories. While these numbers are slightly larger than others for both my normal data frame and the consolidated one, I'm still not seeing any significant enough impacts on things like \"Impact_on_Grades\" to give me confidence that I can reliably predict these variables somehow. The only way to see is by training models at this point."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b87dc5c4-de16-403a-839d-0962164a0596",
   "metadata": {},
   "source": [
    "# Training Models on the Dataset\n",
    "Now I'm going to train models to try to predict the impact on grades students reported AI having on them.\n",
    "### One-Hot Encoding Categorical Variables\n",
    "Most of the data is ready to be put in ML models, but the categorical variables still need to be one-hot encoded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "65aacf10-033f-4891-b388-9d85549b7d42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year_of_Study</th>\n",
       "      <th>Daily_Usage_Hours</th>\n",
       "      <th>Trust_in_AI_Tools</th>\n",
       "      <th>Impact_on_Grades</th>\n",
       "      <th>Do_Professors_Allow_Use</th>\n",
       "      <th>Awareness_Level</th>\n",
       "      <th>Willing_to_Pay_for_Access</th>\n",
       "      <th>Use_Assignments</th>\n",
       "      <th>Use_Coding Help</th>\n",
       "      <th>Use_Content Writing</th>\n",
       "      <th>...</th>\n",
       "      <th>Stream_Science</th>\n",
       "      <th>Preferred_AI_Tool_ChatGPT</th>\n",
       "      <th>Preferred_AI_Tool_Claude</th>\n",
       "      <th>Preferred_AI_Tool_Copilot</th>\n",
       "      <th>Preferred_AI_Tool_Gemini</th>\n",
       "      <th>Preferred_AI_Tool_Other</th>\n",
       "      <th>Device_Used_Mobile</th>\n",
       "      <th>Device_Used_Tablet</th>\n",
       "      <th>Internet_Access_Medium</th>\n",
       "      <th>Internet_Access_Poor</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>0.9</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>3.4</td>\n",
       "      <td>3</td>\n",
       "      <td>-3</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>3.6</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>2.9</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 44 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Year_of_Study  Daily_Usage_Hours  Trust_in_AI_Tools  Impact_on_Grades  \\\n",
       "0              4                0.9                  2                 2   \n",
       "1              2                3.4                  3                -3   \n",
       "2              2                3.6                  5                 0   \n",
       "3              2                2.9                  5                 2   \n",
       "4              1                0.9                  1                 3   \n",
       "\n",
       "   Do_Professors_Allow_Use  Awareness_Level  Willing_to_Pay_for_Access  \\\n",
       "0                        0                9                          1   \n",
       "1                        1                6                          0   \n",
       "2                        0                1                          0   \n",
       "3                        1                5                          0   \n",
       "4                        1                8                          1   \n",
       "\n",
       "   Use_Assignments  Use_Coding Help  Use_Content Writing  ...  Stream_Science  \\\n",
       "0                1                1                    0  ...               0   \n",
       "1                0                0                    0  ...               0   \n",
       "2                0                0                    0  ...               1   \n",
       "3                0                0                    1  ...               0   \n",
       "4                0                0                    0  ...               1   \n",
       "\n",
       "   Preferred_AI_Tool_ChatGPT  Preferred_AI_Tool_Claude  \\\n",
       "0                          0                         0   \n",
       "1                          0                         0   \n",
       "2                          0                         0   \n",
       "3                          0                         0   \n",
       "4                          0                         0   \n",
       "\n",
       "   Preferred_AI_Tool_Copilot  Preferred_AI_Tool_Gemini  \\\n",
       "0                          1                         0   \n",
       "1                          0                         0   \n",
       "2                          0                         1   \n",
       "3                          0                         1   \n",
       "4                          0                         0   \n",
       "\n",
       "   Preferred_AI_Tool_Other  Device_Used_Mobile  Device_Used_Tablet  \\\n",
       "0                        0                   1                   0   \n",
       "1                        1                   0                   0   \n",
       "2                        0                   0                   1   \n",
       "3                        0                   0                   0   \n",
       "4                        1                   0                   0   \n",
       "\n",
       "   Internet_Access_Medium  Internet_Access_Poor  \n",
       "0                       0                     1  \n",
       "1                       0                     1  \n",
       "2                       0                     1  \n",
       "3                       0                     0  \n",
       "4                       1                     0  \n",
       "\n",
       "[5 rows x 44 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.get_dummies(df, columns=categoric_cols, drop_first=True)\n",
    "bool_cols = df.select_dtypes(include='bool').columns\n",
    "df[bool_cols] = df[bool_cols].astype(int)\n",
    "\n",
    "cdf = pd.get_dummies(cdf, columns=categoric_cols, drop_first=True)\n",
    "bool_cols = cdf.select_dtypes(include='bool').columns\n",
    "cdf[bool_cols] = cdf[bool_cols].astype(int)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f362088-4e52-4442-a1af-3068126462cf",
   "metadata": {},
   "source": [
    "## Split Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "43d4d83d-e7ef-457d-a926-467d1f3bf729",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Replace with your actual target column\n",
    "target = 'Impact_on_Grades'\n",
    "\n",
    "X = df.drop(columns=[target])\n",
    "y = df[target]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=20\n",
    ")\n",
    "\n",
    "cX = cdf.drop(columns=[target])\n",
    "cy = cdf[target]\n",
    "\n",
    "cX_train, cX_test, cy_train, cy_test = train_test_split(\n",
    "    cX, cy, test_size=0.2, random_state=20\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9efbbeb6-657e-45da-825a-b9a2351dfbd8",
   "metadata": {},
   "source": [
    "## Mean Model\n",
    "In order to see if my model is better than simply selecting the mean of the impact on grades variable, I'm calculating the MSE of the mean versus other values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "aef1a839-26cc-4746-b1d0-1a0d99e256db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.618694010778351\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "grade_impact_array = df['Impact_on_Grades'].to_numpy()\n",
    "\n",
    "mean_total = 0\n",
    "for entry in grade_impact_array:\n",
    "    mean_total += entry\n",
    "real_mean = mean_total / len(grade_impact_array)\n",
    "real_mean_arr = [real_mean] * len(grade_impact_array)\n",
    "\n",
    "mean_mse = mean_squared_error(grade_impact_array, real_mean_arr)\n",
    "print(mean_mse)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51ddc19c-a63d-4aae-9067-a11bba80015c",
   "metadata": {},
   "source": [
    "If the models are better at predicting the grade impact than simply choosing the mean (which happens to be super close to 0), then their MSE will be less than this value.\n",
    "## Linear Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9dd8c1d2-75fb-45d7-beba-fb71cadf478f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr_mse: 5.738718681638612\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "reg = LinearRegression()\n",
    "reg.fit(X_train, y_train)\n",
    "\n",
    "pred = reg.predict(X_test)\n",
    "\n",
    "lr_mse = mean_squared_error(y_test, pred)\n",
    "print(\"lr_mse:\", lr_mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bebc1f2e-3f7f-4a5d-b1cb-3a9c7847f2b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "coef_df = pd.DataFrame({\n",
    "    \"feature\": X.columns,\n",
    "    \"coef\": reg.coef_\n",
    "}).sort_values(\"coef\", ascending=False)\n",
    "\n",
    "#print(coef_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d3d35c2-371a-4ad7-9173-926c50adb0f8",
   "metadata": {},
   "source": [
    "Comparing the mean MSE of **~5.619** and the unconsolidated linear regression MSE of **~5.7387** show that even with all 42 columns of data, linear regression cannot find any features whatsoever to latch on to that improve its ability to predict the impact on grades. This makes a lot of sense, given that no correlations were significant determiners of the impact on grades. I'm going to try with my consolidated multi-select categories to see if it improves at all."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bebe61da-73bf-407e-ad46-21e534d48867",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "clr_mse: 5.761893785870103\n"
     ]
    }
   ],
   "source": [
    "creg = LinearRegression()\n",
    "creg.fit(cX_train, cy_train)\n",
    "\n",
    "cpred = creg.predict(cX_test)\n",
    "\n",
    "clr_mse = mean_squared_error(cy_test, cpred)\n",
    "print(\"clr_mse:\", clr_mse)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcfab73c-4274-4c6a-80d2-2fb0d8419aa6",
   "metadata": {},
   "source": [
    "The consolidation of categories didn't help this model whatsoever.\n",
    "## Random Forests Model\n",
    "Now it's time to see if a random forest model can demonstrate any improved ability to determine the impact on grades these variables can have"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4da2d2e6-ae5f-478a-ab2e-a00be1b13225",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "random forest mse: 3.647471715076072\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# these are mostly the default parameters, and the ones I had the most success with\n",
    "rf = RandomForestRegressor(\n",
    "    n_estimators=200,\n",
    "    max_depth = None,\n",
    "    min_samples_split=2,\n",
    "    min_samples_leaf=1,\n",
    "    max_features=1.0,\n",
    "    random_state=20\n",
    ")\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "rf_pred = rf.predict(X_test)\n",
    "\n",
    "rf_mse = mean_squared_error(y_test, rf_pred)\n",
    "\n",
    "print(\"random forest mse:\", rf_mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0892cd92-e9a4-4682-aecb-b562766193fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "consolidated random forest mse: 3.750715110650069\n"
     ]
    }
   ],
   "source": [
    "crf = RandomForestRegressor(\n",
    "    n_estimators=200,\n",
    "    max_depth = None,\n",
    "    min_samples_split=2,\n",
    "    min_samples_leaf=1,\n",
    "    max_features=1.0,\n",
    "    random_state=20\n",
    ")\n",
    "crf.fit(cX_train, cy_train)\n",
    "\n",
    "crf_pred = crf.predict(cX_test)\n",
    "\n",
    "crf_mse = mean_squared_error(cy_test, crf_pred)\n",
    "\n",
    "print(\"consolidated random forest mse:\", crf_mse)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7de20b59-962b-4e06-9131-c267e9abe295",
   "metadata": {},
   "source": [
    "It appears that the random forests model was able to improve upon both a simple mean prediction and linear regression, but not by too much. Later I will use SHAP to figure out which variables had the most impact.\n",
    "Additionally, it appears that the consolidation may have slightly hurt the model's ability to make predictions. This does make sense, because consolidating reduced the amount of data, and I'm curious to figure out how being more specific about the use cases and models used matters.\n",
    "\n",
    "## Feed-Forward Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6f699d4a-641a-4c8a-8580-fb38109bfeef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2891, 43)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(X_train.shape)\n",
    "# convert to tensors for faster math\n",
    "X_train_t = torch.tensor(X_train.values, dtype=torch.float32)\n",
    "y_train_t = torch.tensor(y_train.values, dtype=torch.float32).reshape(-1, 1)\n",
    "\n",
    "X_test_t = torch.tensor(X_test.values, dtype=torch.float32)\n",
    "y_test_t = torch.tensor(y_test.values, dtype=torch.float32).reshape(-1, 1)\n",
    "\n",
    "cX_train_t = torch.tensor(cX_train.values, dtype=torch.float32)\n",
    "cy_train_t = torch.tensor(cy_train.values, dtype=torch.float32).reshape(-1, 1)\n",
    "\n",
    "cX_test_t = torch.tensor(cX_test.values, dtype=torch.float32)\n",
    "cy_test_t = torch.tensor(cy_test.values, dtype=torch.float32).reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e81d1010-c7eb-427d-a9d8-08cba268c725",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# modified from codelets and labs\n",
    "class FNNModel(torch.nn.Module):\n",
    "    def __init__(self, num_inputs, num_outputs, num_hiddens, sigma=0.01):\n",
    "        super().__init__()\n",
    "\n",
    "        self.num_inputs = num_inputs\n",
    "\n",
    "        self.W1 = torch.nn.Parameter(torch.randn(num_inputs, num_hiddens) * sigma)\n",
    "        self.b1 = torch.nn.Parameter(torch.zeros(num_hiddens))\n",
    "        self.W2 = torch.nn.Parameter(torch.randn(num_hiddens, num_outputs) * sigma)\n",
    "        self.b2 = torch.nn.Parameter(torch.zeros(num_outputs))\n",
    "\n",
    "        self.epoch_loss_list = np.array([])\n",
    "\n",
    "    def forward(self, X):\n",
    "        X = X.to(torch.float32)\n",
    "        X = X.reshape((-1, self.num_inputs))\n",
    "        H1 = torch.relu(torch.matmul(X, self.W1) + self.b1)\n",
    "        unactivated_output = torch.matmul(H1, self.W2) + self.b2\n",
    "        return unactivated_output\n",
    "\n",
    "def train(model, X_train, y_train, X_test, y_test, epochs, batch_size, my_lr, text_output=False):\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=my_lr)\n",
    "    loss_fn = torch.nn.MSELoss()\n",
    "\n",
    "    training_loss_arr = []\n",
    "    validation_loss_arr = []\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        epoch_training_loss_sum = 0\n",
    "        epoch_validation_loss_sum = 0\n",
    "\n",
    "        # training per epoch\n",
    "        for start in range(0, X_train.shape[0], batch_size):\n",
    "            end = start + batch_size\n",
    "            x_batch = X_train[start:end]\n",
    "            y_batch = y_train[start:end]\n",
    "            \n",
    "            predicted_y = model(x_batch)\n",
    "            training_loss = loss_fn(predicted_y, y_batch)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            training_loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            epoch_training_loss_sum += training_loss.item()\n",
    "\n",
    "        # validation per epoch\n",
    "        with torch.no_grad():\n",
    "            for start in range(0, X_test.shape[0], batch_size):\n",
    "                end = start + batch_size\n",
    "                x_batch = X_test[start:end]\n",
    "                y_batch = y_test[start:end]\n",
    "                \n",
    "                predicted_y = model(x_batch)\n",
    "                validation_loss = loss_fn(predicted_y, y_batch)\n",
    "                epoch_validation_loss_sum += validation_loss.item()\n",
    "\n",
    "        if (epoch % 10 == 0 and text_output):\n",
    "            print(f\"epoch {epoch}, training loss: {epoch_training_loss_sum}, validation loss: {epoch_validation_loss_sum * 4}\")\n",
    "        training_loss_arr.append(epoch_training_loss_sum)\n",
    "        validation_loss_arr.append(epoch_validation_loss_sum * 4)\n",
    "    plt.plot(training_loss_arr, label='Training Loss')\n",
    "    plt.plot(validation_loss_arr, label='Validation Loss')\n",
    "    \n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title('Training vs Validation Loss')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "858af740-3205-44be-b8da-8f41c5ff23fc",
   "metadata": {},
   "source": [
    "### Tuning Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "860c121d-7f76-4779-a80c-c7330356b420",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = FNNModel(X_train.shape[1], 1, 10)\n",
    "#train(model, X_train_t, y_train_t, X_test_t, y_test_t, 500, 64, 0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b637b3e8-a32d-4762-9a4c-a004a2af194b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = FNNModel(cX_train.shape[1], 1, 10)\n",
    "#train(model, cX_train_t, cy_train_t, cX_test_t, cy_test_t, 500, 64, 0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "97eb30fc-0a19-4422-a417-bdc3b126b2c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = FNNModel(cX_train.shape[1], 1, 4)\n",
    "#train(model, cX_train_t, cy_train_t, cX_test_t, cy_test_t, 500, 64, 0.005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fbf1eb40-6766-40fe-a1cd-6376f73ed471",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = FNNModel(cX_train.shape[1], 1, 10)\n",
    "#train(model, cX_train_t, cy_train_t, cX_test_t, cy_test_t, 50, 8, 0.005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f39938d5-a277-44e2-97bf-b47a5bf32eb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = FNNModel(cX_train.shape[1], 1, 5)\n",
    "#train(model, cX_train_t, cy_train_t, cX_test_t, cy_test_t, 100, 8, 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3758fa0f-d7c0-47f0-b4f3-76fd51db6818",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = FNNModel(cX_train.shape[1], 1, 40)\n",
    "#train(model, cX_train_t, cy_train_t, cX_test_t, cy_test_t, 100, 8, 0.005)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0d38e5e-e18c-46fb-a569-d5e2b3f2db77",
   "metadata": {},
   "source": [
    "After a lot of experimentation with the hyperparameters, I was unable to improve the validation loss beyond about 5% less than the first epoch, and even then the hyperparameters that worked were very finnicky. It seems that FNNs are incapable of discovering generalizable features in the dataset. In my next milestone, I will try to work with FNNs a bit more in Keras, where it'll be easier to manipulate parameters and experiment with dropout. I'll also look more into random forests and what they're focusing on to get some improvement in predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6494e41-9791-40b7-a866-eff2f63f8108",
   "metadata": {},
   "source": [
    "## Testing FNNs in Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c5be8470-de3c-4749-96b5-a0a1cdf7d513",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: TF_ENABLE_ONEDNN_OPTS=0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-02 15:51:43.149887: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "# These env variables were necessary for me to get no errors\n",
    "%env TF_ENABLE_ONEDNN_OPTS=0\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e29e3e05-e482-4e56-b36c-edb18ca90f1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_keras_nn(n_features, n_predictions):\n",
    "    # Input layer\n",
    "    input = keras.layers.Input(shape=(n_features,), name='input')\n",
    "\n",
    "    # Dense layers\n",
    "    layers_dense = keras.layers.Dense(10, 'relu')(input)\n",
    "    layers_dense = keras.layers.Dense(10, 'relu')(layers_dense)\n",
    "\n",
    "    # Output layer\n",
    "    output = keras.layers.Dense(n_predictions)(layers_dense)\n",
    "\n",
    "    # Defining the model and compiling it\n",
    "    return Model(inputs=input, outputs=output, name=\"keras_fnn_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c6a88a6e-c152-4edb-a0ff-d8fa8f52f7d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "91/91 - 1s - 9ms/step - loss: 5.7262 - root_mean_squared_error: 2.3929 - val_loss: 5.8165 - val_root_mean_squared_error: 2.4117\n",
      "Epoch 2/100\n",
      "91/91 - 0s - 2ms/step - loss: 5.5954 - root_mean_squared_error: 2.3655 - val_loss: 5.7681 - val_root_mean_squared_error: 2.4017\n",
      "Epoch 3/100\n",
      "91/91 - 0s - 2ms/step - loss: 5.5443 - root_mean_squared_error: 2.3546 - val_loss: 5.7230 - val_root_mean_squared_error: 2.3923\n",
      "Epoch 4/100\n",
      "91/91 - 0s - 2ms/step - loss: 5.5101 - root_mean_squared_error: 2.3474 - val_loss: 5.7026 - val_root_mean_squared_error: 2.3880\n",
      "Epoch 5/100\n",
      "91/91 - 0s - 2ms/step - loss: 5.4753 - root_mean_squared_error: 2.3399 - val_loss: 5.6779 - val_root_mean_squared_error: 2.3828\n",
      "Epoch 6/100\n",
      "91/91 - 0s - 2ms/step - loss: 5.4430 - root_mean_squared_error: 2.3330 - val_loss: 5.6651 - val_root_mean_squared_error: 2.3801\n",
      "Epoch 7/100\n",
      "91/91 - 0s - 2ms/step - loss: 5.4062 - root_mean_squared_error: 2.3251 - val_loss: 5.6391 - val_root_mean_squared_error: 2.3747\n",
      "Epoch 8/100\n",
      "91/91 - 0s - 2ms/step - loss: 5.3756 - root_mean_squared_error: 2.3185 - val_loss: 5.6142 - val_root_mean_squared_error: 2.3694\n",
      "Epoch 9/100\n",
      "91/91 - 0s - 2ms/step - loss: 5.3341 - root_mean_squared_error: 2.3096 - val_loss: 5.6155 - val_root_mean_squared_error: 2.3697\n",
      "Epoch 10/100\n",
      "91/91 - 0s - 2ms/step - loss: 5.2875 - root_mean_squared_error: 2.2995 - val_loss: 5.6524 - val_root_mean_squared_error: 2.3775\n",
      "Epoch 11/100\n",
      "91/91 - 0s - 2ms/step - loss: 5.2610 - root_mean_squared_error: 2.2937 - val_loss: 5.5878 - val_root_mean_squared_error: 2.3639\n",
      "Epoch 12/100\n",
      "91/91 - 0s - 2ms/step - loss: 5.2105 - root_mean_squared_error: 2.2827 - val_loss: 5.6339 - val_root_mean_squared_error: 2.3736\n",
      "Epoch 13/100\n",
      "91/91 - 0s - 2ms/step - loss: 5.1647 - root_mean_squared_error: 2.2726 - val_loss: 5.6698 - val_root_mean_squared_error: 2.3811\n",
      "Epoch 14/100\n",
      "91/91 - 18001s - 198s/step - loss: 5.1240 - root_mean_squared_error: 2.2636 - val_loss: 5.5672 - val_root_mean_squared_error: 2.3595\n",
      "Epoch 15/100\n",
      "91/91 - 0s - 3ms/step - loss: 5.0784 - root_mean_squared_error: 2.2535 - val_loss: 5.5357 - val_root_mean_squared_error: 2.3528\n",
      "Epoch 16/100\n",
      "91/91 - 0s - 3ms/step - loss: 5.0339 - root_mean_squared_error: 2.2436 - val_loss: 5.5118 - val_root_mean_squared_error: 2.3477\n",
      "Epoch 17/100\n",
      "91/91 - 0s - 2ms/step - loss: 4.9912 - root_mean_squared_error: 2.2341 - val_loss: 5.5469 - val_root_mean_squared_error: 2.3552\n",
      "Epoch 18/100\n",
      "91/91 - 0s - 2ms/step - loss: 4.9523 - root_mean_squared_error: 2.2254 - val_loss: 5.4838 - val_root_mean_squared_error: 2.3418\n",
      "Epoch 19/100\n",
      "91/91 - 0s - 2ms/step - loss: 4.9200 - root_mean_squared_error: 2.2181 - val_loss: 5.4665 - val_root_mean_squared_error: 2.3381\n",
      "Epoch 20/100\n",
      "91/91 - 0s - 2ms/step - loss: 4.8765 - root_mean_squared_error: 2.2083 - val_loss: 5.5019 - val_root_mean_squared_error: 2.3456\n",
      "Epoch 21/100\n",
      "91/91 - 0s - 3ms/step - loss: 4.8326 - root_mean_squared_error: 2.1983 - val_loss: 5.4894 - val_root_mean_squared_error: 2.3429\n",
      "Epoch 22/100\n",
      "91/91 - 0s - 3ms/step - loss: 4.7985 - root_mean_squared_error: 2.1906 - val_loss: 5.5066 - val_root_mean_squared_error: 2.3466\n",
      "Epoch 23/100\n",
      "91/91 - 0s - 3ms/step - loss: 4.7555 - root_mean_squared_error: 2.1807 - val_loss: 5.5243 - val_root_mean_squared_error: 2.3504\n",
      "Epoch 24/100\n",
      "91/91 - 0s - 3ms/step - loss: 4.7250 - root_mean_squared_error: 2.1737 - val_loss: 5.5041 - val_root_mean_squared_error: 2.3461\n",
      "Epoch 25/100\n",
      "91/91 - 0s - 2ms/step - loss: 4.6883 - root_mean_squared_error: 2.1652 - val_loss: 5.4735 - val_root_mean_squared_error: 2.3395\n",
      "Epoch 26/100\n",
      "91/91 - 0s - 3ms/step - loss: 4.6500 - root_mean_squared_error: 2.1564 - val_loss: 5.4865 - val_root_mean_squared_error: 2.3423\n",
      "Epoch 27/100\n",
      "91/91 - 0s - 3ms/step - loss: 4.6153 - root_mean_squared_error: 2.1483 - val_loss: 5.5230 - val_root_mean_squared_error: 2.3501\n",
      "Epoch 28/100\n",
      "91/91 - 0s - 3ms/step - loss: 4.5876 - root_mean_squared_error: 2.1419 - val_loss: 5.5557 - val_root_mean_squared_error: 2.3570\n",
      "Epoch 29/100\n",
      "91/91 - 0s - 3ms/step - loss: 4.5589 - root_mean_squared_error: 2.1352 - val_loss: 5.5329 - val_root_mean_squared_error: 2.3522\n",
      "Epoch 30/100\n",
      "91/91 - 0s - 3ms/step - loss: 4.5274 - root_mean_squared_error: 2.1278 - val_loss: 5.5113 - val_root_mean_squared_error: 2.3476\n",
      "Epoch 31/100\n",
      "91/91 - 0s - 3ms/step - loss: 4.4942 - root_mean_squared_error: 2.1200 - val_loss: 5.5318 - val_root_mean_squared_error: 2.3520\n",
      "Epoch 32/100\n",
      "91/91 - 0s - 2ms/step - loss: 4.4778 - root_mean_squared_error: 2.1161 - val_loss: 5.5328 - val_root_mean_squared_error: 2.3522\n",
      "Epoch 33/100\n",
      "91/91 - 0s - 2ms/step - loss: 4.4464 - root_mean_squared_error: 2.1086 - val_loss: 5.5849 - val_root_mean_squared_error: 2.3632\n",
      "Epoch 34/100\n",
      "91/91 - 0s - 3ms/step - loss: 4.4166 - root_mean_squared_error: 2.1016 - val_loss: 5.5775 - val_root_mean_squared_error: 2.3617\n",
      "Epoch 35/100\n",
      "91/91 - 0s - 3ms/step - loss: 4.4051 - root_mean_squared_error: 2.0988 - val_loss: 5.5433 - val_root_mean_squared_error: 2.3544\n",
      "Epoch 36/100\n",
      "91/91 - 0s - 3ms/step - loss: 4.3977 - root_mean_squared_error: 2.0971 - val_loss: 5.6082 - val_root_mean_squared_error: 2.3682\n",
      "Epoch 37/100\n",
      "91/91 - 0s - 2ms/step - loss: 4.3727 - root_mean_squared_error: 2.0911 - val_loss: 5.5697 - val_root_mean_squared_error: 2.3600\n",
      "Epoch 38/100\n",
      "91/91 - 0s - 3ms/step - loss: 4.3335 - root_mean_squared_error: 2.0817 - val_loss: 5.6308 - val_root_mean_squared_error: 2.3729\n",
      "Epoch 39/100\n",
      "91/91 - 0s - 3ms/step - loss: 4.3244 - root_mean_squared_error: 2.0795 - val_loss: 5.6132 - val_root_mean_squared_error: 2.3692\n",
      "Epoch 40/100\n",
      "91/91 - 0s - 3ms/step - loss: 4.3022 - root_mean_squared_error: 2.0742 - val_loss: 5.5989 - val_root_mean_squared_error: 2.3662\n",
      "Epoch 41/100\n",
      "91/91 - 0s - 2ms/step - loss: 4.2852 - root_mean_squared_error: 2.0701 - val_loss: 5.5817 - val_root_mean_squared_error: 2.3626\n",
      "Epoch 42/100\n",
      "91/91 - 0s - 2ms/step - loss: 4.2745 - root_mean_squared_error: 2.0675 - val_loss: 5.6082 - val_root_mean_squared_error: 2.3682\n",
      "Epoch 43/100\n",
      "91/91 - 0s - 2ms/step - loss: 4.2603 - root_mean_squared_error: 2.0640 - val_loss: 5.5732 - val_root_mean_squared_error: 2.3608\n",
      "Epoch 44/100\n",
      "91/91 - 0s - 2ms/step - loss: 4.2463 - root_mean_squared_error: 2.0607 - val_loss: 5.6596 - val_root_mean_squared_error: 2.3790\n",
      "Epoch 45/100\n",
      "91/91 - 0s - 3ms/step - loss: 4.2314 - root_mean_squared_error: 2.0570 - val_loss: 5.6376 - val_root_mean_squared_error: 2.3744\n",
      "Epoch 46/100\n",
      "91/91 - 0s - 3ms/step - loss: 4.2157 - root_mean_squared_error: 2.0532 - val_loss: 5.6295 - val_root_mean_squared_error: 2.3727\n",
      "Epoch 47/100\n",
      "91/91 - 0s - 3ms/step - loss: 4.2011 - root_mean_squared_error: 2.0496 - val_loss: 5.6074 - val_root_mean_squared_error: 2.3680\n",
      "Epoch 48/100\n",
      "91/91 - 0s - 2ms/step - loss: 4.1924 - root_mean_squared_error: 2.0475 - val_loss: 5.6640 - val_root_mean_squared_error: 2.3799\n",
      "Epoch 49/100\n",
      "91/91 - 0s - 2ms/step - loss: 4.1808 - root_mean_squared_error: 2.0447 - val_loss: 5.6456 - val_root_mean_squared_error: 2.3761\n",
      "Epoch 50/100\n",
      "91/91 - 0s - 2ms/step - loss: 4.1513 - root_mean_squared_error: 2.0375 - val_loss: 5.6205 - val_root_mean_squared_error: 2.3708\n",
      "Epoch 51/100\n",
      "91/91 - 0s - 2ms/step - loss: 4.1595 - root_mean_squared_error: 2.0395 - val_loss: 5.6164 - val_root_mean_squared_error: 2.3699\n",
      "Epoch 52/100\n",
      "91/91 - 0s - 2ms/step - loss: 4.1315 - root_mean_squared_error: 2.0326 - val_loss: 5.6315 - val_root_mean_squared_error: 2.3731\n",
      "Epoch 53/100\n",
      "91/91 - 0s - 2ms/step - loss: 4.1323 - root_mean_squared_error: 2.0328 - val_loss: 5.6315 - val_root_mean_squared_error: 2.3731\n",
      "Epoch 54/100\n",
      "91/91 - 0s - 4ms/step - loss: 4.0897 - root_mean_squared_error: 2.0223 - val_loss: 5.6630 - val_root_mean_squared_error: 2.3797\n",
      "Epoch 55/100\n",
      "91/91 - 0s - 2ms/step - loss: 4.0967 - root_mean_squared_error: 2.0240 - val_loss: 5.6685 - val_root_mean_squared_error: 2.3809\n",
      "Epoch 56/100\n",
      "91/91 - 0s - 3ms/step - loss: 4.0731 - root_mean_squared_error: 2.0182 - val_loss: 5.6487 - val_root_mean_squared_error: 2.3767\n",
      "Epoch 57/100\n",
      "91/91 - 0s - 3ms/step - loss: 4.0688 - root_mean_squared_error: 2.0171 - val_loss: 5.7006 - val_root_mean_squared_error: 2.3876\n",
      "Epoch 58/100\n",
      "91/91 - 0s - 3ms/step - loss: 4.0608 - root_mean_squared_error: 2.0152 - val_loss: 5.6523 - val_root_mean_squared_error: 2.3774\n",
      "Epoch 59/100\n",
      "91/91 - 0s - 3ms/step - loss: 4.0372 - root_mean_squared_error: 2.0093 - val_loss: 5.6666 - val_root_mean_squared_error: 2.3805\n",
      "Epoch 60/100\n",
      "91/91 - 0s - 2ms/step - loss: 4.0288 - root_mean_squared_error: 2.0072 - val_loss: 5.6744 - val_root_mean_squared_error: 2.3821\n",
      "Epoch 61/100\n",
      "91/91 - 0s - 3ms/step - loss: 4.0435 - root_mean_squared_error: 2.0109 - val_loss: 5.6390 - val_root_mean_squared_error: 2.3746\n",
      "Epoch 62/100\n",
      "91/91 - 0s - 2ms/step - loss: 4.0468 - root_mean_squared_error: 2.0117 - val_loss: 5.6522 - val_root_mean_squared_error: 2.3774\n",
      "Epoch 63/100\n",
      "91/91 - 0s - 2ms/step - loss: 4.0005 - root_mean_squared_error: 2.0001 - val_loss: 5.6747 - val_root_mean_squared_error: 2.3822\n",
      "Epoch 64/100\n",
      "91/91 - 0s - 2ms/step - loss: 3.9947 - root_mean_squared_error: 1.9987 - val_loss: 5.7656 - val_root_mean_squared_error: 2.4012\n",
      "Epoch 65/100\n",
      "91/91 - 0s - 2ms/step - loss: 4.0027 - root_mean_squared_error: 2.0007 - val_loss: 5.6792 - val_root_mean_squared_error: 2.3831\n",
      "Epoch 66/100\n",
      "91/91 - 0s - 2ms/step - loss: 3.9724 - root_mean_squared_error: 1.9931 - val_loss: 5.6674 - val_root_mean_squared_error: 2.3806\n",
      "Epoch 67/100\n",
      "91/91 - 0s - 3ms/step - loss: 3.9750 - root_mean_squared_error: 1.9937 - val_loss: 5.6883 - val_root_mean_squared_error: 2.3850\n",
      "Epoch 68/100\n",
      "91/91 - 0s - 2ms/step - loss: 3.9578 - root_mean_squared_error: 1.9894 - val_loss: 5.6773 - val_root_mean_squared_error: 2.3827\n",
      "Epoch 69/100\n",
      "91/91 - 0s - 2ms/step - loss: 3.9490 - root_mean_squared_error: 1.9872 - val_loss: 5.6765 - val_root_mean_squared_error: 2.3825\n",
      "Epoch 70/100\n",
      "91/91 - 0s - 3ms/step - loss: 3.9420 - root_mean_squared_error: 1.9855 - val_loss: 5.7585 - val_root_mean_squared_error: 2.3997\n",
      "Epoch 71/100\n",
      "91/91 - 0s - 3ms/step - loss: 3.9452 - root_mean_squared_error: 1.9863 - val_loss: 5.7033 - val_root_mean_squared_error: 2.3882\n",
      "Epoch 72/100\n",
      "91/91 - 0s - 3ms/step - loss: 3.9206 - root_mean_squared_error: 1.9800 - val_loss: 5.7530 - val_root_mean_squared_error: 2.3985\n",
      "Epoch 73/100\n",
      "91/91 - 0s - 3ms/step - loss: 3.9238 - root_mean_squared_error: 1.9809 - val_loss: 5.7218 - val_root_mean_squared_error: 2.3920\n",
      "Epoch 74/100\n",
      "91/91 - 0s - 4ms/step - loss: 3.9148 - root_mean_squared_error: 1.9786 - val_loss: 5.8760 - val_root_mean_squared_error: 2.4240\n",
      "Epoch 75/100\n",
      "91/91 - 0s - 3ms/step - loss: 3.9426 - root_mean_squared_error: 1.9856 - val_loss: 5.7707 - val_root_mean_squared_error: 2.4022\n",
      "Epoch 76/100\n",
      "91/91 - 0s - 4ms/step - loss: 3.9080 - root_mean_squared_error: 1.9769 - val_loss: 5.8072 - val_root_mean_squared_error: 2.4098\n",
      "Epoch 77/100\n",
      "91/91 - 0s - 4ms/step - loss: 3.8899 - root_mean_squared_error: 1.9723 - val_loss: 5.7966 - val_root_mean_squared_error: 2.4076\n",
      "Epoch 78/100\n",
      "91/91 - -18000s - -197803013us/step - loss: 3.8755 - root_mean_squared_error: 1.9686 - val_loss: 5.7384 - val_root_mean_squared_error: 2.3955\n",
      "Epoch 79/100\n",
      "91/91 - 0s - 3ms/step - loss: 3.8718 - root_mean_squared_error: 1.9677 - val_loss: 5.8235 - val_root_mean_squared_error: 2.4132\n",
      "Epoch 80/100\n",
      "91/91 - 0s - 3ms/step - loss: 3.8813 - root_mean_squared_error: 1.9701 - val_loss: 5.7206 - val_root_mean_squared_error: 2.3918\n",
      "Epoch 81/100\n",
      "91/91 - 0s - 4ms/step - loss: 3.8626 - root_mean_squared_error: 1.9653 - val_loss: 5.7625 - val_root_mean_squared_error: 2.4005\n",
      "Epoch 82/100\n",
      "91/91 - 0s - 4ms/step - loss: 3.8582 - root_mean_squared_error: 1.9642 - val_loss: 5.7783 - val_root_mean_squared_error: 2.4038\n",
      "Epoch 83/100\n",
      "91/91 - 0s - 4ms/step - loss: 3.8513 - root_mean_squared_error: 1.9625 - val_loss: 5.7827 - val_root_mean_squared_error: 2.4047\n",
      "Epoch 84/100\n",
      "91/91 - 0s - 3ms/step - loss: 3.8414 - root_mean_squared_error: 1.9600 - val_loss: 5.7945 - val_root_mean_squared_error: 2.4072\n",
      "Epoch 85/100\n",
      "91/91 - 0s - 3ms/step - loss: 3.8384 - root_mean_squared_error: 1.9592 - val_loss: 5.7996 - val_root_mean_squared_error: 2.4082\n",
      "Epoch 86/100\n",
      "91/91 - 0s - 3ms/step - loss: 3.8348 - root_mean_squared_error: 1.9583 - val_loss: 5.8022 - val_root_mean_squared_error: 2.4088\n",
      "Epoch 87/100\n",
      "91/91 - 0s - 3ms/step - loss: 3.8233 - root_mean_squared_error: 1.9553 - val_loss: 5.8906 - val_root_mean_squared_error: 2.4270\n",
      "Epoch 88/100\n",
      "91/91 - 0s - 3ms/step - loss: 3.8176 - root_mean_squared_error: 1.9539 - val_loss: 5.7567 - val_root_mean_squared_error: 2.3993\n",
      "Epoch 89/100\n",
      "91/91 - 1s - 6ms/step - loss: 3.8190 - root_mean_squared_error: 1.9542 - val_loss: 5.7557 - val_root_mean_squared_error: 2.3991\n",
      "Epoch 90/100\n",
      "91/91 - 0s - 3ms/step - loss: 3.8191 - root_mean_squared_error: 1.9543 - val_loss: 5.7621 - val_root_mean_squared_error: 2.4004\n",
      "Epoch 91/100\n",
      "91/91 - 0s - 4ms/step - loss: 3.8014 - root_mean_squared_error: 1.9497 - val_loss: 5.7762 - val_root_mean_squared_error: 2.4034\n",
      "Epoch 92/100\n",
      "91/91 - 0s - 2ms/step - loss: 3.7969 - root_mean_squared_error: 1.9486 - val_loss: 5.7990 - val_root_mean_squared_error: 2.4081\n",
      "Epoch 93/100\n",
      "91/91 - 18001s - 198s/step - loss: 3.7834 - root_mean_squared_error: 1.9451 - val_loss: 5.8237 - val_root_mean_squared_error: 2.4132\n",
      "Epoch 94/100\n",
      "91/91 - -18000s - -197804056us/step - loss: 3.7835 - root_mean_squared_error: 1.9451 - val_loss: 5.7852 - val_root_mean_squared_error: 2.4052\n",
      "Epoch 95/100\n",
      "91/91 - 0s - 2ms/step - loss: 3.7765 - root_mean_squared_error: 1.9433 - val_loss: 5.8518 - val_root_mean_squared_error: 2.4191\n",
      "Epoch 96/100\n",
      "91/91 - 0s - 2ms/step - loss: 3.7694 - root_mean_squared_error: 1.9415 - val_loss: 5.7863 - val_root_mean_squared_error: 2.4055\n",
      "Epoch 97/100\n",
      "91/91 - 0s - 2ms/step - loss: 3.7658 - root_mean_squared_error: 1.9406 - val_loss: 5.8544 - val_root_mean_squared_error: 2.4196\n",
      "Epoch 98/100\n",
      "91/91 - 0s - 2ms/step - loss: 3.7654 - root_mean_squared_error: 1.9405 - val_loss: 5.8095 - val_root_mean_squared_error: 2.4103\n",
      "Epoch 99/100\n",
      "91/91 - 0s - 4ms/step - loss: 3.7815 - root_mean_squared_error: 1.9446 - val_loss: 5.8479 - val_root_mean_squared_error: 2.4182\n",
      "Epoch 100/100\n",
      "91/91 - 0s - 2ms/step - loss: 3.7648 - root_mean_squared_error: 1.9403 - val_loss: 5.9147 - val_root_mean_squared_error: 2.4320\n"
     ]
    }
   ],
   "source": [
    "n_features = X_train.shape[1]\n",
    "n_predictions = 1\n",
    "\n",
    "model = create_keras_nn(n_features, n_predictions)\n",
    "model.compile(loss='mse', optimizer=keras.optimizers.Adam(),\n",
    "              metrics=[keras.metrics.RootMeanSquaredError()])\n",
    "\n",
    "history = model.fit(X_train, y_train,\n",
    "                    batch_size = 32,\n",
    "                    epochs = 100,\n",
    "                    validation_data=(X_test, y_test), verbose = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ba88e646-908d-4b0d-8355-b1e9f9c98068",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'RMSE')"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjcAAAGwCAYAAABVdURTAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8fJSN1AAAACXBIWXMAAA9hAAAPYQGoP6dpAAB7xElEQVR4nO3dd1hTZxsG8DsJEDYKskVwIrj3nnW07mrVqlVpra3WrbWu1mqXXWrHZ+1y1K2tu1pXVUTRqggOQEREUYaKsneS9/vjSDCCCBoI4/5dFxfJOe85eXIY58k7ZUIIASIiIqIKQm7oAIiIiIj0ickNERERVShMboiIiKhCYXJDREREFQqTGyIiIqpQmNwQERFRhcLkhoiIiCoUI0MHUNo0Gg1iYmJgZWUFmUxm6HCIiIioCIQQSElJgYuLC+TywutmKl1yExMTAzc3N0OHQURERM/h9u3bqF69eqFlKl1yY2VlBUC6ONbW1gaOhoiIiIoiOTkZbm5u2vt4YSpdcpPbFGVtbc3khoiIqJwpSpcSdigmIiKiCoXJDREREVUoTG6IiIioQmFyQ0RERBUKkxsiIiKqUJjcEBERUYXC5IaIiIgqFCY3REREVKEwuSEiIqIKhckNERERVShMboiIiKhCYXJDREREFQqTGyIiIqpQmNwQERGRfiTdASL9ACEMGgaTGyIiItKPk8uBP/oBB+cbNAwmN0RERPTikmOBC+ulx559DBoKkxsiIqKSlP4Q2DMVuH3W0JGUrNP/A9RZgFtbwKOjQUNhckNERFSSLm0DLvwBrBto6EhKTtoD4Pxq6XHn2YBMZtBwmNwQEVHpexABHJgn3RQruro9pe856UBOpmFjKSlnfpLen3NToM5Lho6GyQ0RERnA1tHSDXH7W4aOpOTZ1gIsHaXH0QGGjaWkWDoA5nZA5/cNXmsDMLkhIiJDuBcsfb9x3ODDhkvU1f1AYhRQo530/Ja/YeMpKW3eBaZfBjz7GjoSAExuiIiotD3eFGVXF8hIMFwsJSk7DdgxHvi+MWBqI22LKiPJTdoDIDmm8DLX/wVOfAOosot2ThMLQF420oqyEQUREVUeMYHSdwsHYMp5wNzWsPGUlKv7gOxUoKoH0Optadvts4BaZdCwkJMB/NoV+F8rIOFmwWUyEoFtY4GjnwHHPnv6uf77FTi4AEiJK4FAnx+TGyIiKl0xF6TvtboaNIwSd3GL9L3x64BjA6n2JjsViLtk2LgurAeSoqRYTi4vuMz5VUB2ivT41A9S8+GTov4DDi2QhoCHHy6xcJ8HkxsiIipdafGATAG4tgDUOcAN34o3aiolDrhxTHrceBggVwDuHQDHRkBWiuHiUmUDp77Lex4fDmjUumVyMoAzK6XH9vUBCGDnBN2fUWIUsGUkoM4G6vcDmo4q6ciLxcjQARARUSXT52ugxyJAqIENQ4BIX6D/90ALH0NHpj+X/wSEBnBrA9jVlrYN3yAlOYZ0aQuQHA1YOgHD/pDie3J0U/QFKQGzqQGMOwT89hKQEgvcvQLU6iLt2zQcSI8HnBoBg38tM31tcjG5ISKi0mdiLn2v2VlKbq7ur1jJzcWt0vfGw/O2lWZic361lLg4NsjbplYBfsukx+2nADXaFnysRwdg+hWpP46pDTBsHWBsKg1p16iBv8YB90Kk4e0jtkodicuYspVqlXeZydKkVCl3DR0JEVHZlJkEqLLynueuQXTjuDS66EUlRkkdlg05vDzuCnD3MqAwARq8qrtPnQPcPgek3tPva2al5F2/s78Bf88ANr8uNQHmirkAJN0GzGyBlm/mbY86AwT8oXs+S3vArZX02NFbSmwA4PBCIPwgYGQKjNgM2Ljq933oCZMbfdr5rjQp1b6ZFXveBiKi5+W3DFhSXRpiDAAOXkAVd2lNoohjumVD9wLLGwKbR0g1IZnJzz7/f79II4F+bCGN9ClNqiypZkOuABoMBrwH5h8Jtvl1YFUP4Orf+nvde6HAr92AvdOle0/DIUDVmlKit/WNvGTSrTUw5QIw+Le82pY754HVvYF/5kgfzC+sA7JSC34ddQ6Q/qjfzaCVUp+pMorJjT51mw/IjaRf2uAdho6GiKjsibkgdUK1cJCey2RA/UcTv4Xtzyt367TU/JF0W9q+8x2pZrww6hzg0qPmoIcRUgIVf12/8WckAjdPSs0+B+ZJfYa+bwp84Qp85iAtK+HgBQxdIyURT3JtKX3Xx2R+QgBBm4DfugMPwqW4Uu9JCdXIbYDSBog6LdXi5H7gruoO1O3xWDwtpC9VhpR47ZkC/Nwhfyfj3PeuygQG/Ag0HPzi8ZcgJjf65NQI6PS+9Hjf+0DqfcPGQ0RUlmg0QEyQ9PjxT/2er0jfrx2Qbqrx4dKNVp0F1O0NdP4AqFYP8B5Q+PnDDwNp96XEyaOTtC1sn/7ijwkEvqkDrO0rJQxnfgKuHwESIqVh1YDUyTZXQcsQuD82U/GL1PBnJAB/vQnsmiit6VSrKzDBD7B6tMyDfT0pwZLJgaCNwO8vFTwZn0wGdJnz6P09GqLf4NWC+wdZ2gND1wLNxzx/3KWEHYr1rdMsqebm7hVg//tSb3QiIgIeXAeykgEjs0dDjB+p0U7quJr+QJr47tCHQGaiVMsxdK3U+bjb/LzyKXeBoA1Ax5m6CUTQRul742HSxHk3/aSOyh2mFT1GIaTE4WGklLSkxQNtJ0j7HBsBZlWk+B3qSwlXtbqAXR3AyllaWyl3JuKnqd5KquFPjpaajaq6Fz22XJF+UjeI5GjpXF3nAR1n5E9I6rwEvPwl8M8H0ppWy72BWWH5y9XtBTg3AWIvAgol0GZi8WMqYwya3CxZsgQ7duzA1atXYWZmhvbt2+Orr76Cp6dnkY4/deoUunTpgoYNGyIoKKhkgy0qIxNg0E9S+2fILiB4Z/4OZURElVFuzYBzE0Dx2O1HYSzdYGMCpcnjEm9JHVhHbs0bVZWbxKiygJ87Amn3pDK5/1/T4qWaH0Cac8XURvqAefs/qanG0uHpcQkhLTXg/z0QcxHIStLd7/mKlIQojICJp6UajOdlYiGtnB19XmoyKm5yE7gR2D0JgABsawNDfiu870vrd4D7YdJ1bTa64BoZmQzosRjYOFQaRZVb+1OOGbRZytfXF5MmTcKZM2dw+PBhqFQq9OrVC2lpz+4xn5SUhDFjxuCllwy/tHo+zk2ATjOlx/ve1+2tTkRUWeWuiO3aPP++AT8CUwKA0buAV74GRv0FWFTLX85ICbR8tJL4kcV5TS2X/wQ0KsClmTS6x8ZVegwBhP3z9JgSo6Q+KxuHAJEn8hIbK2egRnspIVA/1pzzIolNLvf20vdbp4pWPv1h3uPa3aTao+ZjgHdPPLtTr0wG9F0KTPQHun/49HK1uwHzowsvU44YtObmwIEDOs/XrFkDBwcHBAQEoHPnzoUe++6772LkyJFQKBTYtWtXCUb5nDrPlqpXze2kTm5ERCUhMwlY1UtqGnl9o6GjKVz0o5qbgm7IxmbSd5lMWmG6MO2nAAFrpGaj86uAthPzmqQenym3fl+pNihsP9BibMHnsnSSanaMzaWkqelIqUYoN56S4N4e8P9B6jRdEFWWNI9MTBAQuge4EwDMDAaUVoC1C/Def8WrXZHJdOe7eRojZdHPWcaVqT43SUlSxmxrW/giamvWrEFERAQ2bNiAzz4rfKhfVlYWsrLy5lRITi7CUEJ9MFICb+yQqkINPSMlEVVcV7YD969KX3GXpYENJWnfLCDsADB2T97Mu0WhzpHiAx7VqLwApaXUz+Tv6YDv10DD1wC3tlKS0nBIXrn6/aTh4BHHpOHNSktpe9oDwNRaag4zMpE63latqZ9amaKo0RaATOownZ0mNVX9NU7a9yAcuBsCaB77UCyTAzdPAZ4vS88rQLNRSSszyY0QAjNnzkTHjh3RsGHDp5YLDw/H3Llz4efnByOjZ4e/ZMkSLF68WJ+hFp21c95jVZY0jI6/lESkT8E78x5f3FKyyU1yjDQEWmikYdCjtj297NV9UgfVrvOkmgOFMTDtolSTkjsh3ItoNlpa/yg+TFq4se+3wCtf6X6YtK8P1HtFuia5TUuqbGDzcGltq6FrpJoQt9YvHk9xmFUFZl0FrJyk50IAV/7KX8a5qdQBudkoqYM0FVmZSW4mT56MS5cu4eTJk08to1arMXLkSCxevBj16tUr0nnnzZuHmTNnap8nJyfDzc3theMtlgcRwJ9jpdkq3zoo/ZETEb2o5Fhp5AwgTRpX0kN0gzZKiQ0gzVIbfkR3zpRcCbeAP32khEKVKXVWlcmkD3yPf+h7EQojoOcnUqJyZiXQ6m2gyhP/22UyYOQW3W2HFwJ3zkkdjtUFDI0uLbmJDSBd0z7fSh+CbaoDLk2liQ0LGkpORVImkpspU6Zgz549OHHiBKpXr/7UcikpKTh//jwCAwMxefJkAIBGo4EQAkZGRjh06BC6d++uc4xSqYRSaeB2RCOl1GktM0mqQu2+wLDxEFHFELwDgJDWEBq6pmRfS6MBAjdIj6t5Ahb2Uq3H47LTpb4qVd2BXp9JQ5BPfS81SfX+Qv8363q9pQEcSXekZrknk5snBe8C/nu02vWgn8tObYhcAbQeb+goKhSDjpYSQmDy5MnYsWMHjh49ipo1axZa3traGpcvX0ZQUJD2a8KECfD09ERQUBDatGlTSpHnl5KZg70XY/C73438O22qA/2+kx77ffv0TmRERMVx+VFTRqOhedtKaumXWyelhRSV1tJK0T5/S6OSHrdnCvBHf+DhDalTcL/l0vYzPwGLqwDrB0sT9OmLTAa8+ouUZKUWsqZf9AVgyyipBh2Q5r2p30d/cVCZY9Cam0mTJmHTpk3YvXs3rKysEBcXBwCwsbGBmZnUU33evHmIjo7GunXrIJfL8/XHcXBwgKmpaaH9dErD3eQsTNkcCKWRHKPbuUNp9EQn4oaDgfBDwMXNwF9vSXMTeHQ0TLBEVDG8tFBKcLwHSbUjvl9JtRNvH5GGC+vT3RBAbix12H383BqN1PR000/qNyKTS/0LAWn0kdwY2CPVtCPiX8DEUr9xOXgBE57enQEAcG5V3lpONdoD3RfqNwYqcwxac7Ny5UokJSWha9eucHZ21n5t3bpVWyY2NhZRUVEGjLJoattbwM7CBFkqDS7fSSq40CtfS8M1U2Kk6bv3TM37J0BEVFy1uwGDVkijfORGUifeB+G6nYz1pe0EYGYo0OWDvG0xgcBv3YC906TlCACg3STdeWyaj5ZqV2RyqYOvvvrcFEeDQdJ3pTXw2mrdCQSpQpIJUbmWr05OToaNjQ2SkpJgbW2t13NP3BCAf67EYXZvT0zqVqfgQplJwOGPpTkaAOClj/Mm/CMiehGnfgAOfyT1wRl3qORf75Y/sOaVvOdVPaQZfHNnFX7cgwjAtApgYVfycT1JCCBkN+DcWD8jtcgginP/5sKZetSmpjQ/z9nIh08vZGoD9P8O8NkPePaVPuUQUfklBHBkEXDoo5Lr7/KkmCDg955AwFrd7Y2HSTUkt/+Tkgl9EAII2SN1Fn6Se3tplFau/t8XnNgA0pw4hkhsAKlvToNBTGwqESY3etS6pvSHG3ArASq1pvDCHh2AEZvyZoRMuiN1xNPXPyQiKh2X/wROLpdmnA0o4RFLj7/mnbPS5HSPs3ICaj8aMXpxS/7jnkdsELBtNPB9Y2mo8pN6fSbNx9LpfWllaqIygMmNHnk6WcHa1AipWSqExqYU7+D9s6V1TX7tKrWbE1HZl50OHHxsaodDC4HE2yX7mhq1NCsxoDtKKleTEdL3S1ukzr4FUWUB/34KLK0P/DGg8D46F9ZJ32t2KXh6fhtX4F1f4KWPiv4eiEoYkxs9UshlaOUhNU39F/mgeAf3XSZNH56VDGwZKf3D5IKbRGWbiTnw6s9AvZeB6q2B7BRpSYCSbJ665Q+kxAJKG6Buz/z76/eVOs4mRknrLj3pznngl87StBQpsUCkL3D7nO7+gD+AoM3SSKzc4eYlPUEgkR4xudGz1jVzk5tC+t0UxNpZmjei7XvS89P/A5Z5ScPGI/1Kry2/IBr1o9VyUw0XA1FZVeclYORWYOAKQKEErh+RpnwoSHaa1JR09DNgxzMWhyxI6n3g+BLpsXf/gmtSjM2AxsOlx+aP9XFJuiMtmbCqpzThnYU9MGilNJy86ci8ciG7gL1TgV0TgO3jpA9cVT0Aj07Fj5fIQDgeTs9yk5tzNx9CoxGQy4sxI6fCGHh5iTT/jd9SIDpAqn4O/Rt4P0xaa8QQbhwDNgwBmo8FBvxgmBiISkP6Q2nW3/QEoMtsaZsQ0jwtHp0fddiVSQn/rVNAzc55x9rXA7rNkzoXn/xOSjDkCun4G8eB0yukvyWNKu+YXp8VfbHG8MPArolA2n1pKZdWhcxo2/tzabZez8cmqts+Hojylx43Hg68/CVgXsAixdU8pfWY1NnSlxDSKtxyfham8oPJjZ41dLWBmbECiek5CL+XCk8nq+KfpH5f6Sv2InB+jfQP8vHERqMp3X80ykdD7i78ITWfcY4IepaMRGD720CVGkCPRdIKzM9Do9ZdCDHhZslNmZ8UDfzRT5pdV2ECdJwufeAIPywtOxC4QVpbqd9yIOIosP99oOkoYNBPeedoNwXIyZRm5xUa4OJfgP+PwN3LeWWsq0sDCtw7SCtSA1LTjyoTaPZGwbFp1MC/n0iJjb2XNAloYQtkGimlWXhzZadLC0xau0p/w7mrSxek+Wjpi6gc411Kz4wVcrRwr4qT1+NxNvLB8yU3uZybSMPGH3fud+mf7eDfnv+GUVQZidJMpC7NATNbIOMhEHUaqMnqaXqGoI3A9cPS467znu8cQgCbhkkLCHabD6Q/AFa2B+r3A3p9KiVO+pJ0B1jbD0iIlJKPxkOlZENhLI0A6v4RcOIbqX/KT+2kCfMAwKWZ7nkURlLtDSDVAv09HchJB4zNpVWsW78DVHtiDqyoM1Lzj0whNRXV6y1tz8mQEq5qdaQEb8jvUufe7h8BxqbFe38m5sCsa3kxElVwrGcsAW2et9/Ns6Q/BA4vAq4dAH7vUbxh47n9Zooq/DDwXWPpu8JI6jAJAGH7ixUyVVK5w5A9++Y1u+RkFDyU+GnCD0v9VwLXA9mpwM2TUm1IyC7gf62A/37RT1+0pDvSjOEJkVIi9dY/Um2T8tEHEyMToPP7wER/oFY3QJ0F5KRJw59bvvX085rbSrUnLy0EZgQDfb7On9gA0oR7TUYCQg1sGyvNKXPoQ6nP3Z9j896jvafU3FTcxCaXwoiJDVUaTG5KQOvHJvPT6wTQ5rbA2N2AlbNUxfxbd+mff1Ec+kiaR8dvmTQK63wh83HEBEr/ZLOSpBsJkLfI3NV9hu3cTGXf3WAg7pK0ptDA/+VtPzgf+KWLtEp09AUp4X4atUq6wQNSE09VD6DVOODdE4B7R6lW5Z8PgJ3vFjy5XFEl3n6U2NyUXsNn39NrhOxqA6N3AkNWAQ1elWpP5YqCy+bqOhfoNKvgvi25ZDKpL1udHoAqQ5pTxv9HICMByEwufEFIIioQk5sS0MStCkwUctxLycKtBy/wj7cgri2Ad44Dri2BzERgw2vAiW+fPp8FAJz9DTizQnpsYQ/82FyqLo86k79s+kNg0+vSJ9Na3YC+j1b1rd0dMDIFEm8B90L1+56odNwNAf70kRZWLMkENbfWpl7vvJt6+kMgdC9wPxQ4vFBaj+irmsDmEcCVHfnjufCHlMCb2UqTw+VyaiSNKuy9RGrGubQVWN0LSLhVeEwPIqT1j/7XOm+OGAA4s/KJxMat8PPIZECj14Cha6UOxPqiMAaG/iH9XQNA7ZeAEVuAaUHSxHxEVCxMbkqAqbECTd2qAHjGUgzPy8oJeHO/NHoJAjj6qfRpLzM5f9nww9InXEBqq28+GvAeKD33/Vq3rBDS4nepcdKIiWHr8jo8mljkzT4axkkGyyW72tJcLNvHAatfluYz0TeNWpo9FwCavJ633dwWeO8M0PsLaSSO0lqqGQzbD/z1JrBtDJD2aG6ozGTg2BfS465z869uLZMB7d4DxuwGzKsBcZelZCm9gL+1uMvAn28C/2spLVUQHyat75bLwk6akt9nP2BTXV9X4fkoLYG3DgCzI4DROwDPV55dM0REBWJyU0Kee76bojJSSlXZ/X+QRnaE7ZdGVwHS5F0nvwOOfi59UhcaoOkbUvU4AHScKX3qjfgXuBOQd84r26VmKLkRMPiX/B2Wc4eVFqfvDpUdChMAQvp++wzw+0vSjT/hpv5eI9JXmhjOrCpQt5fuPotq0lpqI7cAH0QC448CHWdIv2/hh6UOwwBwchmQHg/Y1Sm8T0vNTtLMuC7NgJbj8mqJgndJfXJ+6w783FEa2i00QN3eUm1IvccWemz8urTQo42r/q7Bi1AYS9eJiF4Ie5eVkNY1bYFjzzFTcXG1GAs4NgTiLuaNYkq8DRz5OK+MRydp+Krs0Zw7tjWleS4ubpJGgIzcAiTHAPseJT+dZ+cfBQIAXv2l6nv39iX6lug5JN6W+l81eV2axO1xGrX0863iJiUXDV6VEt+gjdKNP2Q30HCwNJeJc5MXiyMtXmr69BpQ8ARzuRRGUhOrawvAexDw4LrUzJMYJQ25BoCen0o3+8LYVAfePKBb7kE4EP9oZJBMLr3fjjMKHjpdVpIaItIrmdBrj9eyrzhLpr+I1CwVmiw+BLVG4NTc7nCtYvbsg/Tl4Q2pH46xGWDtIk329WQtTPx1YEUr6RPtuyeAm6eAg/OkESBvH3n2TYXKDiGkWWfvnJMShaFr8xJZALi4Fdg9CegwVRq5kyv2ktT/5cajxReNzKTJIk1tnv5aOZm6o3WE0H0tAFDnSKObnmfSyew0qR/MjePA2L35z10UKXeBeyFSR9zqraTmOCIq94pz/2bNTQmxVBqhoYs1Lt5JwtnIB3i1WSm259vW0p1YrCDV6gANh0j9I058AwzfIH0KrlavaIlN7hw4ZHiRvlJiA0jNimdWSn1SACnROL4E0OQAJpa6xzk3BsbskkbH+f9Pag7JTWxyMqXVoGu0zSsfdwXYMkLqzOvVTxqafehDYOSfurPsKoyffzZtuZGUlAxc8XyJDQBYOUpfRFRpsc9NCWpbW1rX5Q//W9BoymAFWaf3AcikUSzx4YD3AMChfuHHZCZJfRm+rQdkFXPlcyqarFRpKHRRnfhW+u7YUBom3XhY3r6gTdL8LRb20pDqgrg0A15bJU3Hn+vcb8Dq3tJopvthQNgB6XliFOD7lZQ0/T1DSow2DZVivrj1xVfENlICfb4Bqrq/2HmIqFJjclOC3upQE5ZKIwTdTsTmc1GGDic/h/rSaJRRf0mdN4tCaS3V2qizij7HDhVd5AngKw/gK3ep6TDX0+aEuXUauOknzSkzciswdk9eh1RVVt6IuI4zpRFvhXm8piQtXup0HrYf+KktsPl1qampZmfpNRTGwOubpYUZYwKBja9Jc85831hqFiIiMiAmNyXI0doUs3pJc2F89c9VxKcWY3bW0tJ1LlC3Z9GbAGSyxyb042zFeqXKkmpDNDlSX5bH11Ba27fgUWp+j2ptmo2SmhVzhw7nZABfuALJdwArl8JHHRWk52Jp6Hb9flK/LAighQ/wxo68JqdqdaQmKWNzaVkOCMCtLZuEiMjgmNyUsNFt3dHQ1RrJmSp8sa+CTH7n2Vf6Hn5Qap4g/Tj9P2nUkIXDo07dj7rEpcRJEy5uHinVkuRSZUm1K3IjoMN03XPtnCAlSYC0uvXzTNlvXw94fSPw9lEpien3Xf7+WNVbSPMh5a611GR48V+HiEjPmNyUMCOFHJ8PagSZDNgRGA3/iHhDh/Ti3FpLfTgyk4BdEwufRp+KJjEK8P1GetzrM8DRO2+faRXAoyOQnSLNSJ3bXGWkBEZtA6YGScP7H9dljnScg7c0x9GLqN4CqNfr6bV7dXtK88d0mCatkUREZGBMbkpBE7cqeKON1EHyw11XkKUq58mAXCFNHig3kkZb7ZxQOROcKzuA1Hv6OdeBedK6Qu4ddDsEA1Kty+ubpDlo0uOB9YOkeWtyFbRkgKM3MOMKMP5Y3izTJaluT6DnJ6XzWkREz8DkppS839sT1SyVuHE/Db+duGHocF5c/T7SfCpyI+DyNmml8mdRZUsdXMMPl3h4Je72WWD728DK9i/esTr8MHD1b6mJqc+3BdeQmFoDo7YDtrWBpNvSitGBGwpfU0xp9fwrSBMRlWNMbkqJjZkxPurnBQD44ej1kllzqrR59QdeWw289DFQv++zyyfdllY7/tMnbx2h8iQrFUiKlh4rrQF7TyDtPrBhiDTfiyr7+c778IY02qntRN3mqCdZ2kvz0lg8mlNm96S8mXiJiEiLMxSXIiEE3l0fgEMhd2FlaoRt77aDl3PpxlDibp+TbvpPzogMSCOAvqktrSHUcSbQ4+P8ZcqqnAxg41BpHaaxe6SJEnMygEMfSXPCANLszkNWSaOICpKVIq17lPFQ6gxsYiEthwBI8wxZOUm1Lc9yLxTY+sajVdu/1cObIyIq+4pz/2ZyU8oystUYs/o/nLuZAHsrJbZPaI8adualHkeJeBgJ/NJFqmEY+gfg1FDaficAcG0uNbdc3QdsGSnNljv9ct5ihyUh4aY0X0v1li92HlWWFPP1I4CJFTB2t7QmUq6r+6RalIwEaQmDXp8Crd7WbV6KOArsmQYkPTbfkU0NYMblF4uNiKiSKM79m81SpczMRIHfx7ZCfScr3E/JwujV/+F+Shmc/+Z5ZCYCSktpOPPvL0l9Qq5sB37vLi3KqdFIK4s7NZImhDu9omTiSH8I/DMH+LHFo5WvfZ6/469GI3WYvn5Ems9l1J+6iQ0gNclNOAXU6ip1Cj4wV6qJAaQJD3dPAta/KiU2NjWAJiOkOWM4bJqIqESw5sZA7iVnYsjP/rj9MAPeztbY8m5bWJtWgMUq0x4AO8YDEf9Kz2VyaRK41u8Cr3wl1WaE7pWaVUysgOmX9Ft7E7gBOLhASrSkAAAIaVj0y19Kq2YXZ82ifz8B/JZKfWJGbQNqd396WY0GOPc7oMqUFqnMSgVWtAaSH/XTaf2utHCl0vLp5yAiogKx5qYccLA2xfq32qCapQlCYpPxzrrz5X+IOABY2EnLOXT7MC+x8R4IvLwkL6nw7Cutg5SdIi3yWBRFnSxQCCmxcWgAjN4JvOsLODWWtu2aCNy/WvT3ErhBSmwAYMCPhSc2ACCXA23ekRIbQEpivAdJI5ze/Afo8zUTGyKiUsCaGwO7Ep2E1389g9QsFfo2dsaPrzeDXP6cqyGXNVH/ATEXgBZv5h+SHLIb2DZGWoV6VhhgbPb08yTHAj93AOy9pOYcr/5557tzHrj9X17HXI0aCN4JNHg1bykCdY40+29mctE7Md86DfzRD9CogM6zge4fFuuta+VkSN8Le39ERPRM7FBciLKW3ADAqevx8FlzFjlqAZ/2Hvi4vzdkxWk6KY80GuDIQqDpKMDB69nlr+6TmrKEBjCzlfqtpMRIiYxMDkz0L9p5ckWekJY5eNoq6JnJwF9vSs1ZQ34vXlMWERHpHZObQpTF5AYA9lyMwdTN0rpBc1+pjwldahs4olImRP4EIjkGsHaRHidFS81EF9ZJi0FqyYCmI4HuHwHWzkV7rdtngT8GSEOxx+7Nm1smJxO4Hwq4NJOeq1WAUEvLHBARkUExuSlEWU1uAOB3vxv47NHimsuGNcHg5tUNHFEpyUoFVr8MtBgrNTspjIGYIGkl7LYTgW4L8hIfjVoauRS0SWp26jhDGn1VHOkPgXUDgbhLUi3Qq78At04CF9YDEMDMUDYjERGVMUxuClGWkxsA+HxfCH7zi4SRXIaVb7RAT29HQ4dU8k7/BBycJz22qwt0nC6NUkq9C9TsAryxPf9q1C8qIwFYP1jqE/Q4Gzdg5FbAsYF+X4+IiF4Ik5tClPXkRqMRmPXnRewMjIaJQo7fxrZEl3r2hg6rZKlzgIC1wPEl0uzFuRwbAm/ulzodl4TMJGnW4dv/SSOhWo0H6vXO64hMRERlBpObQpT15AYAVGoNJm8KxIHgOCiN5Fj7Zmu0q21n6LBKXmYScPI74MxPgKUD8NbBvD43JUWjlibas6gE15eIqBxjclOI8pDcAEC2SoMJGwJw9Oo9mJsosH5cG7Rwr2rosEpHVoq0QrZJBVmWgoiIXhgn8asATIzk+GlUc3SsUw3p2Wr4rD6Ly3eSDB1W6VBaMbEhIqLnxuSmDDM1VuDXMS3Q2sMWKVkqvLn2LO4kpBs6LCIiojKNyU0ZZ25ihNVvtoKXszXiU7Px9h/nkZqlMnRYREREZRaTm3LAUmmEVWNbwt5KiatxKZi6ORBqTaXqKkVERFRkTG7KCZcqZvhtTEsojeQ4evUevtgfauiQiIiIyiQmN+VIU7cqWDqsCQBg1clIbPzvloEjIiIiKnuY3JQz/Rq7YFbPegCAhbuDcSg4zsARERERlS1Mbsqhyd3rYHBzV6g1Au9tvIADV2INHRIREVGZweSmHJLJZPh6SGMMaOIClUZg0qZA7L/MBIeIiAhgclNuGSnkWD68KV5tJtXgTNkciL8vxRg6LCIiIoNjclOOKeQyfDu0CYY0rw61RmDaliDsvcgEh4iIKjcmN+WcQi7D1681xtAWUoIz68+LCI6pJMs0EBERFYDJTQWgkMvw1ZDGeKm+A7JVGkzZFMhZjImIqNJiclNByB81UTnbmOJGfBo+3HkZlWzBdyIiIgBMbiqUqhYm+GFEMyjkMuwKisGf5+8YOiQiIqJSx+SmgmnlYYuZuZP87bmCa3dTDBwRERFR6WJyUwFN7FIbnepWQ2aOBpM2XkB6NvvfEBFR5cHkpgKSy2VYPrwpHKyUCL+Xiq8PhBk6JCIiolLD5KaCqmap1C6yudb/Js5GPjRwRERERKWDyU0F1qmuPV5v5QYA+OCvi8jIVhs4IiIiopLH5KaCm9/XC07Wprj5IB3LDrN5ioiIKj6DJjdLlixBq1atYGVlBQcHBwwaNAhhYYXfgE+ePIkOHTrAzs4OZmZmqF+/PpYvX15KEZc/1qbG+GJwQwDAqpORuBCVYOCIiIiISpZBkxtfX19MmjQJZ86cweHDh6FSqdCrVy+kpaU99RgLCwtMnjwZJ06cQGhoKD788EN8+OGH+PXXX0sx8vKle31HDG7mCo0AZv95EZk5bJ4iIqKKSybK0DS29+/fh4ODA3x9fdG5c+ciHzd48GBYWFhg/fr1+fZlZWUhKytL+zw5ORlubm5ISkqCtbW1XuIuDxLTs9Fz+QncT8nCu11qYd4rXoYOiYiIqMiSk5NhY2NTpPt3mepzk5QkLfhoa2tb5GMCAwPh7++PLl26FLh/yZIlsLGx0X65ubnpJdbypoq5CT4bJDVP/eJ7A18fuAqNpszktURERHpTZmpuhBAYOHAgEhIS4Ofn98zy1atXx/3796FSqbBo0SJ89NFHBZZjzY2u74+EY/mRawCA/k1c8M1rjWFqrDBwVERERIUrTs2NUSnF9EyTJ0/GpUuXcPLkySKV9/PzQ2pqKs6cOYO5c+eiTp06GDFiRL5ySqUSSqVS3+GWW9N61IVrVTPM3X4Jey/GIC4pA7+ObomqFiaGDo2IiEgvykTNzZQpU7Br1y6cOHECNWvWLPbxn332GdavX//MkVZA8TK/iuzU9XhM2BCAlEwValazwPpxrVG9qrmhwyIiIipQuelzI4TA5MmTsWPHDhw9evS5Epvc8zze9ETP1qFONWyf2B6uVcwQGZ+G2X9eQhnIc4mIiF6YQZObSZMmYcOGDdi0aROsrKwQFxeHuLg4ZGRkaMvMmzcPY8aM0T5fsWIF9u7di/DwcISHh2PNmjX49ttv8cYbbxjiLZRr9RytsHl8WyiN5Dh94wH2XIwxdEhEREQvzKB9blauXAkA6Nq1q872NWvWwMfHBwAQGxuLqKgo7T6NRoN58+YhMjISRkZGqF27Nr788ku8++67pRV2hVLDzhyTutXBssPX8Pm+UHSv7wArU2NDh0VERPTcykSfm9LEPjf5Zeao8fJ3J3DzQTrGdayJj/p5GzokIiIiHeWmzw2VDabGCiweKM2Bs9b/Jq7GJRs4IiIioufH5IYAAF3q2eOVhk5QawQ+2nWFnYuJiKjcYnJDWh/184aZsQLnbiZg+4VoQ4dDRET0XJjckJZLFTNMfakuAGDJ/lAkpGUbOCIiIqLiY3JDOsZ1rIm6DpZ4kJaNxXuDDR0OERFRsTG5IR0mRnJ8M7QJ5DJgV1AMDofcNXRIRERExcLkhvJp6lYF4zvXAgDM33kZielsniIiovKDyQ0VaEaPeqhtb4H7KVn45O8QQ4dDRERUZExuqECmxgp8/VoTyGTAjgvR+DeUzVNERFQ+MLmhp2rhXhVvd5QWM52/8zKSMnIMHBEREdGzMbmhQs3q5Yla1SxwNzkLC3dzcj8iIir7mNxQoUyNFfhmaGMo5DLsDorBnwF3DB0SERFRoZjc0DO1cLfFzJ71AAALd19B+N0UA0dERET0dExuqEgmdqmNTnWrITNHg0mbLiAjW23okIiIiArE5IaKRC6XYdmwpqhmqcS1u6n45G/OXkxERGUTkxsqMnsrJb5/vSlkMmDz2dvYHcTFNYmIqOxhckPF0qFONUzpVgcAMH/HZdx+mG7giIiIiHQxuaFim/pSXbTyqIq0bDXm7rjE4eFERFSmMLmhYjNSyPHNa01gaizHqesPsPnsbUOHREREpMXkhp6LRzULzO5dHwDwxf5QRCdmGDgiIiIiCZMbem4+7T3Qwr0qUrNUmLudzVNERFQ2MLmh56aQy/D1a42hNJLDLzwef57n7MVERGR4TG7ohdS2t8SsXtLsxZ/uC0FcUqaBIyIiosqOyQ29sHEda6GpWxWkZKowj6OniIjIwJjc0AtTyGX4dmhjmBjJcSzsPhfXJCIig2JyQ3pRx8EKsx4trvnp3hDEcPQUEREZCJMb0pu3O9VC8xpVkJKlwhyOniIiIgNhckN6IzVPNdGOntp0NsrQIRERUSXE5Ib0qpa9JT54WZrc7/N9oVx7ioiISh2TG9K7N9t7oLWHLdKz1fjgr0vQaNg8RUREpYfJDemdXC7DN0Mbw8xYgdM3HmCt/01Dh0RERJUIkxsqEe52Fpjf1wsA8OWBq7h2N8XAERERUWXB5IZKzBttaqCbpz2yVRpM3xKEbJXG0CEREVElwOSGSoxMJsNXrzVGVXNjhMQmY9nha4YOiYiIKgEmN1SiHKxMsWRwYwDALyci8N+NBwaOiIiIKjomN1TiXm7ohKEtqkMIYOa2i0jOzDF0SEREVIExuaFS8fGABnCzNUN0YgY+3h3M2YuJiKjEMLmhUmGpNMLyYU0hlwE7A6Ox9dxtQ4dEREQVFJMbKjUtPWwxq5cnAGDhnmAExyQZOCIiIqqImNxQqZrYpTa613dAtkqD9zZeQFIG+98QEZF+MbmhUiWXy7BsWBNUr2qGWw/SMfvPi+x/Q0REesXkhkpdFXMT/DSqOUwUchwKuYvf/SINHRIREVUgTG7IIBpXr4KF/b0BSMsz+F+PN3BERERUUTC5IYMZ1aYGXm3mCrVG4J31AbgSzQ7GRET04pjckMHIZDIsGdwI7WrZITVLhbGrzyIyPs3QYRERUTnH5IYMytRYgV/HtEADF2s8SMvG6FX/4W5ypqHDIiKicozJDRmclakx1r7ZGh525riTkIGxq89yiDgRET03JjdUJthbKbF+XBvYWylxNS4F76w7D7WGQ8SJiKj4mNxQmeFma451b7WGpdII/0U+xG9+NwwdEhERlUNMbqhM8XK21g4RX3boGsLiUgwcERERlTdMbqjMGdqiOl6q74BstQYztwUhR60xdEhERFSOMLmhMid3iLiNmTGCY5Kx4th1Q4dERETlCJMbKpMcrE3x6aCGAID/Hb2Oy3c4wR8RERUNkxsqs/o3dkafRk5QaQRm/RmELJXa0CEREVE5UKzk5uzZs1Cr824wT67mnJWVhW3btuknMqr0ZDIZPh3YENUsTXDtbiqWHw43dEhERFQOFCu5adeuHR48eKB9bmNjgxs38obrJiYmYsSIEfqLjio9O0slPn+1EQDg1xMRCIxKMHBERERU1hUruXmypubJ50/bRvQiejdwwqCmLtAI4P0/LyIzh81TRET0dHrvcyOTyYpcdsmSJWjVqhWsrKzg4OCAQYMGISwsrNBjduzYgZ49e8Le3h7W1tZo164dDh48+KJhUxm3aEAD2FspEXE/DcsPXzN0OEREVIYZtEOxr68vJk2ahDNnzuDw4cNQqVTo1asX0tKevjL0iRMn0LNnT+zfvx8BAQHo1q0b+vfvj8DAwFKMnEpbFXMTfPGoeeo3vxsIuMXmKSIiKphMFKMdSS6X4+jRo7C1tQUAtG/fHtu2bUP16tUBAPHx8ejZs6dOp+PiuH//PhwcHODr64vOnTsX+bgGDRpg+PDhWLhwYb59WVlZyMrK0j5PTk6Gm5sbkpKSYG1t/VxxkuHM3BqEHYHRqFXNAvundYKpscLQIRERUSlITk6GjY1Nke7fRsU9+UsvvaTTr6Zfv34ApOYoIUSxmqWelJQkzWWSmzwVhUajQUpKylOPWbJkCRYvXvzcMVHZ8nH/Bjh5PR434tOw9FAYFvT1NnRIRERUxhSr5ubWrVtFKufu7l7sQIQQGDhwIBISEuDn51fk47755ht8+eWXCA0NhYODQ779rLmpeI5evYu31p4HAKwc1RyvNHI2cERERFTSSqzm5nmSlqKaPHkyLl26hJMnTxb5mM2bN2PRokXYvXt3gYkNACiVSiiVSn2FSWVA9/qO8GnvgbX+NzF9axCcbEzRrEZVQ4dFRERlRLE6FD98+BB37tzR2RYcHIw333wTw4YNw6ZNm54riClTpmDPnj04duyYtv/Os2zduhXjxo3Dtm3b0KNHj+d6XSq/PuzrhW6e9shSaTB+3Xncfphu6JCIiKiMKFZyM2nSJCxbtkz7/N69e+jUqRPOnTuHrKws+Pj4YP369UU+nxACkydPxo4dO3D06FHUrFmzSMdt3rwZPj4+2LRpE/r27Vuct0AVhJFCjh9HNoeXszXiU7Px1tpzSMrIMXRYRERUBhQruTlz5gwGDBigfb5u3TrY2toiKCgIu3fvxhdffIEVK1YU+XyTJk3Chg0bsGnTJlhZWSEuLg5xcXHIyMjQlpk3bx7GjBmjfb5582aMGTMGS5cuRdu2bbXH5HZGpsrDUmmE1T4t4WitRPi9VLy3MQA5ao2hwyIiIgMrVnITFxenU7ty9OhRvPrqqzAykrruDBgwAOHhRV//Z+XKlUhKSkLXrl3h7Oys/dq6dau2TGxsLKKiorTPf/nlF6hUKkyaNEnnmGnTphXnrVAF4WxjhlVjW8HcRIFT1x/gi/2hhg6JiIgMrFgdiq2trZGYmKjtWHz27FmMGzdOu18mk+mMTHqWogzUWrt2rc7z48ePF/n8VDk0dLXB9683w/h157Hm1E309HZE+9rVDB0WEREZSLFqblq3bo0ffvgBGo0Gf/31F1JSUtC9e3ft/mvXrsHNzU3vQRI9S09vR4xsUwMAMPvPS0jJZP8bIqLKqljJzaeffordu3fDzMwMw4cPxwcffICqVfOG4G7ZsgVdunTRe5BERTG/jxfcbM0QnZiBz/exeYqIqLIq1iR+gLREgr+/P5ycnNCmTRudffv27YO3t3eRRz0ZQnEmAaLy58yNB3j91zMAgDVvtkI3z4LnPyIiovKlOPfvYic35R2Tm4rvk70hWH0qEo7WShya3gU25saGDomIiF5Qic1QvG7duiKVe3zoNlFp++BlTxwPu4cb8Wn4eM8VfPd6M0OHREREpajYq4JbWlrCyMjoqSOdZDIZHj58qLcA9Y01N5XDhagEvLbSHxoBzH2lPiZ0qW3okIiI6AUU5/5drA7FXl5eMDExwZgxY+Dr64uEhIR8X2U5saHKo3mNqpjzcn0AwJf/XMX60zcNGxAREZWaYiU3wcHB2LdvHzIyMtC5c2e0bNkSK1euRHJycknFR/Tc3u1SG5O6STU2H+0OxvaAO884goiIKoJiJTcA0KZNG/zyyy+IjY3F1KlTsW3bNjg7O2PUqFHFmsCPqDS838sTPu09AACz/7qIfy7HGjYgIiIqccVObnKZmZlhzJgxWLx4MVq3bo0tW7YgPZ0rM1PZIpPJsLCfN4a1rA6NAKZuCcTxsHuGDouIiErQcyU30dHR+OKLL1C3bl28/vrraNWqFYKDg3Um9CMqK+RyGZYMbox+jZ2RoxaYsikQN+6nGjosIiIqIcVKbrZt24ZXXnkFdevWxblz57B06VLcvn0bX3/9NerXr19SMRK9MIVchuXDm6K1hy1SslSYsCEAaVkqQ4dFREQloNhDwWvUqIFRo0bB0dHxqeWmTp2ql+BKAoeCV273UjLR74eTuJeShb6NnfG/Ec0gk8kMHRYRET1Dic1Q7OHh8cwbgUwmw40bN4p6ylLH5IYCbj3E8F/OQKUR+LCvF97uVMvQIRER0TOU2AzFN2/efGaZ6Ojo4pySqNS1cLfFwv7eWLg7GEv+uYoGLjZoV9vO0GEREZGePPdoqSfFxcVh6tSpqFOnjr5OSVRiRrd1x+BmrlBrBCZvuoDYpAxDh0RERHpSrOQmMTERo0aNgr29PVxcXPDDDz9Ao9Fg4cKFqFWrFk6fPo3Vq1eXVKxEeiOTyfD5q43g7WyNB2nZmLo5ECq1xtBhERGRHhQruZk/fz5OnDiBsWPHwtbWFjNmzEC/fv1w8uRJ/PPPPzh37hxGjBhRUrES6ZWZiQI/jWoOS6URzt1MwLeHrhk6JCIi0oNiJTf79u3DmjVr8O2332LPnj0QQqBevXo4evQounTpUlIxEpUYj2oW+Pq1xgCAn30jcOwqJ/gjIirvipXcxMTEwNvbGwBQq1YtmJqa4u233y6RwIhKS59Gzhjbzh0AMGNbEGIS2f+GiKg8K1Zyo9FoYGxsrH2uUChgYWGh96CIStv8vl5o5GqDxPQcTN50ATnsf0NEVG4Vayi4EAI+Pj5QKpUAgMzMTEyYMCFfgrNjxw79RUhUCpRGCqwY2Rx9f/TDhahEfH3gKhb09TZ0WERE9ByKldyMHTtW5/kbb7yh12CIDKmGnTm+ea0xJmy4gN/8IuHlbI3BzasbOiwiIiqmYs1QXBFwhmJ6lm8OXsWKYxEwMZJjyztt0bwGF4QlIjK04ty/9TaJH1FFMaunJ3p6OyJbpcE76wLYwZiIqJxhckP0BLlchu+GN0V9JyvEp2Zh/LrzSM/mCuJEROUFkxuiAlgojfDbmJawtTBBcEwyZv95CZWsBZeIqNxickP0FG625vj5jRYwVsiw73IsFu4OhkbDBIeIqKxjckNUiNY1bfHl4MaQyYD1Z25h/s7LUDPBISIq05jcED3DkBbVsXRoE8hlwJZztzH7z4tcZJOIqAxjckNUBIObV8cPI5pBIZdhR2A0pm0N4izGRERlFJMboiLq19gFP41qLvXBuRSLSRsvIFvFBIeIqKxhckNUDL0bOOHX0S1hYiTHoZC7XIeKiKgMYnJDVEzd6jvgtzFMcIiIyiomN0TPoUs9e/w6ugVMjOQ4GHwXUzcHMsEhIiojmNwQPaeung74ZXQLmCjk+OdKHKZtYYJDRFQWMLkhegHdHktw9l+Ow5y/LnGiPyIiA2NyQ/SCutV3wMo3msPo0TDxrw5cNXRIRESVGpMbIj14ycsRXw1pDAD45cQN/O53w8ARERFVXkxuiPRkSIvqmPNyfQDAZ/tCsTso2sARERFVTkxuiPRoQpdaeLODBwDg/T8vwi/8vmEDIiKqhJjcEOmRTCbDR3290b+JC3LUAhPWByAkJtnQYRERVSpMboj0TC6X4duhjdG+th3SstUY98c53E3ONHRYRESVBpMbohKgNFJg5agWqG1vgdikTLz9x3mkZ6sMHRYRUaXA5IaohNiYG2O1TyvYWpjgcnQSpm8Jgppz4BARlTgmN0QlyN3OQlqmQSGtQ8U5cIiISh6TG6IS1tLDFt8MlebA+fXEDXyxPxRpWWyiIiIqKUxuiErBwKaumNmzHgApwem+9Dh2Bt6BEGymIiLSNyY3RKVkSvc6+GV0C7jZmuFuchZmbL2IISv9cflOkqFDIyKqUJjcEJUSmUyG3g2ccHhGF8zu7QlzEwUuRCXi1Z9O4djVe4YOj4iowmByQ1TKTI0VmNStDo7O6ooeXo5QaQTe23gBQbcTDR0aEVGFwOSGyECcbEyx8o3m6FS3GjJy1Hhr7TlExqcZOiwionKPyQ2RARkr5Fj5Rgs0crXBw7RsjFn9H+6nZBk6LCKico3JDZGBWSqNsNqnFWrYmuP2wwy8ufYsUjlUnIjouTG5ISoD7K2UWPdWa9hZmOBKdDLeXX8emTlqQ4dFRFQuMbkhKiM8qllgtU8rmJsocOr6A0zZHIgctcbQYRERlTtMbojKkCZuVfD72JYwMZLjcMhdfPDXJWi4HhURUbEYNLlZsmQJWrVqBSsrKzg4OGDQoEEICwsr9JjY2FiMHDkSnp6ekMvlmD59eukES1RK2teuhp9GNoeRXIadgdFYuOcKZzImIioGgyY3vr6+mDRpEs6cOYPDhw9DpVKhV69eSEt7+nDYrKws2NvbY8GCBWjSpEkpRktUenp4O2LpsCaQyYANZ6Lw5YGrXFGciKiIZKIMfSS8f/8+HBwc4Ovri86dOz+zfNeuXdG0aVN89913RX6N5ORk2NjYICkpCdbW1i8QLVHJ2/RfFObvvAwAcLExxYjWNTC8tRscrEwNHBkRUekqzv3bqJRiKpKkJGmNHVtbW72dMysrC1lZefOGJCcn6+3cRCVtZJsaEBD45mAYYpIysfTwNXz/bzh6N3DCwKYuaFvbDtamxoYOk4ioTCkzyY0QAjNnzkTHjh3RsGFDvZ13yZIlWLx4sd7OR1TaRrVxx5Dm1bH/ciw2/heFgFsJ2Hc5Fvsux0Ihl6FJdRt0rFMNXTwd0LxGFchkMkOHTERkUGWmWWrSpEnYt28fTp48ierVqxfpmKI0SxVUc+Pm5sZmKSq3QmKSse38bZy4dh83nliuYUw7d3zcvwEUciY4RFSxlLtmqSlTpmDPnj04ceJEkRObolIqlVAqlXo9J5EhebtYY9GABgCAOwnp8L/+AL7h97H/cizWnb6F+ylZWD68KUyNFQaOlIjIMAw6WkoIgcmTJ2PHjh04evQoatasachwiMqd6lXNMayVG1aMbI4fRzSDiUKOf67EYczqs0hKzzF0eEREBmHQ5GbSpEnYsGEDNm3aBCsrK8TFxSEuLg4ZGRnaMvPmzcOYMWN0jgsKCkJQUBBSU1Nx//59BAUFISQkpLTDJypT+jV2wdq3WsFKaYSzkQ8x9Bd/xCZlPPtAIqIKxqB9bp7W8XHNmjXw8fEBAPj4+ODmzZs4fvx4oce5u7vj5s2bz3xNDgWnii40NhljV5/FvZQs1LA1x99TO3JEFRGVe8W5f5eZDsWlhckNVQZ3EtIx/JcziE7MwOBmrlg2vKmhQyIieiHFuX9zbSmiCqh6VXN8/3pTyGXAjsBo7A6KNnRIRESlhskNUQXV0sMWk7vXBQB8uOsK7iSkGzgiIqLSweSGqAKb2r0OmtWogpRMFWZuu8j1qYioUmByQ1SBGSnk+G54U1iYKHA28iF+9o0wdEhERCWOyQ1RBeduZ4HFA6UlTZYfvoYVx67j5hMzGxMRVSQcLUVUCQghMGVzIP6+FKvd5u1sjT6NnDCwqSvcbM0NGB0R0bNxKHghmNxQZZWt0mD7hTvYfzkW/hEPtP1vlEZyLBncCIOb63fpEyIifWJyUwgmN0RAQlo2DoXE4c/zd3D+VgIA4K0ONTG/T30YKdhaTURlD+e5IaJCVbUwwfBWNbDt3XaY0r0OAGD1qUiMWX0WD9OyDRwdEdGLYXJDVInJ5TLM6uWJn99oDnMTBfwjHqD/jycR8Kg2h4ioPGJyQ0R4uaEzdr7XAe525ohOzMBrP/tj3o7LSExnLQ4RlT9MbogIAODpZIU9kzpiSPPqEALYfDYKLy31xfaAO6hkXfOIqJxjh2Iiyue/Gw/w4a4rCL+XCgBo6V4VY9t7oFcDRyiNFAaOjogqI46WKgSTG6KiyVZp8PvJG/jh33Bk5mgAAFXMjfFqM1cMb+WG+k78+yGi0sPkphBMboiKJyYxA5vPRuHP83cQl5yp3d6hjh1m9vREC/eqBoyOiCoLJjeFYHJD9HzUGoET4fex7dxtHA65C9WjSQC713fAzJ710NDVxsARElFFxuSmEExuiF7cnYR0/O/odfwZcEc70/HLDZwwo2c9eDpZGTg6IqqImNwUgskNkf5Exqfh+yPXsPtiDIQAZDKgbyNnTO9RF3UcmOQQkf4wuSkEkxsi/bt2NwXfHbmG/ZfjAEhJzsAmLpjWox5qVrMwcHREVBEwuSkEkxuikhMSk4zvjlzDoZC7AAAjuQwjWtfA1Jfqwt5KaeDoiKg8Y3JTCCY3RCXvSnQSlh4Kw7Gw+wAACxMF3ulcG293qgkLpZGBoyOi8ojJTSGY3BCVntMRD/DlP6G4eCcJAGBvpcT7verhtRZuUMhlBo6OiMoTJjeFYHJDVLqEENh3ORZfHwhD1MN0AEADF2t81M8bbWvZGTg6IiovmNwUgskNkWFkqzRYd/omvv83HCmZKgDAKw2dMO8VL9SwMzdwdERU1jG5KQSTGyLDepCaheVHrmHTf1HQCMBYIcOoNu6Y3L0Oqlmy0zERFYzJTSGY3BCVDWFxKfhsXwj8wuMBSJ2Ox3euhbc71YIlOx0T0ROY3BSCyQ1R2XLqejy+/OcqLkdLnY7tLEzQv4kLejdwQiuPqjBSyA0cIRGVBUxuCsHkhqjs0WgE9l+JxbcHw3DzQbp2e1VzY7zk5Yh+jZ3Rua495BxhRVRpMbkpBJMborIrR63B8bD7OBgchyOhd5GYnqPd52FnjtHtPDC0ZXVYmxobMEoiMgQmN4VgckNUPqjUGpy9+RAHrsRhZ2C0doSVuYkCQ5pX56zHRJUMk5tCMLkhKn/SslTYGRiNP/xvIvxeKgCgtr0F/pzQHrYWJgaOjohKQ3Hu3+ypR0RlnoXSCG+0dcehGZ2x8e02cLYxRcT9NLy55ixSs1SGDo+IyhgmN0RUbshkMnSoUw3rx7VGVXNjXLyThAnrA5ClUhs6NCIqQ5jcEFG5U8fBCmvebA1zEwVOXo/HjK1BUGsEMnPUOBZ2Dwt2XkaPZb746fh1Q4dKRAbAPjdEVG6dDI/Hm2vPIkct4O1sjZsP0pCerVuLM7u3JyZ1q2OgCIlIX9jnhogqhY51q+H715tBJgNCYpORnq2Gk7UpRrWpgfGdagIAvjkYht/9bhg4UiIqTZzjnIjKtT6NnLFqbEuExqagSz17NHCxhkwmTfZnZWqMZYev4bN9oTAxkmNMOw/DBktEpYLJDRGVe93rO6J7fcd826d0r4MslRorjkVg4e5g5KgFGle3QVaOBtlqNbJVAi3cq3K+HKIKhskNEVVYMpkM7/fyRFaOBr+fjMSnf4fkK1OzmgX+mdYJpsYKA0RIRCWByQ0RVWgymQwL+nrBXGmEnYF3YCSXQ2kkh4mRHDfj0xAZn4Yfj4Zjdu/6hg6ViPSEo6WIqNI6cCUOEzYEwEguw94pHeHlzP8JRGUVR0sRERXByw2d0LuBI1Qagbk7LkOtqVSf9YgqLCY3RFSpfTKwIayURrh4OxHrTt80dDhEpAdMboioUnO0NsWcV6T+Nt8cDEN0YoZ2X0a2GqcjHiDqQbqhwiOi58AOxURU6Y1sXQO7AqNx/lYC5vx1CS09qsI/4gGCohKRrdbA3ESBFSObo1t9B0OHSkRFwA7FREQAwu+moM8PfshR6/5LtDBRIC1bDbkM+HRQQ4xq426gCIkqt+Lcv1lzQ0QEoK6jFT7q541VJyPRyNUG7WtXQ7vadnCtYob5Oy/jr4A7WLDzCu4kZGB2L0/I5TJDh0xET8GaGyKiZxBC4Id/r2P5kWsAgAFNXDC+Uy3UdrCAuQk/IxKVhuLcv5ncEBEV0V8BdzB3+yWoHhsy7lrFDLUdLNHI1Rrd6zugqVtVKFirQ6R3TG4KweSGiF6Ef0Q8fvz3Oq7dTcGDtOx8+20tTNC1nj26ezmgl7cTTIw4KJVIH5jcFILJDRHpS0JaNq7fT0X43VScufEAx8PuITlTpd3fyqMqfhvTElXMTQwYJVHFwOSmEExuiKikqNQaBNxKwNGr97DpbBRSMlWoZW+BP95sDTdbc0OHR1SuMbkpBJMbIioN1+6mwGf1WcQkZaKapRJrfFqhUXWbQo+JTcqAX3g8ohMyEJ2YgeiEDNxNycSgpq6Y+lLdUoqcqGxiclMIJjdEVFruJmfCZ805hMYmw9xEge+GN0VPb0fIZLodjpMycvDT8etYc+omslWafOeRyYC9kzuioWvhyRFRRcbkphBMboioNKVk5uC9jRfgFx4PQBpd1buBE3o1cERTtyrYfDYKP/wbjoT0HABA4+o28Ha2RvWqZnCtaoZ9l+JwJPQuWnlUxbZ32+VLjIgqCyY3hWByQ0SlLUetwef7QrH13G1k5Ki1243kMu2w8joOlpj3Sn10r++gk8DEJGag+9LjyMzR4McRzdC/iUupx09UFjC5KQSTGyIylIxsNfzC7+Ng8F38e/UuEtNzUM1SiRk962J4SzcYKQoeNv79kXAsP3INLjam+HdWV5iZKEo5ciLDY3JTCCY3RFQW5Kg1iLifihq25s+c5TgjW40ey3wRnZiBGT3qYVoPdi6myqc492+Dzi61ZMkStGrVClZWVnBwcMCgQYMQFhb2zON8fX3RokULmJqaolatWvj5559LIVoiIv0xVshR38m6SMs3mJkoMK9PfQDASt/riEnMKOnwiMo1gyY3vr6+mDRpEs6cOYPDhw9DpVKhV69eSEtLe+oxkZGR6NOnDzp16oTAwEDMnz8fU6dOxfbt20sxciKi0tW3kTNae9giM0eDL/+5WmjZWw/ScCg4rsCRV0SVQZlqlrp//z4cHBzg6+uLzp07F1hmzpw52LNnD0JDQ7XbJkyYgIsXL+L06dP5ymdlZSErK0v7PDk5GW5ubmyWIqJy50p0Evr/7ySEAJrVqIJmblXRrEYVNHWrgtikTPwbehdHQu8i4r70AfGVhk7438jmXOuKKoTiNEuVqeVsk5KSAAC2trZPLXP69Gn06tVLZ1vv3r2xatUq5OTkwNjYWGffkiVLsHjxYv0HS0RUyhq62mBCl9pYeTwCgVGJCIxKBE7lL2f0KJn550ocPt8XioX9vUs3UCIDKzM1N0IIDBw4EAkJCfDz83tquXr16sHHxwfz58/XbvP390eHDh0QExMDZ2dnnfKsuSGiiubWg7RHyU0CAm8nIiQmGZamRujm6YCXvBzQqa49fK/dx9TNgQCAj/p5Y1zHmgaOmujFlMuam8mTJ+PSpUs4efLkM8s+OYlVbn5W0ORWSqUSSqVSP0ESEZUB7nYWcLezwKBmrgCAbJUGRnIZ5I81Pw1o4oKYxAx8+c9VfLYvBC42pnilkfPTTklUoZSJ5GbKlCnYs2cPTpw4gerVqxda1snJCXFxcTrb7t27ByMjI9jZ2ektJrVajZycHL2dj4jKNhMTE8jlBh1j8dxMjAqO+93OtRCdkIH1Z25h+tYgZKk0UMhluJucifspWUjNUuHVZq5o6fH0rgBE5ZFBkxshBKZMmYKdO3fi+PHjqFnz2dWm7dq1w969e3W2HTp0CC1btszX3+Z5Y4qLi0NiYuILn4uIyg+5XI6aNWvCxMTE0KHojUwmw6IBDRCblIkjoXcxfWtQvjIb/4vCmHbu+ODl+rBUlonPu0QvzKB9bt577z1s2rQJu3fvhqenp3a7jY0NzMzMAADz5s1DdHQ01q1bB0AaCt6wYUO8++67GD9+PE6fPo0JEyZg8+bNGDJkyDNf81ltdrGxsUhMTISDgwPMzc25jgtRJaDRaBATEwNjY2PUqFGjwv3dZ2SrMWXzBVy/lwoHa1M4WCnhaG2K+NQs7A6KAQC42Jji88GN0M3TwcDREhWs3MxQ/LR/IGvWrIGPjw8AwMfHBzdv3sTx48e1+319fTFjxgwEBwfDxcUFc+bMwYQJE4r0moVdHLVajWvXrsHBwUGvTVxEVPYlJSUhJiYGderU0UstcHlx6no85u64hNsPpYkB+zRywtCWbuhQu9pTm7uIDKHcJDeGUNjFyczMRGRkJDw8PLQ1R0RUOWRkZODmzZuoWbMmTE1NDR1OqUrPVmHZoWtYfSoSj9bxhI2ZMXp5O6JvY2e0q20HpRHXsyLDKpejpcqSilYlTUTPVpn/7s1NjPBhP28MauaKredu458rcYhPzcKfAXfwZ8AdmBrL0crDFu1rV0OHOnao62CFuORMRCdkIDoxHfGp2ehSzx4NXW1eKA6NRkAAnHSQXhhrbh6TW3NTGT+5EVV2/PvPo9YInI18iP2XY3EgOA73U7KeeYyJQo4fRjTDyw2dnus1bz9Mh8+aszBWyLF5fFtUtag4HbtJP1hzQ0REz00hl6FdbTu0q22HTwY2wLW7qfCPiMep6w/w340HSMlSwcxYAdeqZnCtYob0bBXO3UzAexsD8NWQxhja0q1Yr3c3OROjfv8PUQ/TAQAztwVh1dhWOvP2EBUHkxuiCkomk2Hnzp0YNGiQoUOhckwmk8HTyQqeTlZ4s0NNqNQapGWpYW1mpG3KU6k1mL/zMradv4PZf11CcqaqyDMiP0zLxhuPEhvXKmaIT83CsbD7WOkbgUnd6pTkW6MKjMkNPdXx48fRrVs3JCQkoEqVKoYOh4jKACOFHDbm8nzbvhrSGNamxvj9ZCQ+/TsE0QkZcK1qhuiEDNxJSEdMUgacrM3Qv4kzeng5wkJphOTMHIxZ/R/C76XCydoUW95pC/+IeMzZfhlLD4WheY2qaFebI1ep+JjcVFDZ2dkVajKyyqqgxWDLgqf9fj1vvGX1fVLRyWQyLOjrhSrmxvj20cirJ12JTsaR0LswNZbjpfqOiE7MwJXoZNhZmGDD223gZmuOYVXdcDYyAdsv3MGUzYHYP60jHKwqdx8oKj5OYvAMQgikZ6sM8lWcvt5du3bF5MmTMXPmTFSrVg09e/aEr68vWrduDaVSCWdnZ8ydOxcqlUp7TFZWFqZOnQoHBweYmpqiY8eOOHfuHADg5s2b6NatGwCgatWqkMlk2rmHnhXHlClTMH36dFStWhWOjo749ddfkZaWhjfffBNWVlaoXbs2/vnnH53jQkJC0KdPH1haWsLR0RGjR49GfHy8dv+BAwfQsWNHVKlSBXZ2dujXrx8iIiK0+2/evAmZTIYdO3agW7duMDc3R5MmTXD69OkiXb9bt26hf//+qFq1KiwsLNCgQQPs379fu3///v2oV68ezMzM0K1bN6xduxYymUw7k/WiRYvQtGlTnXN+99138PDw0D4/d+4cevbsiWrVqsHGxgZdunTBhQsXdI6RyWT4+eefMXDgQFhYWOCzzz4DAOzduxctWrSAqakpatWqhcWLF+v8LMPDw9G5c2eYmprC29sbhw8fLtL7zhUdHY3hw4ejatWqsLOzw8CBA3Hz5k3tfh8fHwwaNAhLliyBi4sL6tWrp73m27ZtQ9euXWFqaooNGzZAo9Hgk08+QfXq1aFUKtG0aVMcOHBAe66nHUfln0wmw+TudfHt0CZoV8sOfRs5493OtfDJwAb4dXQLTOleBx525sjM0WDf5VgE3U6EtakR1o1rjToOltpzfDaoITwdrRCfmoWpmwOhUmsM/M6ovGHNzTNk5KjhvfCgQV475JPeMDcp+o/ojz/+wMSJE3Hq1CnEx8ejV69e8PHxwbp163D16lWMHz8epqamWLRoEQDggw8+wPbt2/HHH3/A3d0dX3/9NXr37o3r16/Dzc0N27dvx5AhQxAWFgZra+siz/3zxx9/4IMPPsDZs2exdetWTJw4Ebt27cKrr76K+fPnY/ny5Rg9ejSioqJgbm6O2NhYdOnSBePHj8eyZcuQkZGBOXPmYNiwYTh69CgAIC0tDTNnzkSjRo2QlpaGhQsX4tVXX0VQUJDOekALFizAt99+i7p162LBggUYMWIErl+/DiOjwq/jpEmTkJ2djRMnTsDCwgIhISGwtJT+2d6+fRuDBw/GhAkTMHHiRJw/fx6zZs0q8s8lV0pKCsaOHYsffvgBALB06VL06dMH4eHhsLKy0pb7+OOPsWTJEixfvhwKhQIHDx7EG2+8gR9++AGdOnVCREQE3nnnHW1ZjUaDwYMHo1q1ajhz5gySk5Mxffr0IseVnp6Obt26oVOnTjhx4gSMjIzw2Wef4eWXX8alS5e0NTT//vsvrK2tcfjwYZ3Ee86cOVi6dCnWrFkDpVKJ77//HkuXLsUvv/yCZs2aYfXq1RgwYACCg4NRt27dpx5HFcdrLarjtRb51wns1cAJM3vWQ3BMMvZejMGVmCTM7l0fDVx0h5CbmSjw0xvNMeDHkzhz4yHe23gBSwY3gp0lf0+oiEQlk5SUJACIpKSkfPsyMjJESEiIyMjI0G5Ly8oR7nP+NshXWlZOkd9Xly5dRNOmTbXP58+fLzw9PYVGo9FuW7FihbC0tBRqtVqkpqYKY2NjsXHjRu3+7Oxs4eLiIr7++mshhBDHjh0TAERCQkKx4ujYsaP2uUqlEhYWFmL06NHabbGxsQKAOH36tBBCiI8++kj06tVL5zy3b98WAERYWFiBr3Pv3j0BQFy+fFkIIURkZKQAIH7//XdtmeDgYAFAhIaGPjPuRo0aiUWLFhW4b968ecLLy0vnWs6ZM0fn2nz88ceiSZMmOsctX75cuLu7P/U1VSqVsLKyEnv37tVuAyCmT5+uU65Tp07iiy++0Nm2fv164ezsLIQQ4uDBg0KhUIjbt29r9//zzz8CgNi5c+dTXz/XqlWr8v2uZGVlCTMzM3Hw4EEhhBBjx44Vjo6OIisrS1sm95p/9913OudzcXERn3/+uc62Vq1aiffee6/Q4wytoL9/Mqz9l2JE7Xn7hPucv0WLTw+JQ8Fxhg6JDKiw+/eTWHPzDGbGCoR80ttgr10cLVu21D4ODQ1Fu3btdCYm69ChA1JTU3Hnzh0kJiYiJycHHTp00O43NjZG69atERoa+kJxN27cWPtYoVDAzs4OjRo10m5zdHQEIK3mDgABAQE4duyYtqbkcREREahXrx4iIiLw0Ucf4cyZM4iPj4dGI1VTR0VFoWHDhgW+trOzs/Z16tevX2jMU6dOxcSJE3Ho0CH06NEDQ4YM0Z4rNDQUbdu21bmW7dq1K9rFeMy9e/ewcOFCHD16FHfv3oVarUZ6ejqioqJ0yj3+cwSk63Pu3Dl8/vnn2m1qtRqZmZlIT09HaGgoatSogerV8z4pFye+gIAAXL9+Xaf2CJDmfXm86a9Ro0YF9rN5PN7k5GTExMTo/F4B0u/exYsXC32fRE96pZEzdtmaY8bWIITfS8X4defxWovqWNjfG9am7KNFT8fk5hlkMlmxmoYMycLCQvtYCJFvxlXxqClBJpPpPH6yzIvO1Ppkx1CZTKazLff8uQmKRqNB//798dVXX+U7V26C0r9/f7i5ueG3336Di4sLNBoNGjZsiOzs7Ke+9pOvU5i3334bvXv3xr59+3Do0CEsWbIES5cuxZQpU4rU90kul+crl5OTo/Pcx8cH9+/fx3fffQd3d3colUq0a9cu33t4/OeYG//ixYsxePDgfK9rampaYHzF+RlqNBq0aNECGzduzLfP3t7+qXEVtr0ov1dPOx/R4xq62mDvlI5YdvgafvO7gb8C7uDU9Xi838sTrzZz5Vw4VCB2KK6gvL294e/vr3Pj8/f3h5WVFVxdXVGnTh2YmJjg5MmT2v05OTk4f/48vLy8AED7KV2tVpdorM2bN0dwcDA8PDxQp04dnS8LCws8ePAAoaGh+PDDD/HSSy/By8sLCQkJeo/Dzc0NEyZMwI4dOzBr1iz89ttvAKRreebMGZ2yTz63t7dHXFyczvUOCgrSKePn54epU6eiT58+aNCgAZRKpU6n6adp3rw5wsLC8l2bOnXqQC6Xw9vbG1FRUYiJidEeU9SO1LnnDw8Ph4ODQ77z29gUbzp9a2truLi46PxeAdLvXu7vFVFxmRorML+PF7a+0w41bM0Rm5SJWX9eRL8fT8Iv/P4zj49JzMC60zdx+U5SKURLZQGTmwrqvffew+3btzFlyhRcvXoVu3fvxscff4yZM2dCLpfDwsICEydOxOzZs3HgwAGEhIRg/PjxSE9Px7hx4wAA7u7ukMlk+Pvvv3H//n2kpqaWSKyTJk3Cw4cPMWLECJw9exY3btzAoUOH8NZbb0GtVmtH8Pz666+4fv06jh49ipkzZ+o1hunTp+PgwYOIjIzEhQsXcPToUe3NeMKECYiIiMDMmTMRFhaGTZs2Ye3atTrHd+3aFffv38fXX3+NiIgIrFixIt+IsDp16mD9+vUIDQ3Ff//9h1GjRhWpk/bChQuxbt06LFq0CMHBwQgNDcXWrVvx4YcfAgB69OgBT09PjBkzBhcvXoSfnx8WLFhQ5Pc+atQoVKtWDQMHDoSfnx8iIyPh6+uLadOm4c6dO0U+T67Zs2fjq6++wtatWxEWFoa5c+ciKCgI06ZNK/a5iB7XuqYtDs3ojDkv14eV0gghsckYveosxqw+i23nb+Ns5EPcS8mEEAIpmTnYdv42Rvx6Bh2+OoqFu4Mx6KdT+P5IOEdfVQJMbiooV1dX7N+/H2fPnkWTJk0wYcIEjBs3TntDBIAvv/wSQ4YMwejRo9G8eXNcv34dBw8eRNWqVbXnWLx4MebOnQtHR0dMnjy5RGJ1cXHBqVOnoFar0bt3bzRs2BDTpk2DjY0N5HI55HI5tmzZgoCAADRs2BAzZszAN998o9cY1Go1Jk2aBC8vL7z88svw9PTETz/9BACoUaMGtm/fjr1796JJkyb4+eef8cUXX+gc7+XlhZ9++gkrVqxAkyZNcPbsWbz//vs6ZVavXo2EhAQ0a9YMo0eP1g7Df5bevXvj77//xuHDh9GqVSu0bdsWy5Ytg7u7OwCpSWznzp3IyspC69at8fbbb+v0z3kWc3NznDhxAjVq1MDgwYPh5eWFt956CxkZGc9cv6UgU6dOxaxZszBr1iw0atQIBw4cwJ49e3RGShE9L1NjBSZ2rQ3fD7rhrQ41YayQ4cS1+/jgr0sY9stptP78XzT4+CBafnYEH/x1CadvPIAQQG17C6g1AsuPXMPrv57B7UdLPVDFxIUzH8OF86ioOHtzxcO///Lp1oM0/OF/C+H3UnDzQRqiEzKgeXRXq2VvgcHNXDGwqSvcbM2xM/AOPtoVjNQsFayURvh4QAP0auDIzsnlBBfOJCKiSsHdzgIL+3trn2erNLiTkA61RqCOg6VOR/ZXm1VHS3dbTNsSiAtRiXj/z4vAn4CTtSnqOlqinqMVmrhVQfvadqjGOXXKNSY3VGRRUVHw9vZ+6v6QkBDUqFGjFCMquldeeQV+fn4F7ps/fz7mz59fyhGVni+++CJfM1quTp065esbRFSemRjJUcs+/7QSudxszbHt3Xb46XgENv0XhbjkTO2XX3heB38vZ2t0qG2HjnWroUOdajBWsBdHecJmqcewWrpwKpVKZ0r+J3l4eDxzJmBDiY6ORkZGRoH7bG1tYWtrW8oRlZ6HDx/i4cOHBe4zMzODq6trKUdUNvHvv3JKysjB9XspuHY3FWFxKTgb+RAhsck6ZewsTDCwqStea1Ed3i7F74dG+lGcZikmN4/hPzeiyot//5TrQWoW/CMe4NT1eBwJvYf41CztPm9na/TwckD1quZwqWIG5yqmcLExg5lJ8SZdpeJjnxsiIqLnZGepRP8mLujfxAUqtQZ+4fH4K+AODofcRUhscr6aHQBwsFLC3c4cNWwt4G5njkauNuhczx4KTjJoEExuiIiInsJIIUe3+g7oVt8BienZ+PtSLIJjkhGTmIHYpAxEJ2QgLVuNeylZuJeShXM38yYYrWFrDp/2HhjasjqsOCKrVDG5ISIiKoIq5iZ4o627zjYhBJIychD1MB03H6Qj6kEaIuPT8e/Vu4h6mI5P/g7BssPXMKylG15p5IRGrjYwLea6gVR8TG6IiIiek0wmQxVzE1QxN0Hj6lW02zOy1dgReAerT0Yi4n4aVp+KxOpTkTCSy+DtYo1mblVQy94S6dlqpGblIDVThZQsFVRqAQEpaRIAqpob493OteFma26ot1guMbkhIiLSMzMTBUa1cceIVjVwIvw+tp67jfO3EnA/JQuX7iThUjHWudoVGIOP+nlhWEu3F17YuLJgckMApGHc06dPx/Tp0w0dCpVDnLGZqGByuQxdPR3Q1dMBQghEJ2YgMCoRF6ISEJuYCUtTI1gqjWBlagQLpRGMFXLIAOTmMPsuxeL8rQTM2X4Zh4LvYsngRnCw5mi+Z2FyQ2XGokWLsGvXrnyraRMRVQQymQzVq5qjelVz9G/iUqRjxrTzwO9+N7D00DX8e/Ueen13AuM71YK3izU8Ha3gbGPK2pwCMLmhF5aTkwNjY44EKO+EEFCr1WVyIsbs7GyYmJjobFOr1ZDJZJDLizdz7PMeR2QICrkM73apjW71HTBzWxCuRCfjm4Nh2v1WSiN4uVhjdFt39G3kDDmHngPgquBFl51W+JdalVdWlV142ZzHZsoVouAyxfDLL7/A1dUVGo1GZ/uAAQMwduxYREREYODAgXB0dISlpSVatWqFI0eOPPelkMlk+PnnnzFw4EBYWFjgs88+AwCsXLkStWvXhomJCTw9PbF+/Xqd46KiojBw4EBYWlrC2toaw4YNw927dwEAa9euxeLFi3Hx4kXIZDLIZDKsXbu2SLH88ssv6NevH8zNzeHl5YXTp0/j+vXr6Nq1KywsLNCuXTtEREToHLd37160aNECpqamqFWrFhYvXgyVKu9nuGzZMjRq1AgWFhZwc3PDe++9h9TUVO3+tWvXokqVKjh48CC8vLxgaWmJl19+GbGxsUW6hsePH0fr1q1hYWGBKlWqoEOHDrh165Z2/5dffglHR0dYWVlh3LhxmDt3Lpo2bard37Vr13xNiIMGDYKPj4/2+YYNG9CyZUtYWVnByckJI0eOxL1793RikMlkOHjwIFq2bAmlUgk/Pz8IIfD111+jVq1aMDMzQ5MmTfDXX3/pvNb+/ftRr149mJmZoVu3boXOXF0Qf39/dO7cGWZmZnBzc8PUqVORlpb3e+/h4YHPPvsMPj4+sLGxwfjx47XX/O+//4a3tzeUSiVu3bqFhIQEjBkzBlWrVoW5uTleeeUVhIeHa8/1tOOIypN6jlbY+V4HLB7QAP0aO6OeoyWM5DKkZKlwNvIhpmwORN8fT+JIyF1Usrl5CyYqmaSkJAFAJCUl5duXkZEhQkJCREZGRv4DP7Yu/OvKjryyBxcUXvaXLnllU+8XXKYYHjx4IExMTMSRI0e02x4+fChMTEzEwYMHRVBQkPj555/FpUuXxLVr18SCBQuEqampuHXrlra8u7u7WL58eZFeD4BwcHAQq1atEhEREeLmzZtix44dwtjYWKxYsUKEhYWJpUuXCoVCIY4ePSqEEEKj0YhmzZqJjh07ivPnz4szZ86I5s2biy5dpGuRnp4uZs2aJRo0aCBiY2NFbGysSE9PL1Isrq6uYuvWrSIsLEwMGjRIeHh4iO7du4sDBw6IkJAQ0bZtW/Hyyy9rjzlw4ICwtrYWa9euFREREeLQoUPCw8NDLFq0SFtm+fLl4ujRo+LGjRvi33//FZ6enmLixIna/WvWrBHGxsaiR48e4ty5cyIgIEB4eXmJkSNHPjPmnJwcYWNjI95//31x/fp1ERISItauXav9eWzdulWYmJiI3377TVy9elUsWLBAWFlZiSZNmmjP0aVLFzFt2jSd8w4cOFCMHTtW+3zVqlVi//79IiIiQpw+fVq0bdtWvPLKK9r9x44dEwBE48aNxaFDh8T169dFfHy8mD9/vqhfv744cOCAiIiIEGvWrBFKpVIcP35cCCFEVFSUUCqVYtq0aeLq1atiw4YNwtHRUQAQCQkJz3z/ly5dEpaWlmL58uXi2rVr4tSpU6JZs2bCx8dHW8bd3V1YW1uLb775RoSHh4vw8HDtNW/fvr04deqUuHr1qkhNTRUDBgwQXl5e4sSJEyIoKEj07t1b1KlTR2RnZ+v8rJ487kmF/v0TlUFZOWpxNTZZfHf4mmi48IBwn/O3cJ/ztxi04qRY5x8p1p++Kdb5R4o//CPFhjM3xeU7iUKt1ug9jmyVWu/nLEhh9+8nMbl5THlNboQQYsCAAeKtt97SPv/ll1+Ek5OTUKlUBZb39vYWP/74o/Z5cZOb6dOn62xr3769GD9+vM62oUOHij59+gghhDh06JBQKBQiKipKuz84OFgAEGfPnhVCCPHxxx/r3MCLGsuHH36ofX769GkBQKxatUq7bfPmzcLU1FT7vFOnTuKLL77QOc/69euFs7PzU19n27Ztws7OTvt8zZo1AoC4fv26dtuKFSuEo6PjM2N+8OCBAKBNFp7Url07MWHCBJ1tbdq0KXZy86SzZ88KACIlJUUIkZfc7Nq1S1smNTVVmJqaCn9/f51jx40bJ0aMGCGEEGLevHnCy8tLaDR5/yTnzJlT5ORm9OjR4p133tHZ5ufnJ+RyufZvz93dXQwaNEinTO41DwoK0m67du2aACBOnTql3RYfHy/MzMzEtm3bnnpcQZjcUHn2MDVLLNkfKjw/3K9Ncgr6avbJITF50wWx9WyUiE549gfIwlyLSxbDfvYXdRfsF8sOhYmsnJJNcoqT3JS9xvWyan5M4fsVyrzH3RcCXec9vazssdZAc7tnn7sIRo0ahXfeeQc//fQTlEolNm7ciNdffx0KhQJpaWlYvHgx/v77b8TExEClUiEjIwNRUVHP/XotW7bUeR4aGop33nlHZ1uHDh3w/fffa/e7ubnBzc1Nu9/b2xtVqlRBaGgoWrVq9dyxNG7cWPvY0dERANCoUSOdbZmZmUhOToa1tTUCAgJw7tw5fP7559oyarUamZmZSE9Ph7m5OY4dO4YvvvgCISEhSE5OhkqlQmZmJtLS0mBhYQEAMDc3R+3atbXncHZ21mn2eRpbW1v4+Pigd+/e6NmzJ3r06IFhw4bB2dkZgHStJkyYoHNMu3btcOzYsWJdl8DAQCxatAhBQUF4+PChttnyydXdH/9ZhoSEIDMzEz179tQ5V3Z2Npo1a6aNr23btjqdGNu1a1fkuAICAnD9+nVs3LhRu00IAY1Gg8jISHh5eeWLK5eJiYnOzzs0NBRGRkZo06aNdpudnR08PT0RGhr61OOIKpqqFiaY+0p9vNXBA6tORiIyPg0yGSCDDDIZkJatRsDNh3iYlo29F2Ow96J036njYIlOdauhc117tKllC3OTZ6cFmTlqrDh2HT/7RiBHLTWBff9vOP65EouvhjRGsxpVS/S9FgWTm6IysSh6WSMTACbPLAZAGu9XnHM/Rf/+/aHRaLBv3z60atUKfn5+WLZsGQBg9uzZOHjwIL799lvUqVMHZmZmeO2115Cdnf3cr5d7g3/ckz32hRDabY8/flqZ5/V4Z+bccxW0LffmrtFosHjxYgwePDjfuUxNTXHr1i306dMHEyZMwKeffgpbW1ucPHkS48aNQ05OToGvm/s6ooht3WvWrMHUqVNx4MABbN26FR9++CEOHz6Mtm3bFul4uVye77Uejy0tLQ29evVCr169sGHDBtjb2yMqKgq9e/fO93N//GeZe4327duXb7VwpVJK4Iv6Hp9Go9Hg3XffxdSpU/Ptq1GjRoFx5TIzM9P5fXlaLE/+Xj15HFFF5WBtinl9vArcl6PWIDAqESfD7+NEeDwu3UnE9XupuH4vFWtO3YSxQgYPOwu420nrY3nYmcPR2hTGRnIYyWVQyGVISMvBNwev4uaDdADAS/Ud0MPbEd8eDMO1u6kYvNIfb3WoiVm96hUpUSopTG4qCDMzMwwePBgbN27E9evXUa9ePbRo0QIA4OfnBx8fH7z66qsAgNTU1GJ3AH0WLy8vnDx5EmPGjNFu8/f3134K9/b2RlRUFG7fvq2tvQkJCUFSUpK2jImJCdRqtV7jKkjz5s0RFhaGOnXqFLj//PnzUKlUWLp0qXZEzbZt2/QeR7NmzdCsWTPMmzcP7dq1w6ZNm9C2bVt4eXnhzJkzOtfyzJkzOsfa29vrdF5Wq9W4cuUKunXrBgC4evUq4uPj8eWXX2qv9/nz558ZU26H26ioKHTp0uWpZXbt2qWz7cn4CtO8eXMEBwc/9foXh7e3N1QqFf777z+0b98eAPDgwQNcu3ZN+3tFRBJjhRyta9qidU1bzOzliaT0HPhHxONEeDxOXLuP6MQMhN9LRfi91Geey9FaicUDGqB3AyfIZDK83MAJn/4dgh2B0Vh1MhKHQuKwfUJ7g83Jw+SmAhk1ahT69++P4OBgvPHGG9rtderUwY4dO9C/f3/IZDJ89NFH+UZWvajZs2dj2LBhaN68OV566SXs3bsXO3bs0I7K6tGjBxo3boxRo0bhu+++g0qlwnvvvYcuXbpomx88PDwQGRmJoKAgVK9eHVZWVtraAn1auHAh+vXrBzc3NwwdOhRyuRyXLl3C5cuX8dlnn6F27dpQqVT48ccf0b9/f5w6dQo///yz3l4/MjISv/76KwYMGAAXFxeEhYXh2rVr2mRm2rRpGDt2LFq2bImOHTti48aNCA4ORq1atbTn6N69O2bOnIl9+/ahdu3aWL58ORITE7X7a9SoARMTE/z444+YMGECrly5gk8//fSZsVlZWeH999/HjBkzoNFo0LFjRyQnJ8Pf3x+WlpYYO3YsJkyYgKVLl2LmzJl49913ERAQUKSRbbnmzJmDtm3bYtKkSRg/fjwsLCwQGhqKw4cP48cffyzyeQCgbt26GDhwIMaPH49ffvkFVlZWmDt3LlxdXTFw4MBinYuosrExN8YrjZzxSiNnCCFwJyEDkfFpuPUgDTcfpOPWg3TEp2ZBpdFApRZQawQ0QqBLPQfM6FlXZzHQqhYmWDa8Kfo3dcGCHZfhYWcBeyv9//8ushLr+VNGPXeH4nJApVIJZ2dnAUBERERot0dGRopu3boJMzMz4ebmJv73v//l65Ba3A7FO3fuzLf9p59+ErVq1RLGxsaiXr16Yt26dTr7b926JQYMGCAsLCyElZWVGDp0qIiLi9Puz8zMFEOGDBFVqlQRAMSaNWuKHUtkZKQAIAIDA7XbcjvOPt7Z9cCBA6J9+/bCzMxMWFtbi9atW4tff/1Vu3/ZsmXC2dlZmJmZid69e4t169bpnGPNmjXCxsZGJ5adO3eKovxJxcXFiUGDBglnZ2dhYmIi3N3dxcKFC4VandcZ7/PPPxfVqlUTlpaWYuzYseKDDz7Q6VCcnZ0tJk6cKGxtbYWDg4NYsmRJvg7FmzZtEh4eHkKpVIp27dqJPXv26Fybgq6LENLItu+//154enoKY2NjYW9vL3r37i18fX21Zfbu3Svq1KkjlEql6NSpk1i9enWROxQLIXVu7tmzp7C0tBQWFhaicePG4vPPP9fuL+j3saBrLoQ0MnD06NHCxsZG+/O6du3aM497Unn/+ycqK1Iyc8TdZP3/HRWnQ7FMiMo1ID45ORk2NjZISkqCtbW1zr7MzExERkaiZs2aMDXl9NZUdnD25pLHv3+isq2w+/eTOIkfERERVShMbkjHxo0bYWlpWeBXgwYNKm0sxfW0uC0tLeHn52fo8ErUK6+88tT3/sUXXxg6PCKqBNgs9RhWSwMpKSnaJRGeZGxsDHd390oZS3Fdv379qftcXV1hZmZWitGUrujoaGRkZBS4z9bWFra2tqUcUdHw75+obCtOsxRHS5EOKysrWFlZGToMAGUrluLSxzDn8urJ+XGIiEobm6UKUMkqs4gI/LsnqkiY3Dwmd8bZ9PR0A0dCRKUtd+ZmhUJh4EiI6EWxWeoxCoUCVapU0a4PZG5uzinbiSoBjUaD+/fvw9zcHEZG/LdIVN7xr/gJTk5OAFCkBRCJqOKQy+WoUaMGP9AQVQBMbp4gk8ng7OwMBwcHnYUIiahiMzEx0a4lRkTlG5Obp1AoFGx7JyIiKof4MYWIiIgqFCY3REREVKEwuSEiIqIKpdL1ucmdqCs5OdnAkRAREVFR5d63izLhZqVLblJSUgAAbm5uBo6EiIiIiislJQU2NjaFlql0C2dqNBrExMTAyspK7/NZJCcnw83NDbdv337mol70YnitSw+vdenhtS49vNalR1/XWgiBlJQUuLi4PHPahkpXcyOXy1G9evUSfQ1ra2v+sZQSXuvSw2tdenitSw+vdenRx7V+Vo1NLnYoJiIiogqFyQ0RERFVKExu9EipVOLjjz+GUqk0dCgVHq916eG1Lj281qWH17r0GOJaV7oOxURERFSxseaGiIiIKhQmN0RERFShMLkhIiKiCoXJDREREVUoTG705KeffkLNmjVhamqKFi1awM/Pz9AhlXtLlixBq1atYGVlBQcHBwwaNAhhYWE6ZYQQWLRoEVxcXGBmZoauXbsiODjYQBFXHEuWLIFMJsP06dO123it9Sc6OhpvvPEG7OzsYG5ujqZNmyIgIEC7n9daP1QqFT788EPUrFkTZmZmqFWrFj755BNoNBptGV7r53fixAn0798fLi4ukMlk2LVrl87+olzbrKwsTJkyBdWqVYOFhQUGDBiAO3fuvHhwgl7Yli1bhLGxsfjtt99ESEiImDZtmrCwsBC3bt0ydGjlWu/evcWaNWvElStXRFBQkOjbt6+oUaOGSE1N1Zb58ssvhZWVldi+fbu4fPmyGD58uHB2dhbJyckGjLx8O3v2rPDw8BCNGzcW06ZN027ntdaPhw8fCnd3d+Hj4yP+++8/ERkZKY4cOSKuX7+uLcNrrR+fffaZsLOzE3///beIjIwUf/75p7C0tBTfffedtgyv9fPbv3+/WLBggdi+fbsAIHbu3KmzvyjXdsKECcLV1VUcPnxYXLhwQXTr1k00adJEqFSqF4qNyY0etG7dWkyYMEFnW/369cXcuXMNFFHFdO/ePQFA+Pr6CiGE0Gg0wsnJSXz55ZfaMpmZmcLGxkb8/PPPhgqzXEtJSRF169YVhw8fFl26dNEmN7zW+jNnzhzRsWPHp+7ntdafvn37irfeektn2+DBg8Ubb7whhOC11qcnk5uiXNvExERhbGwstmzZoi0THR0t5HK5OHDgwAvFw2apF5SdnY2AgAD06tVLZ3uvXr3g7+9voKgqpqSkJACAra0tACAyMhJxcXE6116pVKJLly689s9p0qRJ6Nu3L3r06KGznddaf/bs2YOWLVti6NChcHBwQLNmzfDbb79p9/Na60/Hjh3x77//4tq1awCAixcv4uTJk+jTpw8AXuuSVJRrGxAQgJycHJ0yLi4uaNiw4Qtf/0q3cKa+xcfHQ61Ww9HRUWe7o6Mj4uLiDBRVxSOEwMyZM9GxY0c0bNgQALTXt6Brf+vWrVKPsbzbsmULLly4gHPnzuXbx2utPzdu3MDKlSsxc+ZMzJ8/H2fPnsXUqVOhVCoxZswYXms9mjNnDpKSklC/fn0oFAqo1Wp8/vnnGDFiBAD+XpekolzbuLg4mJiYoGrVqvnKvOj9k8mNnshkMp3nQoh82+j5TZ48GZcuXcLJkyfz7eO1f3G3b9/GtGnTcOjQIZiamj61HK/1i9NoNGjZsiW++OILAECzZs0QHByMlStXYsyYMdpyvNYvbuvWrdiwYQM2bdqEBg0aICgoCNOnT4eLiwvGjh2rLcdrXXKe59rq4/qzWeoFVatWDQqFIl+Wee/evXwZKz2fKVOmYM+ePTh27BiqV6+u3e7k5AQAvPZ6EBAQgHv37qFFixYwMjKCkZERfH198cMPP8DIyEh7PXmtX5yzszO8vb11tnl5eSEqKgoAf6/1afbs2Zg7dy5ef/11NGrUCKNHj8aMGTOwZMkSALzWJako19bJyQnZ2dlISEh4apnnxeTmBZmYmKBFixY4fPiwzvbDhw+jffv2BoqqYhBCYPLkydixYweOHj2KmjVr6uyvWbMmnJycdK59dnY2fH19ee2L6aWXXsLly5cRFBSk/WrZsiVGjRqFoKAg1KpVi9daTzp06JBvSoNr167B3d0dAH+v9Sk9PR1yue5tTqFQaIeC81qXnKJc2xYtWsDY2FinTGxsLK5cufLi1/+FuiOTECJvKPiqVatESEiImD59urCwsBA3b940dGjl2sSJE4WNjY04fvy4iI2N1X6lp6dry3z55ZfCxsZG7NixQ1y+fFmMGDGCwzj15PHRUkLwWuvL2bNnhZGRkfj8889FeHi42LhxozA3NxcbNmzQluG11o+xY8cKV1dX7VDwHTt2iGrVqokPPvhAW4bX+vmlpKSIwMBAERgYKACIZcuWicDAQO00KEW5thMmTBDVq1cXR44cERcuXBDdu3fnUPCyZMWKFcLd3V2YmJiI5s2ba4cr0/MDUODXmjVrtGU0Go34+OOPhZOTk1AqlaJz587i8uXLhgu6AnkyueG11p+9e/eKhg0bCqVSKerXry9+/fVXnf281vqRnJwspk2bJmrUqCFMTU1FrVq1xIIFC0RWVpa2DK/18zt27FiB/6PHjh0rhCjatc3IyBCTJ08Wtra2wszMTPTr109ERUW9cGwyIYR4sbofIiIiorKDfW6IiIioQmFyQ0RERBUKkxsiIiKqUJjcEBERUYXC5IaIiIgqFCY3REREVKEwuSEiIqIKhckNERERVShMboio0jl+/DhkMhkSExMNHQoRlQAmN0RERFShMLkhIiKiCoXJDRGVOiEEvv76a9SqVQtmZmZo0qQJ/vrrLwB5TUb79u1DkyZNYGpqijZt2uDy5cs659i+fTsaNGgApVIJDw8PLF26VGd/VlYWPvjgA7i5uUGpVKJu3bpYtWqVTpmAgAC0bNkS5ubmaN++PcLCwrT7Ll68iG7dusHKygrW1tZo0aIFzp8/X0JXhIj0ycjQARBR5fPhhx9ix44dWLlyJerWrYsTJ07gjTfegL29vbbM7Nmz8f3338PJyQnz58/HgAEDcO3aNRgbGyMgIADDhg3DokWLMHz4cPj7++O9996DnZ0dfHx8AABjxozB6dOn8cMPP6BJkyaIjIxEfHy8ThwLFizA0qVLYW9vjwkTJuCtt97CqVOnAACjRo1Cs2bNsHLlSigUCgQFBcHY2LjUrhERvYAXXleciKgYUlNThampqfD399fZPm7cODFixAhx7NgxAUBs2bJFu+/BgwfCzMxMbN26VQghxMiRI0XPnj11jp89e7bw9vYWQggRFhYmAIjDhw8XGEPuaxw5ckS7bd++fQKAyMjIEEIIYWVlJdauXfvib5iISh2bpYioVIWEhCAzMxM9e/aEpaWl9mvdunWIiIjQlmvXrp32sa2tLTw9PREaGgoACA0NRYcOHXTO26FDB4SHh0OtViMoKAgKhQJdunQpNJbGjRtrHzs7OwMA7t27BwCYOXMm3n77bfTo0QNffvmlTmxEVLYxuSGiUqXRaAAA+/btQ1BQkPYrJCRE2+/maWQyGQCpz07u41xCCO1jMzOzIsXyeDNT7vly41u0aBGCg4PRt29fHD16FN7e3ti5c2eRzktEhsXkhohKlbe3N5RKJaKiolCnTh2dLzc3N225M2fOaB8nJCTg2rVrqF+/vvYcJ0+e1Dmvv78/6tWrB4VCgUaNGkGj0cDX1/eFYq1Xrx5mzJiBQ4cOYfDgwVizZs0LnY+ISgc7FBNRqbKyssL777+PGTNmQKPRoGPHjkhOToa/vz8sLS3h7u4OAPjkk09gZ2cHR0dHLFiwANWqVcOgQYMAALNmzUKrVq3w6aefYvjw4Th9+jT+97//4aeffgIAeHh4YOzYsXjrrbe0HYpv3bqFe/fuYdiwYc+MMSMjA7Nnz8Zrr72GmjVr4s6dOzh37hyGDBlSYteFiPTI0J1+iKjy0Wg04vvvvxeenp7C2NhY2Nvbi969ewtfX19tZ9+9e/eKBg0aCBMTE9GqVSsRFBSkc46//vpLeHt7C2NjY1GjRg3xzTff6OzPyMgQM2bMEM7OzsLExETUqVNHrF69WgiR16E4ISFBWz4wMFAAEJGRkSIrK0u8/vrrws3NTZiYmAgXFxcxefJkbWdjIirbZEI81lBNRGRgx48fR7du3ZCQkIAqVaoYOhwiKofY54aIiIgqFCY3REREVKGwWYqIiIgqFNbcEBERUYXC5IaIiIgqFCY3REREVKEwuSEiIqIKhckNERERVShMboiIiKhCYXJDREREFQqTGyIiIqpQ/g80GaWrxK2cqQAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "history_df = pd.DataFrame.from_dict(history.history)\n",
    "sns.lineplot(data=history_df[['root_mean_squared_error', 'val_root_mean_squared_error']])\n",
    "plt.xlabel(\"epochs\")\n",
    "plt.ylabel(\"RMSE\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef2ad0fd-aa56-439b-885b-b86f2014572b",
   "metadata": {},
   "source": [
    "Immediately keras is getting the same results that my pytorch FNN model was getting. I'm going to test with the consolidated data now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "501ab16e-153e-420f-8017-b4f497af00cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "91/91 - 18001s - 198s/step - loss: 7.8398 - root_mean_squared_error: 2.8000 - val_loss: 5.8016 - val_root_mean_squared_error: 2.4087\n",
      "Epoch 2/100\n",
      "91/91 - -18000s - -197803705us/step - loss: 5.6249 - root_mean_squared_error: 2.3717 - val_loss: 5.7847 - val_root_mean_squared_error: 2.4051\n",
      "Epoch 3/100\n",
      "91/91 - 0s - 3ms/step - loss: 5.5869 - root_mean_squared_error: 2.3637 - val_loss: 5.7385 - val_root_mean_squared_error: 2.3955\n",
      "Epoch 4/100\n",
      "91/91 - 0s - 2ms/step - loss: 5.5587 - root_mean_squared_error: 2.3577 - val_loss: 5.7561 - val_root_mean_squared_error: 2.3992\n",
      "Epoch 5/100\n",
      "91/91 - 0s - 2ms/step - loss: 5.5373 - root_mean_squared_error: 2.3531 - val_loss: 5.7467 - val_root_mean_squared_error: 2.3972\n",
      "Epoch 6/100\n",
      "91/91 - 0s - 2ms/step - loss: 5.5166 - root_mean_squared_error: 2.3488 - val_loss: 5.7317 - val_root_mean_squared_error: 2.3941\n",
      "Epoch 7/100\n",
      "91/91 - 0s - 2ms/step - loss: 5.5019 - root_mean_squared_error: 2.3456 - val_loss: 5.7322 - val_root_mean_squared_error: 2.3942\n",
      "Epoch 8/100\n",
      "91/91 - 0s - 2ms/step - loss: 5.4804 - root_mean_squared_error: 2.3410 - val_loss: 5.7344 - val_root_mean_squared_error: 2.3947\n",
      "Epoch 9/100\n",
      "91/91 - 0s - 2ms/step - loss: 5.4676 - root_mean_squared_error: 2.3383 - val_loss: 5.7298 - val_root_mean_squared_error: 2.3937\n",
      "Epoch 10/100\n",
      "91/91 - 0s - 3ms/step - loss: 5.4430 - root_mean_squared_error: 2.3330 - val_loss: 5.7510 - val_root_mean_squared_error: 2.3981\n",
      "Epoch 11/100\n",
      "91/91 - 0s - 3ms/step - loss: 5.4294 - root_mean_squared_error: 2.3301 - val_loss: 5.7247 - val_root_mean_squared_error: 2.3926\n",
      "Epoch 12/100\n",
      "91/91 - 0s - 3ms/step - loss: 5.4183 - root_mean_squared_error: 2.3277 - val_loss: 5.7360 - val_root_mean_squared_error: 2.3950\n",
      "Epoch 13/100\n",
      "91/91 - 0s - 3ms/step - loss: 5.4031 - root_mean_squared_error: 2.3245 - val_loss: 5.7271 - val_root_mean_squared_error: 2.3931\n",
      "Epoch 14/100\n",
      "91/91 - 0s - 3ms/step - loss: 5.3846 - root_mean_squared_error: 2.3205 - val_loss: 5.7214 - val_root_mean_squared_error: 2.3920\n",
      "Epoch 15/100\n",
      "91/91 - 0s - 3ms/step - loss: 5.3771 - root_mean_squared_error: 2.3189 - val_loss: 5.7312 - val_root_mean_squared_error: 2.3940\n",
      "Epoch 16/100\n",
      "91/91 - 0s - 3ms/step - loss: 5.3585 - root_mean_squared_error: 2.3149 - val_loss: 5.7454 - val_root_mean_squared_error: 2.3969\n",
      "Epoch 17/100\n",
      "91/91 - 0s - 3ms/step - loss: 5.3510 - root_mean_squared_error: 2.3132 - val_loss: 5.7220 - val_root_mean_squared_error: 2.3921\n",
      "Epoch 18/100\n",
      "91/91 - 0s - 4ms/step - loss: 5.3316 - root_mean_squared_error: 2.3090 - val_loss: 5.7171 - val_root_mean_squared_error: 2.3911\n",
      "Epoch 19/100\n",
      "91/91 - 0s - 3ms/step - loss: 5.3300 - root_mean_squared_error: 2.3087 - val_loss: 5.7514 - val_root_mean_squared_error: 2.3982\n",
      "Epoch 20/100\n",
      "91/91 - 0s - 3ms/step - loss: 5.3148 - root_mean_squared_error: 2.3054 - val_loss: 5.7787 - val_root_mean_squared_error: 2.4039\n",
      "Epoch 21/100\n",
      "91/91 - 18001s - 198s/step - loss: 5.2997 - root_mean_squared_error: 2.3021 - val_loss: 5.7455 - val_root_mean_squared_error: 2.3970\n",
      "Epoch 22/100\n",
      "91/91 - -18000s - -197804020us/step - loss: 5.2849 - root_mean_squared_error: 2.2989 - val_loss: 5.7582 - val_root_mean_squared_error: 2.3996\n",
      "Epoch 23/100\n",
      "91/91 - 0s - 2ms/step - loss: 5.2809 - root_mean_squared_error: 2.2980 - val_loss: 5.7729 - val_root_mean_squared_error: 2.4027\n",
      "Epoch 24/100\n",
      "91/91 - 0s - 2ms/step - loss: 5.2579 - root_mean_squared_error: 2.2930 - val_loss: 5.8021 - val_root_mean_squared_error: 2.4087\n",
      "Epoch 25/100\n",
      "91/91 - 0s - 2ms/step - loss: 5.2456 - root_mean_squared_error: 2.2903 - val_loss: 5.7341 - val_root_mean_squared_error: 2.3946\n",
      "Epoch 26/100\n",
      "91/91 - 0s - 2ms/step - loss: 5.2477 - root_mean_squared_error: 2.2908 - val_loss: 5.7392 - val_root_mean_squared_error: 2.3957\n",
      "Epoch 27/100\n",
      "91/91 - 0s - 2ms/step - loss: 5.2240 - root_mean_squared_error: 2.2856 - val_loss: 5.7684 - val_root_mean_squared_error: 2.4018\n",
      "Epoch 28/100\n",
      "91/91 - 0s - 3ms/step - loss: 5.2260 - root_mean_squared_error: 2.2860 - val_loss: 5.7619 - val_root_mean_squared_error: 2.4004\n",
      "Epoch 29/100\n",
      "91/91 - 0s - 3ms/step - loss: 5.2021 - root_mean_squared_error: 2.2808 - val_loss: 5.7443 - val_root_mean_squared_error: 2.3967\n",
      "Epoch 30/100\n",
      "91/91 - 0s - 2ms/step - loss: 5.1858 - root_mean_squared_error: 2.2772 - val_loss: 5.8255 - val_root_mean_squared_error: 2.4136\n",
      "Epoch 31/100\n",
      "91/91 - 0s - 2ms/step - loss: 5.1786 - root_mean_squared_error: 2.2756 - val_loss: 5.7512 - val_root_mean_squared_error: 2.3982\n",
      "Epoch 32/100\n",
      "91/91 - 0s - 2ms/step - loss: 5.1748 - root_mean_squared_error: 2.2748 - val_loss: 5.7777 - val_root_mean_squared_error: 2.4037\n",
      "Epoch 33/100\n",
      "91/91 - 0s - 2ms/step - loss: 5.1585 - root_mean_squared_error: 2.2712 - val_loss: 5.8112 - val_root_mean_squared_error: 2.4106\n",
      "Epoch 34/100\n",
      "91/91 - 0s - 2ms/step - loss: 5.1385 - root_mean_squared_error: 2.2668 - val_loss: 5.7863 - val_root_mean_squared_error: 2.4055\n",
      "Epoch 35/100\n",
      "91/91 - 0s - 2ms/step - loss: 5.1394 - root_mean_squared_error: 2.2670 - val_loss: 5.7949 - val_root_mean_squared_error: 2.4073\n",
      "Epoch 36/100\n",
      "91/91 - 0s - 3ms/step - loss: 5.1336 - root_mean_squared_error: 2.2658 - val_loss: 5.7835 - val_root_mean_squared_error: 2.4049\n",
      "Epoch 37/100\n",
      "91/91 - 0s - 2ms/step - loss: 5.1133 - root_mean_squared_error: 2.2613 - val_loss: 5.7798 - val_root_mean_squared_error: 2.4041\n",
      "Epoch 38/100\n",
      "91/91 - 0s - 2ms/step - loss: 5.1078 - root_mean_squared_error: 2.2600 - val_loss: 5.8188 - val_root_mean_squared_error: 2.4122\n",
      "Epoch 39/100\n",
      "91/91 - 0s - 2ms/step - loss: 5.1064 - root_mean_squared_error: 2.2597 - val_loss: 5.7813 - val_root_mean_squared_error: 2.4044\n",
      "Epoch 40/100\n",
      "91/91 - 0s - 2ms/step - loss: 5.0820 - root_mean_squared_error: 2.2543 - val_loss: 5.8587 - val_root_mean_squared_error: 2.4205\n",
      "Epoch 41/100\n",
      "91/91 - 0s - 2ms/step - loss: 5.0674 - root_mean_squared_error: 2.2511 - val_loss: 5.8099 - val_root_mean_squared_error: 2.4104\n",
      "Epoch 42/100\n",
      "91/91 - 0s - 2ms/step - loss: 5.0631 - root_mean_squared_error: 2.2501 - val_loss: 5.8254 - val_root_mean_squared_error: 2.4136\n",
      "Epoch 43/100\n",
      "91/91 - 0s - 3ms/step - loss: 5.0401 - root_mean_squared_error: 2.2450 - val_loss: 5.8038 - val_root_mean_squared_error: 2.4091\n",
      "Epoch 44/100\n",
      "91/91 - 18001s - 198s/step - loss: 5.0530 - root_mean_squared_error: 2.2479 - val_loss: 5.7961 - val_root_mean_squared_error: 2.4075\n",
      "Epoch 45/100\n",
      "91/91 - -18000s - -197803439us/step - loss: 5.0197 - root_mean_squared_error: 2.2405 - val_loss: 5.8049 - val_root_mean_squared_error: 2.4093\n",
      "Epoch 46/100\n",
      "91/91 - 0s - 3ms/step - loss: 5.0056 - root_mean_squared_error: 2.2373 - val_loss: 5.8288 - val_root_mean_squared_error: 2.4143\n",
      "Epoch 47/100\n",
      "91/91 - 0s - 3ms/step - loss: 5.0061 - root_mean_squared_error: 2.2374 - val_loss: 5.8124 - val_root_mean_squared_error: 2.4109\n",
      "Epoch 48/100\n",
      "91/91 - 0s - 3ms/step - loss: 4.9821 - root_mean_squared_error: 2.2321 - val_loss: 5.8679 - val_root_mean_squared_error: 2.4224\n",
      "Epoch 49/100\n",
      "91/91 - 0s - 4ms/step - loss: 4.9857 - root_mean_squared_error: 2.2329 - val_loss: 5.8131 - val_root_mean_squared_error: 2.4110\n",
      "Epoch 50/100\n",
      "91/91 - 0s - 4ms/step - loss: 4.9678 - root_mean_squared_error: 2.2289 - val_loss: 5.7838 - val_root_mean_squared_error: 2.4050\n",
      "Epoch 51/100\n",
      "91/91 - 0s - 3ms/step - loss: 4.9547 - root_mean_squared_error: 2.2259 - val_loss: 5.8310 - val_root_mean_squared_error: 2.4147\n",
      "Epoch 52/100\n",
      "91/91 - 0s - 3ms/step - loss: 4.9447 - root_mean_squared_error: 2.2237 - val_loss: 5.8343 - val_root_mean_squared_error: 2.4154\n",
      "Epoch 53/100\n",
      "91/91 - 0s - 3ms/step - loss: 4.9371 - root_mean_squared_error: 2.2220 - val_loss: 5.8099 - val_root_mean_squared_error: 2.4104\n",
      "Epoch 54/100\n",
      "91/91 - 0s - 3ms/step - loss: 4.9251 - root_mean_squared_error: 2.2193 - val_loss: 5.8235 - val_root_mean_squared_error: 2.4132\n",
      "Epoch 55/100\n",
      "91/91 - 0s - 3ms/step - loss: 4.9227 - root_mean_squared_error: 2.2187 - val_loss: 5.8273 - val_root_mean_squared_error: 2.4140\n",
      "Epoch 56/100\n",
      "91/91 - 0s - 3ms/step - loss: 4.9069 - root_mean_squared_error: 2.2151 - val_loss: 5.8476 - val_root_mean_squared_error: 2.4182\n",
      "Epoch 57/100\n",
      "91/91 - 0s - 3ms/step - loss: 4.8872 - root_mean_squared_error: 2.2107 - val_loss: 5.8349 - val_root_mean_squared_error: 2.4155\n",
      "Epoch 58/100\n",
      "91/91 - 0s - 2ms/step - loss: 4.8848 - root_mean_squared_error: 2.2102 - val_loss: 5.8790 - val_root_mean_squared_error: 2.4247\n",
      "Epoch 59/100\n",
      "91/91 - 0s - 3ms/step - loss: 4.8899 - root_mean_squared_error: 2.2113 - val_loss: 5.8068 - val_root_mean_squared_error: 2.4097\n",
      "Epoch 60/100\n",
      "91/91 - 0s - 2ms/step - loss: 4.8689 - root_mean_squared_error: 2.2066 - val_loss: 5.8194 - val_root_mean_squared_error: 2.4123\n",
      "Epoch 61/100\n",
      "91/91 - 0s - 2ms/step - loss: 4.8565 - root_mean_squared_error: 2.2037 - val_loss: 5.8138 - val_root_mean_squared_error: 2.4112\n",
      "Epoch 62/100\n",
      "91/91 - 18001s - 198s/step - loss: 4.8436 - root_mean_squared_error: 2.2008 - val_loss: 5.8649 - val_root_mean_squared_error: 2.4217\n",
      "Epoch 63/100\n",
      "91/91 - -18000s - -197803953us/step - loss: 4.8474 - root_mean_squared_error: 2.2017 - val_loss: 5.8239 - val_root_mean_squared_error: 2.4133\n",
      "Epoch 64/100\n",
      "91/91 - 0s - 2ms/step - loss: 4.8303 - root_mean_squared_error: 2.1978 - val_loss: 5.8129 - val_root_mean_squared_error: 2.4110\n",
      "Epoch 65/100\n",
      "91/91 - 0s - 2ms/step - loss: 4.8270 - root_mean_squared_error: 2.1970 - val_loss: 5.8300 - val_root_mean_squared_error: 2.4145\n",
      "Epoch 66/100\n",
      "91/91 - 0s - 2ms/step - loss: 4.8159 - root_mean_squared_error: 2.1945 - val_loss: 5.8554 - val_root_mean_squared_error: 2.4198\n",
      "Epoch 67/100\n",
      "91/91 - 0s - 3ms/step - loss: 4.8143 - root_mean_squared_error: 2.1942 - val_loss: 5.7942 - val_root_mean_squared_error: 2.4071\n",
      "Epoch 68/100\n",
      "91/91 - 0s - 2ms/step - loss: 4.7984 - root_mean_squared_error: 2.1905 - val_loss: 5.8299 - val_root_mean_squared_error: 2.4145\n",
      "Epoch 69/100\n",
      "91/91 - 0s - 3ms/step - loss: 4.8063 - root_mean_squared_error: 2.1923 - val_loss: 5.8955 - val_root_mean_squared_error: 2.4281\n",
      "Epoch 70/100\n",
      "91/91 - 0s - 2ms/step - loss: 4.7853 - root_mean_squared_error: 2.1875 - val_loss: 5.8129 - val_root_mean_squared_error: 2.4110\n",
      "Epoch 71/100\n",
      "91/91 - 0s - 2ms/step - loss: 4.7765 - root_mean_squared_error: 2.1855 - val_loss: 5.8249 - val_root_mean_squared_error: 2.4135\n",
      "Epoch 72/100\n",
      "91/91 - 0s - 3ms/step - loss: 4.7689 - root_mean_squared_error: 2.1838 - val_loss: 5.8449 - val_root_mean_squared_error: 2.4176\n",
      "Epoch 73/100\n",
      "91/91 - 0s - 2ms/step - loss: 4.7693 - root_mean_squared_error: 2.1839 - val_loss: 5.8330 - val_root_mean_squared_error: 2.4152\n",
      "Epoch 74/100\n",
      "91/91 - 0s - 2ms/step - loss: 4.7576 - root_mean_squared_error: 2.1812 - val_loss: 5.8338 - val_root_mean_squared_error: 2.4153\n",
      "Epoch 75/100\n",
      "91/91 - 0s - 2ms/step - loss: 4.7562 - root_mean_squared_error: 2.1809 - val_loss: 5.8755 - val_root_mean_squared_error: 2.4239\n",
      "Epoch 76/100\n",
      "91/91 - 0s - 3ms/step - loss: 4.7578 - root_mean_squared_error: 2.1812 - val_loss: 5.8117 - val_root_mean_squared_error: 2.4107\n",
      "Epoch 77/100\n",
      "91/91 - 0s - 4ms/step - loss: 4.7461 - root_mean_squared_error: 2.1785 - val_loss: 5.8167 - val_root_mean_squared_error: 2.4118\n",
      "Epoch 78/100\n",
      "91/91 - 0s - 2ms/step - loss: 4.7386 - root_mean_squared_error: 2.1768 - val_loss: 5.8385 - val_root_mean_squared_error: 2.4163\n",
      "Epoch 79/100\n",
      "91/91 - 0s - 2ms/step - loss: 4.7320 - root_mean_squared_error: 2.1753 - val_loss: 5.8423 - val_root_mean_squared_error: 2.4171\n",
      "Epoch 80/100\n",
      "91/91 - 0s - 3ms/step - loss: 4.7259 - root_mean_squared_error: 2.1739 - val_loss: 5.8462 - val_root_mean_squared_error: 2.4179\n",
      "Epoch 81/100\n",
      "91/91 - 0s - 2ms/step - loss: 4.7176 - root_mean_squared_error: 2.1720 - val_loss: 5.8253 - val_root_mean_squared_error: 2.4136\n",
      "Epoch 82/100\n",
      "91/91 - 0s - 3ms/step - loss: 4.7188 - root_mean_squared_error: 2.1723 - val_loss: 5.8252 - val_root_mean_squared_error: 2.4135\n",
      "Epoch 83/100\n",
      "91/91 - 0s - 3ms/step - loss: 4.7096 - root_mean_squared_error: 2.1702 - val_loss: 5.8008 - val_root_mean_squared_error: 2.4085\n",
      "Epoch 84/100\n",
      "91/91 - 0s - 3ms/step - loss: 4.7070 - root_mean_squared_error: 2.1696 - val_loss: 5.8332 - val_root_mean_squared_error: 2.4152\n",
      "Epoch 85/100\n",
      "91/91 - 0s - 937us/step - loss: 4.7019 - root_mean_squared_error: 2.1684 - val_loss: 5.8352 - val_root_mean_squared_error: 2.4156\n",
      "Epoch 86/100\n"
     ]
    }
   ],
   "source": [
    "n_features = cX_train.shape[1]\n",
    "n_predictions = 1\n",
    "\n",
    "model = create_keras_nn(n_features, n_predictions)\n",
    "model.compile(loss='mse', optimizer=keras.optimizers.Adam(),\n",
    "              metrics=[keras.metrics.RootMeanSquaredError()])\n",
    "\n",
    "history = model.fit(cX_train, cy_train,\n",
    "                    batch_size = 32,\n",
    "                    epochs = 100,\n",
    "                    validation_data=(cX_test, cy_test), verbose = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7140b79-83da-4ef7-a02b-8460fc3ec373",
   "metadata": {},
   "outputs": [],
   "source": [
    "history_df = pd.DataFrame.from_dict(history.history)\n",
    "sns.lineplot(data=history_df[['root_mean_squared_error', 'val_root_mean_squared_error']])\n",
    "plt.xlabel(\"epochs\")\n",
    "plt.ylabel(\"RMSE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c4e00b9-7b35-471a-b640-73dcdb8987dd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "ml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
